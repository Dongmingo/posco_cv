{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(VGG, self).__init__()\n",
    "        self.conv1_1 = self.make_conv_relu(3, 64)\n",
    "        \n",
    "        self.conv2_1 = self.make_conv_relu(64, 128)\n",
    "\n",
    "        self.conv3_1 = self.make_conv_relu(128, 256)\n",
    "        self.conv3_2 = self.make_conv_relu(256, 256)\n",
    "\n",
    "        self.conv4_1 = self.make_conv_relu(256, 512)\n",
    "        self.conv4_2 = self.make_conv_relu(512, 512)\n",
    "\n",
    "        self.conv5_1 = self.make_conv_relu(512, 512)\n",
    "        self.conv5_2 = self.make_conv_relu(512, 512)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def make_conv_relu(self, in_channels, out_channel):\n",
    "        layers = []\n",
    "        layers += [nn.Conv2d(in_channels, out_channel, kernel_size=3, padding=1),  #using kernel size 3, padding 1 -> keep the spatial dimension of tensor\n",
    "                   nn.ReLU()]\n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [Batchsize, 3, 32, 32]\n",
    "        \n",
    "        x = self.conv1_1(x) # [Batchsize, 64, 32, 32]\n",
    "        x = self.maxpool(x) # [Batchsize, 64, 16, 16]\n",
    "        \n",
    "        x = self.conv2_1(x) # [Batchsize, 128, 16, 16]\n",
    "        x = self.maxpool(x) # [Batchsize, 128, 8, 8]\n",
    "        \n",
    "        x = self.conv3_1(x) # [Batchsize, 256, 8, 8]\n",
    "        x = self.conv3_2(x) # [Batchsize, 256, 8, 8]\n",
    "        x = self.maxpool(x) # [Batchsize, 256, 4, 4]\n",
    "        \n",
    "        x = self.conv4_1(x) # [Batchsize, 512, 4, 4]\n",
    "        x = self.conv4_2(x) # [Batchsize, 512, 4, 4]\n",
    "        x = self.maxpool(x) # [Batchsize, 512, 2, 2]\n",
    "        \n",
    "        x = self.conv5_1(x) # [Batchsize, 512, 2, 2]\n",
    "        x = self.conv5_2(x) # [Batchsize, 512, 2, 2]\n",
    "        x = self.maxpool(x) # [Batchsize, 512, 1, 1]\n",
    "\n",
    "        x = x.view(x.size(0), -1) # [Batchsize, 512]\n",
    "        \n",
    "        x = self.classifier(x) # [Batchsize, num_classes]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state dictionary\n",
    "a = {\n",
    "    \"key\": 5,\n",
    "    \"name\": \"chunghyun\",\n",
    "    \"age\": 27\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunghyun\n"
     ]
    }
   ],
   "source": [
    "print(a[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = vgg.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.OrderedDict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1_1.0.weight\n",
      "conv1_1.0.bias\n",
      "conv2_1.0.weight\n",
      "conv2_1.0.bias\n",
      "conv3_1.0.weight\n",
      "conv3_1.0.bias\n",
      "conv3_2.0.weight\n",
      "conv3_2.0.bias\n",
      "conv4_1.0.weight\n",
      "conv4_1.0.bias\n",
      "conv4_2.0.weight\n",
      "conv4_2.0.bias\n",
      "conv5_1.0.weight\n",
      "conv5_1.0.bias\n",
      "conv5_2.0.weight\n",
      "conv5_2.0.bias\n",
      "classifier.weight\n",
      "classifier.bias\n"
     ]
    }
   ],
   "source": [
    "for k, v in state_dict.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 3])\n",
      "tensor([[[[-0.0764, -0.1197,  0.0123],\n",
      "          [-0.0812,  0.0168, -0.1048],\n",
      "          [ 0.0682,  0.1021, -0.0753]],\n",
      "\n",
      "         [[ 0.0539, -0.1040,  0.1738],\n",
      "          [ 0.1653,  0.1796, -0.0810],\n",
      "          [-0.1722, -0.0299, -0.0277]],\n",
      "\n",
      "         [[-0.1456, -0.1477, -0.1041],\n",
      "          [-0.0983,  0.0875,  0.1176],\n",
      "          [ 0.1666,  0.1655,  0.0710]]],\n",
      "\n",
      "\n",
      "        [[[-0.1034, -0.0692,  0.0085],\n",
      "          [ 0.1770,  0.0549,  0.1138],\n",
      "          [-0.1111, -0.1614, -0.0655]],\n",
      "\n",
      "         [[-0.1825, -0.0319,  0.1222],\n",
      "          [-0.1783,  0.0717, -0.0194],\n",
      "          [ 0.1332, -0.0024,  0.0123]],\n",
      "\n",
      "         [[ 0.0257,  0.0768, -0.0205],\n",
      "          [ 0.1155, -0.1794, -0.1061],\n",
      "          [ 0.1037, -0.0285, -0.0885]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0725, -0.1410, -0.1742],\n",
      "          [-0.1297,  0.1152, -0.1014],\n",
      "          [ 0.1585,  0.0095,  0.1285]],\n",
      "\n",
      "         [[-0.0097, -0.1815, -0.1713],\n",
      "          [-0.0041, -0.1843,  0.1141],\n",
      "          [-0.0743,  0.1402, -0.1052]],\n",
      "\n",
      "         [[-0.1705,  0.0258,  0.0362],\n",
      "          [ 0.1750,  0.0323,  0.1735],\n",
      "          [ 0.0253,  0.0771, -0.1654]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0946, -0.1346,  0.0332],\n",
      "          [ 0.1320,  0.0862,  0.0664],\n",
      "          [ 0.0767, -0.1821, -0.1574]],\n",
      "\n",
      "         [[-0.0382, -0.1687,  0.0115],\n",
      "          [ 0.1360,  0.0718, -0.0706],\n",
      "          [-0.1228,  0.1380, -0.0908]],\n",
      "\n",
      "         [[ 0.1764,  0.0757,  0.1805],\n",
      "          [-0.1212, -0.1651,  0.1202],\n",
      "          [-0.0647, -0.1860,  0.0262]]],\n",
      "\n",
      "\n",
      "        [[[-0.0916, -0.0279,  0.0903],\n",
      "          [ 0.1882, -0.1157, -0.0335],\n",
      "          [ 0.0840,  0.1767,  0.1686]],\n",
      "\n",
      "         [[ 0.1899, -0.1676, -0.1481],\n",
      "          [-0.1499,  0.0729,  0.0605],\n",
      "          [-0.0988,  0.0132, -0.0177]],\n",
      "\n",
      "         [[-0.0183,  0.0701, -0.0098],\n",
      "          [-0.0331, -0.1358,  0.0474],\n",
      "          [ 0.0725,  0.1767, -0.0877]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1172, -0.1451, -0.0427],\n",
      "          [ 0.0205,  0.0524,  0.0743],\n",
      "          [ 0.0090, -0.0151, -0.0023]],\n",
      "\n",
      "         [[-0.0141, -0.1062, -0.0858],\n",
      "          [ 0.0658, -0.1752, -0.1442],\n",
      "          [ 0.0596,  0.1542, -0.0880]],\n",
      "\n",
      "         [[-0.1811, -0.1818, -0.1107],\n",
      "          [ 0.0600,  0.0991,  0.0528],\n",
      "          [-0.0995,  0.1108, -0.1014]]]])\n"
     ]
    }
   ],
   "source": [
    "weight = state_dict[\"conv1_1.0.weight\"]\n",
    "print(weight.shape)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (conv1_1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv2_1): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv3_1): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv3_2): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv4_1): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv4_2): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv5_1): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv5_2): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU()\n",
       "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg = VGG(10).to(device)\n",
    "vgg.train()\n",
    "# print(vgg.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "782\n"
     ]
    }
   ],
   "source": [
    "# Loading and normalizing CIFAR-10\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #normalization value for cifar10\n",
    "    ])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                      download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                      download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vgg.parameters(), lr=0.001)\n",
    "\n",
    "print(len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vgg.state_dict(), \"state_dict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_before = vgg.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_after = torch.load(\"state_dict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.1550,  0.1311, -0.0730],\n",
      "          [-0.0310, -0.1659, -0.1092],\n",
      "          [-0.1587, -0.0859,  0.0658]],\n",
      "\n",
      "         [[-0.1543, -0.0692,  0.0299],\n",
      "          [ 0.0873,  0.1903, -0.1028],\n",
      "          [ 0.1657, -0.0163,  0.1028]],\n",
      "\n",
      "         [[-0.1534, -0.0733,  0.1793],\n",
      "          [ 0.1310, -0.0265, -0.1138],\n",
      "          [ 0.0515,  0.1543,  0.0630]]],\n",
      "\n",
      "\n",
      "        [[[-0.1426, -0.0045,  0.1683],\n",
      "          [-0.1240, -0.0053, -0.0346],\n",
      "          [-0.1391, -0.0825,  0.0780]],\n",
      "\n",
      "         [[-0.0139, -0.0374, -0.1791],\n",
      "          [-0.1222,  0.0160, -0.1572],\n",
      "          [ 0.0093, -0.0191, -0.0382]],\n",
      "\n",
      "         [[-0.1140,  0.0798,  0.1162],\n",
      "          [ 0.0232,  0.0194,  0.0879],\n",
      "          [-0.0213,  0.0805, -0.1212]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0552,  0.0595,  0.1751],\n",
      "          [-0.1297, -0.0342,  0.0403],\n",
      "          [ 0.0541, -0.0704,  0.1160]],\n",
      "\n",
      "         [[ 0.1712,  0.1649, -0.1189],\n",
      "          [-0.1422,  0.0098,  0.1151],\n",
      "          [-0.1216, -0.0686,  0.0357]],\n",
      "\n",
      "         [[ 0.0786, -0.0055, -0.0626],\n",
      "          [-0.1078,  0.0620,  0.1605],\n",
      "          [-0.1307,  0.1463, -0.0164]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1887, -0.0929, -0.0925],\n",
      "          [ 0.1841,  0.1418,  0.0489],\n",
      "          [-0.0048, -0.0712, -0.1874]],\n",
      "\n",
      "         [[-0.1414,  0.0123, -0.1820],\n",
      "          [ 0.1762,  0.0776, -0.1528],\n",
      "          [-0.1623,  0.0847, -0.0026]],\n",
      "\n",
      "         [[ 0.0154,  0.0790, -0.1331],\n",
      "          [-0.1791,  0.0081,  0.0674],\n",
      "          [-0.0536,  0.0053, -0.1236]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0051, -0.1768, -0.1347],\n",
      "          [ 0.0063, -0.0318,  0.0715],\n",
      "          [-0.1367,  0.0818, -0.0639]],\n",
      "\n",
      "         [[ 0.1270, -0.1023,  0.0347],\n",
      "          [ 0.0955,  0.0489,  0.0097],\n",
      "          [-0.0519, -0.0272, -0.1625]],\n",
      "\n",
      "         [[-0.0561, -0.0291,  0.1845],\n",
      "          [ 0.1033, -0.1677,  0.0667],\n",
      "          [ 0.1636,  0.0650,  0.0608]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0106,  0.0605,  0.1188],\n",
      "          [ 0.0475,  0.0291,  0.0155],\n",
      "          [-0.1764,  0.1017,  0.0284]],\n",
      "\n",
      "         [[-0.0970,  0.0096, -0.1213],\n",
      "          [-0.0304,  0.0732,  0.0615],\n",
      "          [ 0.1730, -0.0608, -0.0131]],\n",
      "\n",
      "         [[ 0.1387, -0.0701, -0.0267],\n",
      "          [-0.1014,  0.1601, -0.0282],\n",
      "          [-0.1905, -0.0622,  0.1905]]]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "print(state_dict_before['conv1_1.0.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.1550,  0.1311, -0.0730],\n",
      "          [-0.0310, -0.1659, -0.1092],\n",
      "          [-0.1587, -0.0859,  0.0658]],\n",
      "\n",
      "         [[-0.1543, -0.0692,  0.0299],\n",
      "          [ 0.0873,  0.1903, -0.1028],\n",
      "          [ 0.1657, -0.0163,  0.1028]],\n",
      "\n",
      "         [[-0.1534, -0.0733,  0.1793],\n",
      "          [ 0.1310, -0.0265, -0.1138],\n",
      "          [ 0.0515,  0.1543,  0.0630]]],\n",
      "\n",
      "\n",
      "        [[[-0.1426, -0.0045,  0.1683],\n",
      "          [-0.1240, -0.0053, -0.0346],\n",
      "          [-0.1391, -0.0825,  0.0780]],\n",
      "\n",
      "         [[-0.0139, -0.0374, -0.1791],\n",
      "          [-0.1222,  0.0160, -0.1572],\n",
      "          [ 0.0093, -0.0191, -0.0382]],\n",
      "\n",
      "         [[-0.1140,  0.0798,  0.1162],\n",
      "          [ 0.0232,  0.0194,  0.0879],\n",
      "          [-0.0213,  0.0805, -0.1212]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0552,  0.0595,  0.1751],\n",
      "          [-0.1297, -0.0342,  0.0403],\n",
      "          [ 0.0541, -0.0704,  0.1160]],\n",
      "\n",
      "         [[ 0.1712,  0.1649, -0.1189],\n",
      "          [-0.1422,  0.0098,  0.1151],\n",
      "          [-0.1216, -0.0686,  0.0357]],\n",
      "\n",
      "         [[ 0.0786, -0.0055, -0.0626],\n",
      "          [-0.1078,  0.0620,  0.1605],\n",
      "          [-0.1307,  0.1463, -0.0164]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1887, -0.0929, -0.0925],\n",
      "          [ 0.1841,  0.1418,  0.0489],\n",
      "          [-0.0048, -0.0712, -0.1874]],\n",
      "\n",
      "         [[-0.1414,  0.0123, -0.1820],\n",
      "          [ 0.1762,  0.0776, -0.1528],\n",
      "          [-0.1623,  0.0847, -0.0026]],\n",
      "\n",
      "         [[ 0.0154,  0.0790, -0.1331],\n",
      "          [-0.1791,  0.0081,  0.0674],\n",
      "          [-0.0536,  0.0053, -0.1236]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0051, -0.1768, -0.1347],\n",
      "          [ 0.0063, -0.0318,  0.0715],\n",
      "          [-0.1367,  0.0818, -0.0639]],\n",
      "\n",
      "         [[ 0.1270, -0.1023,  0.0347],\n",
      "          [ 0.0955,  0.0489,  0.0097],\n",
      "          [-0.0519, -0.0272, -0.1625]],\n",
      "\n",
      "         [[-0.0561, -0.0291,  0.1845],\n",
      "          [ 0.1033, -0.1677,  0.0667],\n",
      "          [ 0.1636,  0.0650,  0.0608]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0106,  0.0605,  0.1188],\n",
      "          [ 0.0475,  0.0291,  0.0155],\n",
      "          [-0.1764,  0.1017,  0.0284]],\n",
      "\n",
      "         [[-0.0970,  0.0096, -0.1213],\n",
      "          [-0.0304,  0.0732,  0.0615],\n",
      "          [ 0.1730, -0.0608, -0.0131]],\n",
      "\n",
      "         [[ 0.1387, -0.0701, -0.0267],\n",
      "          [-0.1014,  0.1601, -0.0282],\n",
      "          [-0.1905, -0.0622,  0.1905]]]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "print(state_dict_after['conv1_1.0.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.675\n",
      "[1,   200] loss: 0.664\n",
      "[1,   300] loss: 0.662\n",
      "[1,   400] loss: 0.676\n",
      "[1,   500] loss: 0.688\n",
      "[1,   600] loss: 0.695\n",
      "[1,   700] loss: 0.665\n",
      "[2,   100] loss: 0.544\n",
      "[2,   200] loss: 0.581\n",
      "[2,   300] loss: 0.571\n",
      "[2,   400] loss: 0.601\n",
      "[2,   500] loss: 0.573\n",
      "[2,   600] loss: 0.598\n",
      "[2,   700] loss: 0.605\n",
      "[3,   100] loss: 0.467\n",
      "[3,   200] loss: 0.469\n",
      "[3,   300] loss: 0.495\n",
      "[3,   400] loss: 0.517\n",
      "[3,   500] loss: 0.490\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-defcdd80c373>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Train the network\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = vgg(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # print statistics\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                 (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    #save models\n",
    "    ##implement this\n",
    "    os.makedirs('./checkpoint', exist_ok=True)\n",
    "    torch.save(\n",
    "        {\n",
    "            'state_dict': vgg.state_dict(),\n",
    "            'epoch': epoch\n",
    "        },\n",
    "        f'./checkpoint/vgg_epoch{epoch}.pt')\n",
    "    torch.save(vgg.state_dict(), f'./checkpoint/vgg_latest.pt')\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "# checkpoint: ./checkpoint/vgg-epoch2.pt\n",
    "\n",
    "vgg_after = VGG(10)\n",
    "checkpoint = torch.load(\"./checkpoint/vgg_epoch0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_after.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1228,  0.1161, -0.0619],\n",
       "        [-0.0297, -0.1798, -0.0854],\n",
       "        [-0.1226, -0.0380,  0.0923]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_after.state_dict()['conv1_1.0.weight'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1228,  0.1161, -0.0619],\n",
       "        [-0.0297, -0.1798, -0.0854],\n",
       "        [-0.1226, -0.0380,  0.0923]], device='cuda:1')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['state_dict']['conv1_1.0.weight'][0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
