{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09c410a3-b828-4bb3-bc73-df20473d9a43",
   "metadata": {},
   "source": [
    "Referecnce : https://github.com/eriklindernoren/PyTorch-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2afbd92-67d7-4d49-8f9a-3bd71ff89243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23b2f3ac-9e09-473f-ab69-9d9360dad41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        ##implement\n",
    "        def block(in_feature, out_feature):\n",
    "            ## linear relu batchnorm\n",
    "            layers = []\n",
    "            layers.append(nn.Linear(in_feature, out_feature))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.BatchNorm1d(out_feature))\n",
    "            \n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "                *block(100, 256), # list\n",
    "                *block(256, 512),\n",
    "                *block(512, 1024),\n",
    "                nn.Dropout(),\n",
    "                nn.Linear(1024, 784),\n",
    "                nn.Tanh() # -> output: -1 ~ 1 (real image range와 맞추기 위해서)\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        ##implement\n",
    "        ## z: [batch, 100]\n",
    "        img = self.model(z) ## [batch, 784]\n",
    "        img = img.view(img.shape[0], 1, 28, 28)\n",
    "        \n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        ##implement\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(784, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        ##implement\n",
    "        ## img: [batch, 1, 28, 28]\n",
    "        img = img.view(img.shape[0], -1) # [batch, 784]\n",
    "        out = self.model(img)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8728f4c-c09b-405a-9712-f8549c0626da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator().cuda()\n",
    "discriminator = Discriminator().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b86e60d-6340-45e2-8767-5795a46a080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(\"./mnist\", train=True, download=True, \n",
    "                         transform=transforms.Compose([transforms.Resize(28), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d249fb70-78cf-4191-9d58-afd3d6d4572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.9999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6e2e40-5b60-4ddc-9d55-4a4faf66a756",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/64] [Batch 0/937] [D loss: 0.713945] [G loss: 0.627999]\n",
      "[Epoch 0/64] [Batch 100/937] [D loss: 0.366326] [G loss: 2.716374]\n",
      "[Epoch 0/64] [Batch 200/937] [D loss: 0.482585] [G loss: 2.162812]\n",
      "[Epoch 0/64] [Batch 300/937] [D loss: 0.388261] [G loss: 2.229098]\n",
      "[Epoch 0/64] [Batch 400/937] [D loss: 0.390624] [G loss: 2.104918]\n",
      "[Epoch 0/64] [Batch 500/937] [D loss: 0.423960] [G loss: 1.506979]\n",
      "[Epoch 0/64] [Batch 600/937] [D loss: 0.447793] [G loss: 1.867022]\n",
      "[Epoch 0/64] [Batch 700/937] [D loss: 0.497519] [G loss: 1.089848]\n",
      "[Epoch 0/64] [Batch 800/937] [D loss: 0.498748] [G loss: 0.638261]\n",
      "[Epoch 0/64] [Batch 900/937] [D loss: 0.514719] [G loss: 1.108158]\n",
      "[Epoch 1/64] [Batch 63/937] [D loss: 0.442374] [G loss: 1.247671]\n",
      "[Epoch 1/64] [Batch 163/937] [D loss: 0.542918] [G loss: 1.148885]\n",
      "[Epoch 1/64] [Batch 263/937] [D loss: 0.472351] [G loss: 1.340585]\n",
      "[Epoch 1/64] [Batch 363/937] [D loss: 0.570362] [G loss: 0.804038]\n",
      "[Epoch 1/64] [Batch 463/937] [D loss: 0.510023] [G loss: 1.345256]\n",
      "[Epoch 1/64] [Batch 563/937] [D loss: 0.405045] [G loss: 1.325380]\n",
      "[Epoch 1/64] [Batch 663/937] [D loss: 0.528286] [G loss: 1.543848]\n",
      "[Epoch 1/64] [Batch 763/937] [D loss: 0.477361] [G loss: 1.342326]\n",
      "[Epoch 1/64] [Batch 863/937] [D loss: 0.560447] [G loss: 1.310056]\n",
      "[Epoch 2/64] [Batch 26/937] [D loss: 0.494774] [G loss: 1.094697]\n",
      "[Epoch 2/64] [Batch 126/937] [D loss: 0.485896] [G loss: 1.404104]\n",
      "[Epoch 2/64] [Batch 226/937] [D loss: 0.460968] [G loss: 1.072863]\n",
      "[Epoch 2/64] [Batch 326/937] [D loss: 0.450680] [G loss: 1.216053]\n",
      "[Epoch 2/64] [Batch 426/937] [D loss: 0.444692] [G loss: 1.370445]\n",
      "[Epoch 2/64] [Batch 526/937] [D loss: 0.508970] [G loss: 0.881034]\n",
      "[Epoch 2/64] [Batch 626/937] [D loss: 0.498366] [G loss: 1.074623]\n",
      "[Epoch 2/64] [Batch 726/937] [D loss: 0.522774] [G loss: 1.276694]\n",
      "[Epoch 2/64] [Batch 826/937] [D loss: 0.521810] [G loss: 1.203912]\n",
      "[Epoch 2/64] [Batch 926/937] [D loss: 0.543467] [G loss: 0.935933]\n",
      "[Epoch 3/64] [Batch 89/937] [D loss: 0.581264] [G loss: 1.149822]\n",
      "[Epoch 3/64] [Batch 189/937] [D loss: 0.465455] [G loss: 1.339118]\n",
      "[Epoch 3/64] [Batch 289/937] [D loss: 0.504379] [G loss: 1.231380]\n",
      "[Epoch 3/64] [Batch 389/937] [D loss: 0.534862] [G loss: 0.915207]\n",
      "[Epoch 3/64] [Batch 489/937] [D loss: 0.629792] [G loss: 1.066245]\n",
      "[Epoch 3/64] [Batch 589/937] [D loss: 0.581479] [G loss: 0.983619]\n",
      "[Epoch 3/64] [Batch 689/937] [D loss: 0.557309] [G loss: 1.034826]\n",
      "[Epoch 3/64] [Batch 789/937] [D loss: 0.576034] [G loss: 1.232467]\n",
      "[Epoch 3/64] [Batch 889/937] [D loss: 0.563944] [G loss: 0.798525]\n",
      "[Epoch 4/64] [Batch 52/937] [D loss: 0.549018] [G loss: 0.998599]\n",
      "[Epoch 4/64] [Batch 152/937] [D loss: 0.624041] [G loss: 1.034261]\n",
      "[Epoch 4/64] [Batch 252/937] [D loss: 0.593494] [G loss: 0.982361]\n",
      "[Epoch 4/64] [Batch 352/937] [D loss: 0.596334] [G loss: 0.819719]\n",
      "[Epoch 4/64] [Batch 452/937] [D loss: 0.562931] [G loss: 0.957711]\n",
      "[Epoch 4/64] [Batch 552/937] [D loss: 0.517035] [G loss: 1.124212]\n",
      "[Epoch 4/64] [Batch 652/937] [D loss: 0.676605] [G loss: 0.820057]\n",
      "[Epoch 4/64] [Batch 752/937] [D loss: 0.603292] [G loss: 1.095376]\n",
      "[Epoch 4/64] [Batch 852/937] [D loss: 0.613798] [G loss: 0.899130]\n",
      "[Epoch 5/64] [Batch 15/937] [D loss: 0.592474] [G loss: 0.900349]\n",
      "[Epoch 5/64] [Batch 115/937] [D loss: 0.633621] [G loss: 0.935338]\n",
      "[Epoch 5/64] [Batch 215/937] [D loss: 0.613759] [G loss: 0.890395]\n",
      "[Epoch 5/64] [Batch 315/937] [D loss: 0.639976] [G loss: 1.006447]\n",
      "[Epoch 5/64] [Batch 415/937] [D loss: 0.670166] [G loss: 1.052216]\n",
      "[Epoch 5/64] [Batch 515/937] [D loss: 0.647691] [G loss: 0.885438]\n",
      "[Epoch 5/64] [Batch 615/937] [D loss: 0.603641] [G loss: 0.892742]\n",
      "[Epoch 5/64] [Batch 715/937] [D loss: 0.552839] [G loss: 0.881806]\n",
      "[Epoch 5/64] [Batch 815/937] [D loss: 0.573716] [G loss: 0.823667]\n",
      "[Epoch 5/64] [Batch 915/937] [D loss: 0.613964] [G loss: 0.810576]\n",
      "[Epoch 6/64] [Batch 78/937] [D loss: 0.638729] [G loss: 0.854228]\n",
      "[Epoch 6/64] [Batch 178/937] [D loss: 0.659709] [G loss: 0.873513]\n",
      "[Epoch 6/64] [Batch 278/937] [D loss: 0.589739] [G loss: 0.924108]\n",
      "[Epoch 6/64] [Batch 378/937] [D loss: 0.566912] [G loss: 0.935711]\n",
      "[Epoch 6/64] [Batch 478/937] [D loss: 0.656313] [G loss: 1.006029]\n",
      "[Epoch 6/64] [Batch 578/937] [D loss: 0.606263] [G loss: 0.982432]\n",
      "[Epoch 6/64] [Batch 678/937] [D loss: 0.600053] [G loss: 0.872067]\n",
      "[Epoch 6/64] [Batch 778/937] [D loss: 0.670672] [G loss: 0.895797]\n",
      "[Epoch 6/64] [Batch 878/937] [D loss: 0.676128] [G loss: 0.777515]\n",
      "[Epoch 7/64] [Batch 41/937] [D loss: 0.662889] [G loss: 0.811891]\n",
      "[Epoch 7/64] [Batch 141/937] [D loss: 0.665352] [G loss: 0.834802]\n",
      "[Epoch 7/64] [Batch 241/937] [D loss: 0.650359] [G loss: 0.997271]\n",
      "[Epoch 7/64] [Batch 341/937] [D loss: 0.610018] [G loss: 0.851824]\n",
      "[Epoch 7/64] [Batch 441/937] [D loss: 0.632480] [G loss: 0.768380]\n",
      "[Epoch 7/64] [Batch 541/937] [D loss: 0.641325] [G loss: 0.867364]\n",
      "[Epoch 7/64] [Batch 641/937] [D loss: 0.619738] [G loss: 0.856713]\n",
      "[Epoch 7/64] [Batch 741/937] [D loss: 0.677477] [G loss: 0.780867]\n",
      "[Epoch 7/64] [Batch 841/937] [D loss: 0.628725] [G loss: 0.919132]\n",
      "[Epoch 8/64] [Batch 4/937] [D loss: 0.637372] [G loss: 0.809922]\n",
      "[Epoch 8/64] [Batch 104/937] [D loss: 0.652544] [G loss: 0.853084]\n",
      "[Epoch 8/64] [Batch 204/937] [D loss: 0.593728] [G loss: 0.828418]\n",
      "[Epoch 8/64] [Batch 304/937] [D loss: 0.611918] [G loss: 0.815793]\n",
      "[Epoch 8/64] [Batch 404/937] [D loss: 0.619958] [G loss: 0.875084]\n",
      "[Epoch 8/64] [Batch 504/937] [D loss: 0.667804] [G loss: 0.816899]\n",
      "[Epoch 8/64] [Batch 604/937] [D loss: 0.644473] [G loss: 0.783251]\n",
      "[Epoch 8/64] [Batch 704/937] [D loss: 0.633790] [G loss: 0.855222]\n",
      "[Epoch 8/64] [Batch 804/937] [D loss: 0.636359] [G loss: 0.819680]\n",
      "[Epoch 8/64] [Batch 904/937] [D loss: 0.626539] [G loss: 0.869603]\n",
      "[Epoch 9/64] [Batch 67/937] [D loss: 0.613181] [G loss: 0.842769]\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"./mlpgan\", exist_ok=True)\n",
    "for epoch in range(200):\n",
    "    for i, (real_imgs, _) in enumerate(dataloader):\n",
    "        \n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        real_imgs = real_imgs.cuda()\n",
    "        optimizer_G.zero_grad()\n",
    "        # Sample noise as generator input\n",
    "        ## 100 dim \n",
    "        z = torch.Tensor(np.random.normal(0, 1, (real_imgs.shape[0], 100))).cuda()\n",
    "        \n",
    "        # Generate a batch of images\n",
    "        ## generator \n",
    "        gen_imgs = generator(z) ## [batch, 100] -> [batch, 1, 28, 28]\n",
    "        \n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        ## generator loss -> bceloss \n",
    "        ## generator update\n",
    "        g_loss = adversarial_loss(\n",
    "            discriminator(gen_imgs), torch.ones((gen_imgs.shape[0], 1)).cuda()\n",
    "        )\n",
    "        \n",
    "        g_loss.backward() # compute gradiet\n",
    "        optimizer_G.step() # weight update\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        ### discriminator\n",
    "        ### bceloss -> \n",
    "        #D(x)\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        real_loss = adversarial_loss(\n",
    "            discriminator(real_imgs), torch.ones((gen_imgs.shape[0], 1)).cuda()\n",
    "        )\n",
    "        fake_loss = adversarial_loss(\n",
    "            discriminator(gen_imgs.detach()), torch.zeros((gen_imgs.shape[0], 1)).cuda()\n",
    "        )\n",
    "        d_loss = (real_loss + fake_loss)/2\n",
    "        \n",
    "        \n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        \n",
    "        if batches_done % 100 == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (epoch, 64, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "            )\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % 2000 == 0:\n",
    "            save_image(gen_imgs.data[:25], \"mlpgan/%d.png\" % batches_done, nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d542b-9180-401e-a5f3-57564121b102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e37e4f-2eaa-46ad-9fba-5aa956a3392f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
