{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YqkKav8O6Fh1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import os.path as osp\n",
    "import collections\n",
    "import PIL\n",
    "import imageio\n",
    "from distutils.version import LooseVersion\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Downloading dataset from google drive, 밑의 코드의 주석을 풀면 구글 드라이브로 부터 데이터셋 다운, 압축이 풀리고, Kitti라는 폴더가 생성됩니다. \n",
    "\n",
    "# !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=19EiycfOQtf6uDKvMgwlHZB50cAxX_U4z' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=19EiycfOQtf6uDKvMgwlHZB50cAxX_U4z\" -O Kitti.zip && rm -rf /tmp/cookies.txt\n",
    "# !mkdir Kitti\n",
    "# !unzip Kitti.zip -d Kitti\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsAFBC8X6Fh5"
   },
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "error",
     "timestamp": 1636096005436,
     "user": {
      "displayName": "Ji Ye Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05110516000762554458"
     },
     "user_tz": -540
    },
    "id": "TwA5VAjp6Fh7",
    "outputId": "24ad80d0-4595-45b5-b8c4-c7b3da462966",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgsets_file = osp.join('Kitti', '{}.txt'.format('train'))\n",
    "for line in open(imgsets_file):\n",
    "    line = line.strip()\n",
    "#     import pdb; pdb.set_trace()\n",
    "    print(line)\n",
    "    line = line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEEnAaqx6Fh8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KITTIdataset(torch.utils.data.Dataset):\n",
    "    class_names = np.array(['background', 'road'])\n",
    "\n",
    "    def __init__(self, root, transform, split='train'): # root: \"./Kitti\"\n",
    "        ## split에 맞는 txt파일 읽어서, \n",
    "        ## input image label image경로 리스트로 각각 저장\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        \n",
    "        self.images_path = []\n",
    "        self.ys = []\n",
    "        \n",
    "        imgsets_file = osp.join('Kitti', '{}.txt'.format(split)) # train, val\n",
    "        for line in open(imgsets_file):\n",
    "            #\"\\n\"\n",
    "            # line[0]: input image path, # line[1]: label image\n",
    "            #load image file\n",
    "            #load label file\n",
    "            self.images_path.append(img_file)\n",
    "            self.ys.append(lbl_file)\n",
    "            \n",
    "    def __len__(self):\n",
    "        ## length return\n",
    "        return len(self.ys)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        ## index에 맞는 image, label image읽어오기\n",
    "        # load image\n",
    "        \n",
    "        # load label\n",
    "        \n",
    "        ## black: 0, white: 255 255->1\n",
    "        ## 0, 1\n",
    "        \n",
    "        return self.transform(img), torch.from_numpy(lbl).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tK9bq2XB6Fh-",
    "outputId": "cd741c18-ad55-43f5-f783-f5def1c72ce4",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5))\n",
    "])\n",
    "train_dataset = KITTIdataset(root = './Kitti', split = 'train', transform = transform)\n",
    "val_dataset = KITTIdataset(root = './Kitti', split = 'val', transform = transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 1, shuffle = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_dataset[7][0].shape) ## [0]: img tensor, [1]: label tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOtKS8ll6Fh-"
   },
   "source": [
    "# Define the Network\n",
    "-VGG16\n",
    "\n",
    "- FCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# Maxpooling with ceil mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i4iwVXSB6FiA",
    "outputId": "32950bd8-0fd5-4a82-ec92-c732da2bde9e"
   },
   "outputs": [],
   "source": [
    "#Transposed convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KNXGDhv16Fh_"
   },
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self, num_class = 3):\n",
    "        super(FCN, self).__init__()\n",
    "        \n",
    "        ## conv1\n",
    "        \n",
    "        \n",
    "        ## conv2\n",
    "        \n",
    "        ## self.pool2\n",
    "        \n",
    "        ## conv3\n",
    "        \n",
    "        ### pool3\n",
    "        ## conv4\n",
    "        \n",
    "        ### pool4\n",
    "        \n",
    "        ## conv5\n",
    "        \n",
    "        ## pool 5\n",
    "        \n",
    "        ## upsampling transposed convolution\n",
    "        \n",
    "        self.params = [self.features1, self.features2, self.features3, \n",
    "                       self.features4, self.features5]\n",
    "        \n",
    "\n",
    "                             \n",
    "    def forward(self, inputs):\n",
    "        # input [Batch size, 3, w, h]\n",
    "\n",
    "        \n",
    "        ## channel num_class\n",
    "        \n",
    "        \n",
    "        return x ## label map [batch, num_class, inputs h, input w]\n",
    "    \n",
    "    def copy_params(self, vgg):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4PsFc39F6FiB",
    "outputId": "d707cc55-9778-4d17-96e5-be4f9bd11608"
   },
   "outputs": [],
   "source": [
    "# model = FCN(2)\n",
    "# # # print(model)\n",
    "# temp_input = torch.rand(1, 3, 1024, 1024)\n",
    "# output = model(temp_input)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtkrMy4C6FiC"
   },
   "source": [
    "## Measure accuracy and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5L8zp1sd6FiC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _fast_hist(label_true, label_pred, n_class):\n",
    "    ## define mask, histogram\n",
    "    ## hint : np.bincount\n",
    "    \n",
    "    return hist\n",
    "\n",
    "def compute_mean_iou(label_trues, label_preds, n_class): \n",
    "    # label_true: [h, w] # label_pred: [h, w] # n_class: 2\n",
    "    # TO DO : 각 Class 별 Intersection of Union을 계산\n",
    "        # Hint1 : _fast_hist를 통해 confusion matrix를 구할 수 있다. \n",
    "        # Hint2 : 해당 class의 True = confusion matrix의 해당 row 값의 합\n",
    "        #         해당 class의 Positive = confusion matrix의 해당 column 값의 합 \n",
    "        #         해당 class의 True_Positive = confusion matrix의 (class, class)의 값\n",
    "        # Hint3 : iou = True_Positive / True + Positive - True_Positive \n",
    "\n",
    "    return mean_iou\n",
    "\n",
    "def visualization(net, input_img, epoch):\n",
    "    ## TO DO : image를 network에 넣어 label을 추출\n",
    "    \n",
    "    os.makedirs(\"./pred\", exist_ok = True)\n",
    "    os.makedirs(\"./input\", exist_ok = True)\n",
    "    \n",
    "    imageio.imsave('./pred/mask_'+str(epoch+1)+'.png', lbl_pred)\n",
    "    plt.imshow(mpimg.imread('./pred/mask_'+str(epoch+1)+'.png'),cmap='gray') ### visualize predicted label map\n",
    "    plt.show()\n",
    "    input_img = np.array(input_img)\n",
    "    imageio.imsave('./input/input_'+str(epoch+1)+'.png', input_img)\n",
    "    plt.imshow(mpimg.imread('./input/input_'+str(epoch+1)+'.png'))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_true = np.array([\n",
    "    [1, 2],\n",
    "    [2, 3]\n",
    "])\n",
    "label_pred = np.array([\n",
    "    [1, 2],\n",
    "    [2, 2]\n",
    "])\n",
    "\n",
    "compute_mean_iou(label_true, label_pred, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ES9wHzU6FiD"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##load pretrained model from torchvision\n",
    "##pretrained using coco 2017\n",
    "net = torchvision.models.segmentation.fcn_resnet50(pretrained = True)\n",
    "# print(net)\n",
    "net.classifier = torchvision.models.segmentation.fcn.FCNHead( 2048, 2)\n",
    "net = net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16 = torchvision.models.vgg16(pretrained = True)\n",
    "# net = FCN(num_class = 2)\n",
    "# net.copy_params(vgg16)\n",
    "\n",
    "# net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-5, weight_decay = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zqey3Kju6FiD",
    "outputId": "33b61b31-74d3-48a5-9944-ac21804c9bfb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_epochs = 5\n",
    "best_iou = 0\n",
    "num_class = len(train_loader.dataset.class_names)\n",
    "j=0\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    net.train()\n",
    "    print ('current epoch : %d'%(epoch))\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # load data, forward\n",
    "        \n",
    "        \n",
    "        if batch_idx % 20 ==0:\n",
    "            print ('batch : {}, loss : {}'.format(batch_idx, loss.item()))\n",
    "        j += 1\n",
    "        \n",
    "    #validation\n",
    "    net.eval()\n",
    "    val_loss = 0\n",
    "    metrics = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            # load data, forward\n",
    "            \n",
    "            # calc val loss, accuracy\n",
    "            loss = criterion(score, target)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "           \n",
    "    val_loss /= len(val_loader)\n",
    "    metrics = np.mean(metrics)\n",
    "    \n",
    "    print ('val loss : {}, mean_iou : {}'.format(val_loss, metrics))\n",
    "\n",
    "    ##save model\n",
    "    if best_iou < metrics:\n",
    "        best_iou = metrics\n",
    "        print(\"Best model saved\")\n",
    "        torch.save(net.state_dict(), './model_best.pth')\n",
    "    \n",
    "    ## visualization\n",
    "    img = PIL.Image.open('./road_sample1.png')\n",
    "    visualization(net, img, epoch)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PIL.Image.open('./road_sample1.png')\n",
    "visualization(net, img, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "seg_kitti_ans.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
