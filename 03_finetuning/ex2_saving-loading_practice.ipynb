{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Save & Load Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define VGG11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "              ReLU-2           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-3           [-1, 64, 16, 16]               0\n",
      "            Conv2d-4          [-1, 128, 16, 16]          73,856\n",
      "              ReLU-5          [-1, 128, 16, 16]               0\n",
      "         MaxPool2d-6            [-1, 128, 8, 8]               0\n",
      "            Conv2d-7            [-1, 256, 8, 8]         295,168\n",
      "              ReLU-8            [-1, 256, 8, 8]               0\n",
      "            Conv2d-9            [-1, 256, 8, 8]         590,080\n",
      "             ReLU-10            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-11            [-1, 256, 4, 4]               0\n",
      "           Conv2d-12            [-1, 512, 4, 4]       1,180,160\n",
      "             ReLU-13            [-1, 512, 4, 4]               0\n",
      "           Conv2d-14            [-1, 512, 4, 4]       2,359,808\n",
      "             ReLU-15            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-16            [-1, 512, 2, 2]               0\n",
      "           Conv2d-17            [-1, 512, 2, 2]       2,359,808\n",
      "             ReLU-18            [-1, 512, 2, 2]               0\n",
      "           Conv2d-19            [-1, 512, 2, 2]       2,359,808\n",
      "             ReLU-20            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-21            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-22            [-1, 512, 7, 7]               0\n",
      "           Linear-23                 [-1, 4096]     102,764,544\n",
      "             ReLU-24                 [-1, 4096]               0\n",
      "          Dropout-25                 [-1, 4096]               0\n",
      "           Linear-26                 [-1, 4096]      16,781,312\n",
      "             ReLU-27                 [-1, 4096]               0\n",
      "          Dropout-28                 [-1, 4096]               0\n",
      "           Linear-29                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 132,863,336\n",
      "Trainable params: 132,863,336\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.94\n",
      "Params size (MB): 506.83\n",
      "Estimated Total Size (MB): 509.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "vgg = torchvision.models.vgg11(pretrained=False).to(device)\n",
    "summary (vgg, batch_size = -1, input_size = (3,32,32), device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG11(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=1000):\n",
    "        super().__init__()\n",
    "        self.conv1_1 = self.make_conv_relu(3, 64)\n",
    "        \n",
    "        self.conv2_1 = self.make_conv_relu(64, 128)\n",
    "\n",
    "        self.conv3_1 = self.make_conv_relu(128, 256)\n",
    "        self.conv3_2 = self.make_conv_relu(256, 256)\n",
    "\n",
    "        self.conv4_1 = self.make_conv_relu(256, 512)\n",
    "        self.conv4_2 = self.make_conv_relu(512, 512)\n",
    "\n",
    "        self.conv5_1 = self.make_conv_relu(512, 512)\n",
    "        self.conv5_2 = self.make_conv_relu(512, 512)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(512, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def make_conv_relu(self, in_channels, out_channel):\n",
    "        layers = []\n",
    "        layers += [nn.Conv2d(in_channels, out_channel, kernel_size=3, padding=1),  #using kernel size 3, padding 1 -> keep the spatial dimension of tensor\n",
    "                   nn.ReLU()]\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [Batchsize, 3, 32, 32]\n",
    "        \n",
    "        x = self.conv1_1(x) # [Batchsize, 64, 32, 32]\n",
    "        x = self.maxpool(x) # [Batchsize, 64, 16, 16]\n",
    "        \n",
    "        x = self.conv2_1(x) # [Batchsize, 128, 16, 16]\n",
    "        x = self.maxpool(x) # [Batchsize, 128, 8, 8]\n",
    "        \n",
    "        x = self.conv3_1(x) # [Batchsize, 256, 8, 8]\n",
    "        x = self.conv3_2(x) # [Batchsize, 256, 8, 8]\n",
    "        x = self.maxpool(x) # [Batchsize, 256, 4, 4]\n",
    "        \n",
    "        x = self.conv4_1(x) # [Batchsize, 512, 4, 4]\n",
    "        x = self.conv4_2(x) # [Batchsize, 512, 4, 4]\n",
    "        x = self.maxpool(x) # [Batchsize, 512, 2, 2]\n",
    "        \n",
    "        x = self.conv5_1(x) # [Batchsize, 512, 2, 2]\n",
    "        x = self.conv5_2(x) # [Batchsize, 512, 2, 2]\n",
    "        x = self.maxpool(x) # [Batchsize, 512, 1, 1]\n",
    "\n",
    "        x = x.view(x.size(0), -1) # [Batchsize, 512]\n",
    "        \n",
    "        x = self.linear_layers(x) # [Batchsize, num_classes]\n",
    "\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "              ReLU-2           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-3           [-1, 64, 16, 16]               0\n",
      "            Conv2d-4          [-1, 128, 16, 16]          73,856\n",
      "              ReLU-5          [-1, 128, 16, 16]               0\n",
      "         MaxPool2d-6            [-1, 128, 8, 8]               0\n",
      "            Conv2d-7            [-1, 256, 8, 8]         295,168\n",
      "              ReLU-8            [-1, 256, 8, 8]               0\n",
      "            Conv2d-9            [-1, 256, 8, 8]         590,080\n",
      "             ReLU-10            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-11            [-1, 256, 4, 4]               0\n",
      "           Conv2d-12            [-1, 512, 4, 4]       1,180,160\n",
      "             ReLU-13            [-1, 512, 4, 4]               0\n",
      "           Conv2d-14            [-1, 512, 4, 4]       2,359,808\n",
      "             ReLU-15            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-16            [-1, 512, 2, 2]               0\n",
      "           Conv2d-17            [-1, 512, 2, 2]       2,359,808\n",
      "             ReLU-18            [-1, 512, 2, 2]               0\n",
      "           Conv2d-19            [-1, 512, 2, 2]       2,359,808\n",
      "             ReLU-20            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-21            [-1, 512, 1, 1]               0\n",
      "           Linear-22                 [-1, 4096]       2,101,248\n",
      "             ReLU-23                 [-1, 4096]               0\n",
      "        Dropout2d-24                 [-1, 4096]               0\n",
      "           Linear-25                 [-1, 4096]      16,781,312\n",
      "             ReLU-26                 [-1, 4096]               0\n",
      "        Dropout2d-27                 [-1, 4096]               0\n",
      "           Linear-28                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 28,144,010\n",
      "Trainable params: 28,144,010\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.74\n",
      "Params size (MB): 107.36\n",
      "Estimated Total Size (MB): 110.11\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG11(10).to(device)\n",
    "summary(vgg, batch_size=-1, input_size=(3, 32, 32), device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## python dict type\n",
    "- key 와 value로 이루어진 datatype\n",
    "- torch의 weight는 key : layer 이름 과 value : weights 의 형태로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwonyoung\n"
     ]
    }
   ],
   "source": [
    "# dict_ex, print dict, show state_dict, weights for layer\n",
    "a = {'name': 'dongmin', 'age' : 26, 'list' : [] }\n",
    "a['name'] = 'kwonyoung'\n",
    "print(a['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name kwonyoung\n",
      "age 26\n",
      "list []\n"
     ]
    }
   ],
   "source": [
    "for k, v in a.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1_1.0.weight', 'conv1_1.0.bias', 'conv2_1.0.weight', 'conv2_1.0.bias', 'conv3_1.0.weight', 'conv3_1.0.bias', 'conv3_2.0.weight', 'conv3_2.0.bias', 'conv4_1.0.weight', 'conv4_1.0.bias', 'conv4_2.0.weight', 'conv4_2.0.bias', 'conv5_1.0.weight', 'conv5_1.0.bias', 'conv5_2.0.weight', 'conv5_2.0.bias', 'linear_layers.0.weight', 'linear_layers.0.bias', 'linear_layers.3.weight', 'linear_layers.3.bias', 'linear_layers.6.weight', 'linear_layers.6.bias'])\n",
      "torch.Size([64, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "state_dict = vgg.state_dict()\n",
    "print(state_dict.keys())\n",
    "weight = state_dict['conv1_1.0.weight']\n",
    "print(weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = vgg.to(device)\n",
    "vgg.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make checkpoints dir, save & load epoch 0 state_dict\n",
    "import os\n",
    "if not os.path.exists('check'):\n",
    "    os.makedirs('check')\n",
    "torch.save(vgg.state_dict(), 'check/vgg_epoch0.pth')\n",
    "dictionary = {'state_dict' : vgg.state_dict(),\n",
    "             'loss' : 1.0,\n",
    "             'epoch' : 10}\n",
    "torch.save(dictionary, 'check/test.pth')\n",
    "state_dict0 = torch.load('check/vgg_epoch0.pth')\n",
    "state_dict_test = torch.load('check/test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['state_dict', 'loss', 'epoch'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "782\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "# Loading and normalizing CIFAR-10\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #normalization value for cifar10\n",
    "    ])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                      download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                      download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vgg.parameters(), lr=0.001)\n",
    "\n",
    "print(len(trainloader))\n",
    "print(len(testloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.177\n",
      "[1,   200] loss: 1.175\n",
      "[1,   300] loss: 1.175\n",
      "[1,   400] loss: 1.117\n",
      "[1,   500] loss: 1.095\n",
      "[1,   600] loss: 1.080\n",
      "[1,   700] loss: 1.047\n",
      "[2,   100] loss: 0.978\n",
      "[2,   200] loss: 0.979\n",
      "[2,   300] loss: 0.995\n",
      "[2,   400] loss: 0.982\n",
      "[2,   500] loss: 0.980\n",
      "[2,   600] loss: 0.945\n",
      "[2,   700] loss: 0.905\n",
      "[3,   100] loss: 0.878\n",
      "[3,   200] loss: 0.837\n",
      "[3,   300] loss: 0.874\n",
      "[3,   400] loss: 0.845\n",
      "[3,   500] loss: 0.847\n",
      "[3,   600] loss: 0.845\n",
      "[3,   700] loss: 0.834\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "### Train the network\n",
    "vgg.to(device)\n",
    "vgg.train()\n",
    "epochs = 3\n",
    "for epoch in range(1, epochs+1):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # implement\n",
    "        # forward + backward + optimize + loss aggregate\n",
    "        optimizer.zero_grad()\n",
    "        outputs = vgg(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # print statistics\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                 (epoch, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    #save models\n",
    "    if epoch % 3 == 0:\n",
    "        torch.save(\n",
    "            {\n",
    "                'state_dict': vgg.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'running_loss' : running_loss\n",
    "            },\n",
    "            f'./check/vgg_epoch{epoch}.pth')\n",
    "    torch.save(vgg.state_dict(), f'./check/vgg_latest.pth')\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "vgg_before = VGG11(10)\n",
    "checkpoint = torch.load(\"./check/vgg_epoch1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_before.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1272, -0.0377, -0.0771],\n",
      "        [-0.0828, -0.1401,  0.0353],\n",
      "        [-0.1506,  0.1945,  0.1298]])\n",
      "tensor([[ 0.1399, -0.0530, -0.0927],\n",
      "        [-0.0767, -0.1372,  0.0416],\n",
      "        [-0.1508,  0.2058,  0.1322]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "state_dict_before = vgg_before.state_dict()\n",
    "state_dict_after = vgg.state_dict()\n",
    "\n",
    "print(state_dict_before['conv1_1.0.weight'][0,0])\n",
    "print(state_dict_after['conv1_1.0.weight'][0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
