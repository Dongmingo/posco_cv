{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG11(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=1000):\n",
    "        super().__init__()\n",
    "        self.conv1_1 = self.make_conv_relu(3, 64)\n",
    "        \n",
    "        self.conv2_1 = self.make_conv_relu(64, 128)\n",
    "\n",
    "        self.conv3_1 = self.make_conv_relu(128, 256)\n",
    "        self.conv3_2 = self.make_conv_relu(256, 256)\n",
    "\n",
    "        self.conv4_1 = self.make_conv_relu(256, 512)\n",
    "        self.conv4_2 = self.make_conv_relu(512, 512)\n",
    "\n",
    "        self.conv5_1 = self.make_conv_relu(512, 512)\n",
    "        self.conv5_2 = self.make_conv_relu(512, 512)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(512, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def make_conv_relu(self, in_channels, out_channel):\n",
    "        layers = []\n",
    "        layers += [nn.Conv2d(in_channels, out_channel, kernel_size=3, padding=1),  #using kernel size 3, padding 1 -> keep the spatial dimension of tensor\n",
    "                   nn.ReLU()]\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [Batchsize, 3, 32, 32]\n",
    "        \n",
    "        x = self.conv1_1(x) # [Batchsize, 64, 32, 32]\n",
    "        x = self.maxpool(x) # [Batchsize, 64, 16, 16]\n",
    "        \n",
    "        x = self.conv2_1(x) # [Batchsize, 128, 16, 16]\n",
    "        x = self.maxpool(x) # [Batchsize, 128, 8, 8]\n",
    "        \n",
    "        x = self.conv3_1(x) # [Batchsize, 256, 8, 8]\n",
    "        x = self.conv3_2(x) # [Batchsize, 256, 8, 8]\n",
    "        x = self.maxpool(x) # [Batchsize, 256, 4, 4]\n",
    "        \n",
    "        x = self.conv4_1(x) # [Batchsize, 512, 4, 4]\n",
    "        x = self.conv4_2(x) # [Batchsize, 512, 4, 4]\n",
    "        x = self.maxpool(x) # [Batchsize, 512, 2, 2]\n",
    "        \n",
    "        x = self.conv5_1(x) # [Batchsize, 512, 2, 2]\n",
    "        x = self.conv5_2(x) # [Batchsize, 512, 2, 2]\n",
    "        x = self.maxpool(x) # [Batchsize, 512, 1, 1]\n",
    "\n",
    "        x = x.view(x.size(0), -1) # [Batchsize, 512]\n",
    "        \n",
    "        x = self.linear_layers(x) # [Batchsize, num_classes]\n",
    "\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "              ReLU-2           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-3           [-1, 64, 16, 16]               0\n",
      "            Conv2d-4          [-1, 128, 16, 16]          73,856\n",
      "              ReLU-5          [-1, 128, 16, 16]               0\n",
      "         MaxPool2d-6            [-1, 128, 8, 8]               0\n",
      "            Conv2d-7            [-1, 256, 8, 8]         295,168\n",
      "              ReLU-8            [-1, 256, 8, 8]               0\n",
      "            Conv2d-9            [-1, 256, 8, 8]         590,080\n",
      "             ReLU-10            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-11            [-1, 256, 4, 4]               0\n",
      "           Conv2d-12            [-1, 512, 4, 4]       1,180,160\n",
      "             ReLU-13            [-1, 512, 4, 4]               0\n",
      "           Conv2d-14            [-1, 512, 4, 4]       2,359,808\n",
      "             ReLU-15            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-16            [-1, 512, 2, 2]               0\n",
      "           Conv2d-17            [-1, 512, 2, 2]       2,359,808\n",
      "             ReLU-18            [-1, 512, 2, 2]               0\n",
      "           Conv2d-19            [-1, 512, 2, 2]       2,359,808\n",
      "             ReLU-20            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-21            [-1, 512, 1, 1]               0\n",
      "           Linear-22                 [-1, 4096]       2,101,248\n",
      "             ReLU-23                 [-1, 4096]               0\n",
      "        Dropout2d-24                 [-1, 4096]               0\n",
      "           Linear-25                 [-1, 4096]      16,781,312\n",
      "             ReLU-26                 [-1, 4096]               0\n",
      "        Dropout2d-27                 [-1, 4096]               0\n",
      "           Linear-28                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 28,144,010\n",
      "Trainable params: 28,144,010\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.74\n",
      "Params size (MB): 107.36\n",
      "Estimated Total Size (MB): 110.11\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG11(10)\n",
    "summary(vgg, batch_size=-1, input_size=(3, 32, 32), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict, print dict, show state_dict, weights for layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec41bb2c45245aa8d010c46c301de89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "782\n"
     ]
    }
   ],
   "source": [
    "# Loading and normalizing CIFAR-10\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #normalization value for cifar10\n",
    "    ])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                      download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                      download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vgg.parameters(), lr=0.001)\n",
    "\n",
    "print(len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make checkpoints dir, save & load epoch 0 state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.184\n",
      "[1,   200] loss: 0.227\n",
      "[1,   300] loss: 0.218\n",
      "[1,   400] loss: 0.218\n",
      "[1,   500] loss: 0.236\n",
      "[1,   600] loss: 0.274\n",
      "[1,   700] loss: 0.271\n",
      "[2,   100] loss: 0.157\n",
      "[2,   200] loss: 0.207\n",
      "[2,   300] loss: 0.192\n",
      "[2,   400] loss: 0.204\n",
      "[2,   500] loss: 0.216\n",
      "[2,   600] loss: 0.255\n",
      "[2,   700] loss: 0.231\n",
      "[3,   100] loss: 0.229\n",
      "[3,   200] loss: 0.302\n",
      "[3,   300] loss: 0.218\n",
      "[3,   400] loss: 0.197\n",
      "[3,   500] loss: 0.186\n",
      "[3,   600] loss: 0.186\n",
      "[3,   700] loss: 0.248\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "### Train the network\n",
    "vgg.to(device)\n",
    "vgg.train()\n",
    "epochs = 3\n",
    "for epoch in range(1, epochs+1):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = vgg(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # print statistics\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                 (epoch, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    #save models\n",
    "    ##implement this\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            'state_dict': vgg.state_dict(),\n",
    "            'epoch': epoch\n",
    "        },\n",
    "        f'./checkpoints/vgg_epoch{epoch}.pth')\n",
    "    torch.save(vgg.state_dict(), f'./checkpoints/vgg_latest.pth')\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "vgg_before = VGG11(10)\n",
    "checkpoint = torch.load(\"./checkpoints/vgg_epoch1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_before.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1728,  0.0857,  0.1240],\n",
      "        [-0.0612,  0.0833,  0.0636],\n",
      "        [ 0.1286, -0.0822, -0.0512]])\n",
      "tensor([[ 0.1859,  0.0803,  0.1145],\n",
      "        [-0.0714,  0.0772,  0.0620],\n",
      "        [ 0.1085, -0.1160, -0.0756]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "state_dict_before = vgg_before.state_dict()\n",
    "state_dict_after = vgg.state_dict()\n",
    "\n",
    "print(state_dict_before['conv1_1.0.weight'][0,0])\n",
    "print(state_dict_after['conv1_1.0.weight'][0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
