{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9311e8d0-50bc-4f08-8d9d-1f1e19373699",
   "metadata": {},
   "source": [
    "# Local self-attention (practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad09cca0-c6be-4a27-9ff2-36446fd85f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch.nn.modules.linear import Linear\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfec9c4-f731-48b8-af8c-3b19f6e29bd0",
   "metadata": {},
   "source": [
    "### unfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba81c2b-599a-496f-991e-ced2637f6ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfold = nn.Unfold(kernel_size=(2, 3))\n",
    "B, C, H, W = 2, 4, 5, 6\n",
    "K = 3\n",
    "\n",
    "x = torch.randn(B, C, H, W)\n",
    "out = x.unfold(2, K, 1)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64ba1ee-4a22-4e4d-9567-7e6424cd0f78",
   "metadata": {},
   "source": [
    "## LocalSelfAttention module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad747fc-e532-4096-8842-0476dece7d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalSelfAttention(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding=0, bias=False):\n",
    "        super(LocalSelfAttention, self).__init__()\n",
    "        # in-class implementation\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        \n",
    "        # define projection layers\n",
    "        # (step 1) query projection layer (linear layer with a sliding window)\n",
    "        \n",
    "        # (step 2) key projection layer (linear layer with a sliding window)\n",
    "        \n",
    "        # (step 3) value projection layer (linear layer with a sliding window)\n",
    "        \n",
    "        assert out_channels % 2 == 0\n",
    "        \n",
    "        # define learnable relative positional encodings\n",
    "        # (step 4) positional encoding in height direction\n",
    "        \n",
    "            # self.rel = nn.Parameter(torch.randn(out_channels, 1, 1, 1, 1), requires_grad=True)\n",
    "        # (step 5) positional encoding in width direction\n",
    "        \n",
    "        # Hint: initialize the positional encoding with normal distribution. torch.randn\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # in-class implementation\n",
    "        batch, channels, height, width = x.size()\n",
    "        \n",
    "        # define pad\n",
    "        # q_out : (B, C, H, W)\n",
    "        # k_out : (B, C, H + padding, W + padding)\n",
    "        # v_out : (B, C, H + padding, W + padding)\n",
    "\n",
    "        # k_out: (B, C, H, W, K, K)\n",
    "        # k_out[:, :, :, :, 0, 0]\n",
    "        \n",
    "        # k_out_h: (B, C//2, H, W, K, K)\n",
    "        # self.rel_h: (C//2, 1, 1, K, 1), self.rel_w: (C//2, 1, 1, 1, K)\n",
    "        \n",
    "        # k_out = k_out + self.rel\n",
    "        # (B, C, H, W, K, K)\n",
    "        \n",
    "        # reshape k_out : (B, C, H, W, K*K)\n",
    "        # reshape v_out : (B, C, H, W, K*K)\n",
    "        \n",
    "        # reshape q_out : (B, C, H, W, 1)\n",
    "        # (B, C, H, W, K*K)\n",
    "        # scaling\n",
    "        # v_out: (B, C, H, W, K*K)\n",
    "        # out: (B, C, H, W, K*K)\n",
    "        \n",
    "        # out.shape == (B, C, H, W)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cbe818-c80a-4b79-8dc8-ceb198d218dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, C, H, W = 2, 4, 5, 6\n",
    "layer = LocalSelfAttention(C, C**2, kernel_size=3, padding=1)\n",
    "x = torch.randn((B, C, H, W))\n",
    "out = layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc52c90-c352-4624-8693-85fe6d08b54e",
   "metadata": {},
   "source": [
    "## Simple Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a00ad9-0eac-4575-ab40-6de39bc95206",
   "metadata": {},
   "source": [
    "### Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7bfab5-0a1c-46e6-9d2e-d5667d863390",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(SimpleBlock, self).__init__()\n",
    "        # in-class implementation: attn -> residual connection -> relu -> output\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # in-class implementation\n",
    "        # if stride > 1, using avg_pool2d\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe85fb59-8856-4074-942c-d740e2839516",
   "metadata": {},
   "source": [
    "### Simple Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa158c9-1458-4a1f-8f33-91bf11b66b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.net = nn.Sequential(\n",
    "            SimpleBlock(16, 16, stride=2),\n",
    "            SimpleBlock(16, 16, stride=2),\n",
    "            SimpleBlock(16, 16, stride=2),\n",
    "            SimpleBlock(16, 32, stride=2) # 1/16\n",
    "        )\n",
    "        self.classifier = nn.Linear(32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # (B, 3, 224, 224)\n",
    "        out = self.stem(x)\n",
    "        out = self.net(out) # (B, 32, 14, 14)\n",
    "        out = F.avg_pool2d(out, 14)\n",
    "        out = out.view(out.size(0), -1) # (B, 32)\n",
    "        out = self.classifier(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c37de2-d3e6-4657-9719-8622070f92b1",
   "metadata": {},
   "source": [
    "### Load Train, Test Dataset and Define Train, Test Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaadf1eb-cca4-4437-9d7e-3c3a9f7f9264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and normalizing CIFAR-10\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Resize(224),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                      download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                      download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=2,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "print(len(trainset))\n",
    "print(len(testset))\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e350b120-76b2-4042-9996-86b530634640",
   "metadata": {},
   "source": [
    "### For Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e217f1d-8d77-443e-a9ef-1c639dd78d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display some images\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d597cb1-ede6-4374-83e7-5186c69ad23c",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315dc896-0eb5-4de0-a41c-f6d920709afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\"\n",
    "x = torch.randn(2,3,224,224).to(device)\n",
    "model = SimpleNet(3, 10).to(device)\n",
    "output = model(x)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2731b7fa-ea90-4d1f-a54a-5afbfdb1b99b",
   "metadata": {},
   "source": [
    "### Define Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5265c48a-5f6a-4804-971d-8890e136f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# define a loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8671c7cb-adfd-4349-994a-415488d48dec",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ad83a-ae07-4051-af5e-00c481ab4b9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Train the network\n",
    "print('Start Training ')\n",
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # Fill this loop\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # print statistics\n",
    "        if i % 50 == 0:\n",
    "            print('[%d, %5d] loss: %.6f' %\n",
    "                 (epoch + 1, i + 1, running_loss / 500))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17d6eb1-3dea-4560-a304-50532e4b6a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "#print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GrondTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce4c2f9-e5c8-45a7-a0d8-6c7f758fe6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.to(device)\n",
    "outputs = model(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(2))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
