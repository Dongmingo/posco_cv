{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  IoU & NMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import pickle\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "### Funtion for visualization\n",
    "def draw_bb(img, boxes, color='r'):\n",
    "    fig,ax = plt.subplots(1)\n",
    "    for box in boxes:\n",
    "        rect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],linewidth=3,edgecolor=color,facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    ax.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "### Fuction for vislualize bounding with two differnt colors\n",
    "def draw_bb2(img, boxes1, boxes2, color1='r', color2='g'):\n",
    "    fig,ax = plt.subplots(1)\n",
    "    for box in boxes1:\n",
    "        rect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],linewidth=3,edgecolor=color1,facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    for box in boxes2:\n",
    "        rect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],linewidth=3,edgecolor=color2,facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    ax.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PASCAL VOC2007 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PASCAL_DATASET(data.Dataset):\n",
    "    def __init__(self, data_root, img_list_file):        \n",
    "        self.data_root = data_root        \n",
    "        self.img_list = []\n",
    "        self._load_img_name_list(img_list_file)               \n",
    "\n",
    "    def _load_img_name_list(self, img_list_file):\n",
    "        with open(img_list_file) as f:\n",
    "            self.img_list = f.read().splitlines()\n",
    "                                  \n",
    "    def _load_annotation(self, img_path):\n",
    "        filename = os.path.join(self.data_root, 'Annotations', img_path + '.xml')\n",
    "        tree = ET.parse(filename)\n",
    "        objs = tree.findall('object')\n",
    "        num_objs = len(objs)\n",
    "        boxes = np.zeros((num_objs, 4), dtype=np.int32)\n",
    "        gt_classes_str = []\n",
    "        \n",
    "        for ix, obj in enumerate(objs):\n",
    "            bbox = obj.find('bndbox')\n",
    "            # Make pixel indexes 0-based\n",
    "            x1 = float(bbox.find('xmin').text) - 1\n",
    "            y1 = float(bbox.find('ymin').text) - 1\n",
    "            x2 = float(bbox.find('xmax').text) - 1\n",
    "            y2 = float(bbox.find('ymax').text) - 1\n",
    "            gt_classes_str.append(obj.find('name').text)\n",
    "            boxes[ix, :] = [x1, y1, x2, y2]\n",
    "\n",
    "        return boxes, gt_classes_str\n",
    "                                      \n",
    "    def __len__(self,):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_list[index]\n",
    "        img = Image.open(os.path.join(self.data_root, 'JPEGImages', img_path + '.jpg'))\n",
    "        boxes, gt_classes_str = self._load_annotation(img_path)\n",
    "        return img, boxes, gt_classes_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal_data = PASCAL_DATASET(data_root='./VOC2007/',img_list_file='./VOC2007/ImageSets/Main/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal_it = iter(pascal_data)\n",
    "img, gt_boxes, gt_box_classes = next(pascal_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bb(img, gt_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate IoU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Our ground truth box\n",
    "print(gt_boxes)\n",
    "print(gt_boxes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assume we have following predictions from network\n",
    "predicted_boxes = np.zeros((4, 4), dtype=np.int32)\n",
    "predicted_boxes[0, :] = [100, 80, 320, 240]\n",
    "predicted_boxes[1, :] = [50, 40, 160, 120]\n",
    "predicted_boxes[2, :] = [200, 150, 300, 300]\n",
    "predicted_boxes[3, :] = [250, 50, 450, 250]\n",
    "predicted_scores = np.array([0.9, 0.8, 0.7, 0.6])\n",
    "print(predicted_boxes)\n",
    "print(predicted_boxes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bb2(img, gt_boxes, predicted_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert to pytorch tensors\n",
    "gt_boxes = torch.from_numpy(gt_boxes).float()\n",
    "predicted_boxes = torch.from_numpy(predicted_boxes).float()\n",
    "predicted_scores = torch.from_numpy(predicted_scores).float()\n",
    "print(predicted_boxes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Returns the IoU of two bounding boxes \n",
    "    box 1 : (1, 4) shaped pytorch tensors - sinlge GT bounding box\n",
    "    box 2 : (N, 4) shaped pytorch tensors - multiple predictions from network\n",
    "    \"\"\"\n",
    "    b1_x1, b1_y1, b1_x2, b1_y2 = box1[:,0], box1[:,1], box1[:,2], box1[:,3]\n",
    "    b2_x1, b2_y1, b2_x2, b2_y2 = box2[:,0], box2[:,1], box2[:,2], box2[:,3]\n",
    "    \n",
    "    ## intersection rectangle coordinate\n",
    "    inter_rect_x1 = torch.max(b1_x1, b2_x1)\n",
    "    inter_rect_y1 = torch.max(b1_y1, b2_y1)\n",
    "    inter_rect_x2 = torch.min(b1_x2, b2_x2)\n",
    "    inter_rect_y2 = torch.min(b1_y2, b2_y2)\n",
    "    \n",
    "    ## practice\n",
    "    inter_area = torch.clamp(inter_rect_x2-inter_rect_x1, min=0.)\\\n",
    "            * torch.clamp(inter_rect_y2-inter_rect_y1, min=0.)\n",
    "                 \n",
    "    \n",
    "    ## calculate iou\n",
    "    area_1 = (b1_x2-b1_x1) * (b1_y2-b1_y1)\n",
    "    area_2 = (b2_x2-b2_x1) * (b2_y2-b2_y1)\n",
    "    iou = inter_area/(area_1+area_2-inter_area)\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get iou score for each prediction boxes\n",
    "ious = bbox_iou(gt_boxes, predicted_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ious)\n",
    "print(predicted_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Threshold bounding boxes based on IoU scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "th = np.where(ious.numpy() > threshold)\n",
    "th_boxes = predicted_boxes[th]\n",
    "draw_bb2(img, gt_boxes, th_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "th = np.where(ious.numpy() > threshold)\n",
    "th_boxes = predicted_boxes[th]\n",
    "draw_bb2(img, gt_boxes, th_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Non-maximum suppression (NMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(boxes, scores, threshold):\n",
    "    \"\"\"\n",
    "    boxes: (N, 4), each row-> (x1, y1, x2, y2), x2 > x1, y2 > y1\n",
    "    scores: (N,), each value in [0, 1]\n",
    "    threshold: iou threshold\n",
    "    \"\"\"\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    \n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "    order = scores.argsort()\n",
    "    \n",
    "    keep = []\n",
    "    \n",
    "    while len(order) > 0:\n",
    "        # the index with the highest score.\n",
    "        idx = order[-1]\n",
    "        # keep it.\n",
    "        keep.append(boxes[idx])\n",
    "        # remove the index from the candidate list.\n",
    "        order = order[:-1]\n",
    "        \n",
    "        if len(order) == 0:\n",
    "            break # check\n",
    "        \n",
    "        # order bounding boxes according to the order.\n",
    "        xx1 = x1[order]\n",
    "        xx2 = x2[order]\n",
    "        yy1 = y1[order]\n",
    "        yy2 = y2[order]\n",
    "        \n",
    "        # intersection coordinate\n",
    "        ix1 = torch.max(xx1, boxes[idx, 0])\n",
    "        iy1 = torch.max(yy1, boxes[idx, 1])\n",
    "        ix2 = torch.min(xx2, boxes[idx, 2])\n",
    "        iy2 = torch.min(yy2, boxes[idx, 3])\n",
    "        \n",
    "        # width and height of the intesection, calculate intersection\n",
    "        w = torch.clamp(ix2-ix1, min=0.)\n",
    "        h = torch.clamp(iy2-iy1, min=0.)\n",
    "        \n",
    "        inter = w*h\n",
    "        rem_areas = areas[order] + areas[idx] - 2*inter\n",
    "        union = rem_areas + inter\n",
    "        iou = inter / union\n",
    "        \n",
    "        # keep the boxes with iou less than threshold\n",
    "        order = order[iou<threshold]\n",
    "        \n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bb(img, predicted_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms_boxes = nms(predicted_boxes, predicted_scores, 0.2)\n",
    "print(nms_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bb(img, torch.vstack(nms_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
