{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c389010f-54b5-466c-a2a6-eacd542094c4",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "---\n",
    "## Tensors\n",
    "* Tensorflow의 Tensor와 다르지 않다.\n",
    "  * Numpy의 ndarrays를 기본적으로 활용하고 있다.\n",
    "  * Numpy의 ndarrays의 대부분의 operation을 사용할 수 있도록 구성되어 있다.\n",
    "* Numpy의 operation은 CPU만을 이용해 느리지만 Tensor는 CUDA를 활용해 GPU를 이용하기 때문에 빠르게 연산을 진행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "297b1820-8514-4b77-a3f1-e2d436303ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5b44208-3d0f-4902-ae96-60406c17ea2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 17 00:54:13 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:18:00.0 Off |                  N/A |\n",
      "| 41%   32C    P8    14W / 280W |      3MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 40%   32C    P8    16W / 280W |    824MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:D8:00.0 Off |                  N/A |\n",
      "| 41%   32C    P8    15W / 280W |      3MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c3da022-af25-4f50-9443-75df3f7512ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(10000,100000).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c36e03-a7e6-4e7f-a8a5-dae21a88ffa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 17 00:54:26 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:18:00.0 Off |                  N/A |\n",
      "| 40%   35C    P2    56W / 280W |   4514MiB / 24220MiB |     22%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 41%   32C    P8    16W / 280W |    824MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:D8:00.0 Off |                  N/A |\n",
      "| 40%   32C    P8    14W / 280W |      3MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d1259f-0df0-457b-9716-ee1755367b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4391.697265625"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype\n",
    "1000000000/1024/1024*4 + 577"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34cf77bd-455d-49ab-9afc-429d19ef0b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4013e-45,  0.0000e+00,  1.0825e+38],\n",
      "        [ 3.0805e-41,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  3.3631e-44],\n",
      "        [ 4.5622e-41, -1.0658e+11,  4.5622e-41],\n",
      "        [ 1.4013e-45,  0.0000e+00,  7.0625e-43]])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5,3)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.size())\n",
    "print(x.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "452592b7-d4e6-4e50-aec7-3af1f842e3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Construct a matrix with the list\n",
    "x = torch.tensor([[0,1,2],[3,4,5]])\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdbff714-6f3c-449c-820e-49e611bba7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6).reshape(2,3)\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c37d8ed-da8c-4273-8bcb-52e86be22c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6128, 0.3909, 0.1892],\n",
      "        [0.2209, 0.6444, 0.2064],\n",
      "        [0.8283, 0.5554, 0.7367],\n",
      "        [0.1333, 0.0658, 0.5253],\n",
      "        [0.3632, 0.4416, 0.1197]])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Construct a randomly initialized matrix \n",
    "x = torch.rand(5, 3) # np.random.rand\n",
    "print(x)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7223f7c8-72be-471e-afca-ab170dfab290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0844e+38, 3.0805e-41],\n",
      "        [1.1518e-03, 3.0805e-41, 9.4018e-30],\n",
      "        [4.5622e-41, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "tensor([[0.0262, 0.6635, 0.4867],\n",
      "        [0.9307, 0.9751, 0.4217],\n",
      "        [0.7110, 0.9057, 0.9989],\n",
      "        [0.7970, 0.6095, 0.8732],\n",
      "        [0.0198, 0.3319, 0.6648]])\n",
      "torch.float32\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Construct a 5 x 3 matrix, uninitialized (random initialized)\n",
    "x = torch.Tensor(5, 3)\n",
    "print(x)\n",
    "\n",
    "# Construct a randomly initialized matrix \n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "# Construct a matrix with the list\n",
    "x = torch.tensor([[3.5, 4, 5], [1, 2, 3]])\n",
    "print(x.dtype)\n",
    "\n",
    "# Get its size\n",
    "print(x.size())\n",
    "print(x.shape)\n",
    "\n",
    "# Get its grad\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1504510d-ed37-4525-adee-5983f23eaf1c",
   "metadata": {},
   "source": [
    "### dtype and device \n",
    " * dtype - Tensor의 데이터 타입\n",
    " * device - Tensor의 작업 위치 (cpu or cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "975a0d9b-5943-41a0-8bfd-bff0d45599c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4., 5.],\n",
      "        [1., 2., 3.]], dtype=torch.float64)\n",
      "tensor([[3, 4, 5],\n",
      "        [1, 2, 3]], dtype=torch.int32)\n",
      "tensor([[ 6.,  8., 10.],\n",
      "        [ 2.,  4.,  6.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[3, 4, 5], [1, 2, 3]], dtype=torch.float64)\n",
    "print(x)\n",
    "\n",
    "y = torch.tensor([[3, 4, 5], [1, 2, 3]], dtype=torch.int)\n",
    "print(y)\n",
    "\n",
    "\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d29dfafb-e3ee-4f29-b60f-a3613837141b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4., 5.],\n",
      "        [1., 2., 3.]])\n",
      "torch.float32\n",
      "tensor([[3., 4., 5.],\n",
      "        [1., 2., 3.]], dtype=torch.float64)\n",
      "tensor([[ 6.,  8., 10.],\n",
      "        [ 2.,  4.,  6.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[3, 4, 5], [1, 2, 3]], dtype=torch.float32)\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "y = x.double()\n",
    "print(y)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77aee205-9bfe-48d1-90ec-ee61780cb986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:0\n",
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[3, 4, 5], [1, 2, 3]], dtype=torch.float32)\n",
    "print(x.device)\n",
    "x = x.to(torch.device('cuda'))\n",
    "print(x.device)\n",
    "x = x.to(torch.device('cuda:1'))\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "226db5ba-8737-4738-8b88-c6915c69ff43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "x = x.cuda()\n",
    "print(x.device)\n",
    "x = x.cpu()\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f83bf72c-f5b6-4919-ad94-dfcc8ce4c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5733e0bc-168b-4626-b45b-27c66cdb21d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before \"to\" method\n",
      "torch.float64 cpu\n",
      "torch.float32 cpu\n",
      "torch.int32 cuda:1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "device_0 = torch.device('cuda:0')\n",
    "device_1 = torch.device('cuda:1')\n",
    "\n",
    "x = torch.randn(4, 3, dtype=torch.float64)\n",
    "y = torch.randn(4, 3, dtype=torch.float32)\n",
    "z = torch.randint(0, 10, (4, 3), dtype=torch.int32)\n",
    "\n",
    "z = z.to(device_1)\n",
    "\n",
    "print('Before \"to\" method')\n",
    "\n",
    "print(x.dtype, x.device)\n",
    "print(y.dtype, y.device)\n",
    "print(z.dtype, z.device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83b0a670-bb28-4bd0-b9c7-770be69ca39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After \"to\" method\n",
      "torch.int32 cuda:0\n",
      "torch.int32 cuda:1\n",
      "torch.int32 cpu \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('After \"to\" method')\n",
    "# to method with specific dtype and device \n",
    "x = x.to(dtype=torch.int32, device=device_0)\n",
    "\n",
    "# to method with some tensor \n",
    "y = y.to(z)\n",
    "z = z.to(device='cpu')\n",
    "\n",
    "print(x.dtype, x.device)\n",
    "print(y.dtype, y.device)\n",
    "print(z.dtype, z.device, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3359e8a9-c23e-44bb-98da-b25fc6fa3dec",
   "metadata": {},
   "source": [
    "### Constructing like Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d27d60a-ad76-4a4b-9ff7-563aadc213ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.4923e+10,  4.5622e-41, -7.4923e+10,  4.5622e-41,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.6217e-19],\n",
      "        [ 7.7052e+31,  7.2148e+22,  2.5226e-18,  1.0372e-08,  1.0356e-11]])\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "tensor([[3.1415, 3.1415, 3.1415, 3.1415, 3.1415],\n",
      "        [3.1415, 3.1415, 3.1415, 3.1415, 3.1415],\n",
      "        [3.1415, 3.1415, 3.1415, 3.1415, 3.1415]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3, 5)\n",
    "print(x)\n",
    "\n",
    "x = torch.zeros(3, 5)\n",
    "print(x)\n",
    "\n",
    "x = torch.ones(3, 5)\n",
    "print(x)\n",
    "\n",
    "x = torch.full((3, 5), 3.1415)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17e29664-3ccb-4e21-bce4-b2e44b9e9666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n",
      "tensor([0.0000, 0.6250, 1.2500, 1.8750, 2.5000, 3.1250, 3.7500, 4.3750, 5.0000])\n",
      "tensor([1.0000e-10, 1.0000e-05, 1.0000e+00, 1.0000e+05, 1.0000e+10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 5, 1)\n",
    "x = torch.arange(5)\n",
    "print(x)\n",
    "\n",
    "y = torch.linspace(0, 5, 9)\n",
    "print(y)\n",
    "\n",
    "z = torch.logspace(-10, 10, 5)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e5ba788-b5fa-4a65-b585-11fa55191d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.eye(5) # I: Identity Matrix\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "162fb8d3-fd50-4ce2-9509-b829b8e80137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2673, 0.8408, 0.9023, 0.8138, 0.2728],\n",
      "        [0.0783, 0.4564, 0.1266, 0.1114, 0.2190],\n",
      "        [0.1715, 0.1478, 0.2119, 0.4236, 0.1932]])\n",
      "tensor([[ 1.6780, -0.7488, -1.1527, -1.4136, -0.2482],\n",
      "        [-0.2041,  0.1943,  0.4597, -0.2457, -0.2182],\n",
      "        [ 0.1025, -0.1163, -1.6372, -1.3694,  0.5092]])\n",
      "tensor([[8, 5, 9, 7, 7],\n",
      "        [5, 8, 9, 8, 6],\n",
      "        [5, 4, 3, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# Construct a 3 x 5 matrix with random value from uniform distribution, i.e. Uniform[0, 1)\n",
    "x = torch.rand(3, 5)\n",
    "print(x)\n",
    "\n",
    "# Construct a 3 x 5 matrix with random value from normal distribution, i.e. Normal(0, 1)\n",
    "x = torch.randn(3, 5)\n",
    "print(x)\n",
    "\n",
    "x = torch.randint(3, 10, (3, 5))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a46dd8-f977-4de4-b2c4-bc33e32fd337",
   "metadata": {},
   "source": [
    "- From numpy to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8ac2af0-4aad-4635-b10a-a955efd375c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "cpu\n",
      "cpu\n",
      "torch.float64\n",
      "torch.float32\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      " [1. 1. 1. 1. 1.] \n",
      " tensor([1., 1., 1., 1., 1.], dtype=torch.float64) \n",
      " tensor([1., 1., 1., 1., 1.]) \n",
      " [1. 1. 1. 1. 1.] \n",
      " [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "print(a)\n",
    "b = torch.from_numpy(a)\n",
    "c = torch.Tensor(a)\n",
    "print(b.device)\n",
    "print(c.device)\n",
    "print(b.dtype)\n",
    "print(c.dtype)\n",
    "d = b.numpy()\n",
    "e = np.array(b)\n",
    "print(type(d))\n",
    "print(\"\\n\",a,\"\\n\",b,\"\\n\",c,\"\\n\",d,\"\\n\",e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193ac068-f243-45ae-8ff7-32b00851bd67",
   "metadata": {},
   "source": [
    "### Operations\n",
    "* Operations에도 여러가지 syntax가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fbb8bfd-9b4f-47b9-a6f6-ba1d3a30a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5, 3)\n",
    "y = torch.rand(1, 3)\n",
    "x = x + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e7bd51b-da0b-46e8-ace1-86e4b939e69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.9962, 3.8651, 4.7598],\n",
      "        [4.0251, 4.0541, 4.9596],\n",
      "        [3.9308, 3.6283, 4.3541],\n",
      "        [4.1426, 4.3848, 4.4948],\n",
      "        [3.5530, 4.4659, 4.1304]])\n"
     ]
    }
   ],
   "source": [
    "posco = x + y\n",
    "print(posco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee7b63f6-a855-4025-a123-3566e87c6d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution 1 :  tensor([[0.5726, 1.1181, 1.6126],\n",
      "        [1.0247, 0.9161, 1.4150],\n",
      "        [1.3466, 1.2237, 0.8758],\n",
      "        [0.9720, 1.1149, 0.9213],\n",
      "        [0.1841, 0.5973, 1.3159]]) \n",
      "\n",
      "solution 2 :  tensor([[0.5726, 1.1181, 1.6126],\n",
      "        [1.0247, 0.9161, 1.4150],\n",
      "        [1.3466, 1.2237, 0.8758],\n",
      "        [0.9720, 1.1149, 0.9213],\n",
      "        [0.1841, 0.5973, 1.3159]]) \n",
      "\n",
      "solution 3 :  tensor([[0.5726, 1.1181, 1.6126],\n",
      "        [1.0247, 0.9161, 1.4150],\n",
      "        [1.3466, 1.2237, 0.8758],\n",
      "        [0.9720, 1.1149, 0.9213],\n",
      "        [0.1841, 0.5973, 1.3159]]) \n",
      "\n",
      "solution 4 :  tensor([[0.5726, 1.1181, 1.6126],\n",
      "        [1.0247, 0.9161, 1.4150],\n",
      "        [1.3466, 1.2237, 0.8758],\n",
      "        [0.9720, 1.1149, 0.9213],\n",
      "        [0.1841, 0.5973, 1.3159]]) \n",
      "\n",
      "tensor([[0.8928, 1.4121, 2.4509],\n",
      "        [1.2309, 1.7260, 1.8501],\n",
      "        [2.1298, 1.6512, 1.4808],\n",
      "        [1.2215, 1.3166, 1.8186],\n",
      "        [0.3602, 0.6176, 1.8764]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "y = torch.rand(5, 3)\n",
    "print(\"solution 1 : \", x + y, '\\n')\n",
    "\n",
    "\n",
    "print(\"solution 2 : \", torch.add(x, y), '\\n')\n",
    "\n",
    "\n",
    "result = torch.Tensor(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(\"solution 3 : \", result, '\\n')\n",
    "\n",
    "y.add_(x) # y = y + x\n",
    "print(\"solution 4 : \", y, '\\n')\n",
    "\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa09981-859a-4c4e-9e93-571126abd8dd",
   "metadata": {},
   "source": [
    "### Same indexing as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33699044-394b-4e46-b101-9b766aadb33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3203, 0.2940, 0.8383],\n",
      "        [0.2062, 0.8099, 0.4351],\n",
      "        [0.7832, 0.4274, 0.6050],\n",
      "        [0.2496, 0.2018, 0.8973],\n",
      "        [0.1761, 0.0203, 0.5605]])\n",
      "tensor([[0.2940],\n",
      "        [0.8099],\n",
      "        [0.4274],\n",
      "        [0.2018],\n",
      "        [0.0203]]) \n",
      "\n",
      "tensor([[False, False,  True],\n",
      "        [False,  True, False],\n",
      "        [ True, False,  True],\n",
      "        [False, False,  True],\n",
      "        [False, False,  True]])\n",
      "tensor([0.8383, 0.8099, 0.7832, 0.6050, 0.8973, 0.5605])\n"
     ]
    }
   ],
   "source": [
    "# indexing 또한 비슷하게\n",
    "print(x)\n",
    "print(x[:, [1]], '\\n')\n",
    "print(x>0.5)\n",
    "print(x[x > 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1464fe-d4ad-4637-83ce-c6f850ce3087",
   "metadata": {},
   "source": [
    "### Squeeze and Unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b07615ad-b9a6-4ba8-bf23-029ca0ade94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 1, 3])\n",
      "tensor([[[[0.6367, 0.4894, 0.7851]],\n",
      "\n",
      "         [[0.3169, 0.3582, 0.2569]]]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0.6367, 0.4894, 0.7851],\n",
      "        [0.3169, 0.3582, 0.2569]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 2, 1, 3)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "x = x.squeeze() # [1, 20, 1, 128] -> [20, 128]\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11370684-83aa-4563-9075-dea18ebd5d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 1, 128])\n",
      "torch.Size([1, 20, 128])\n"
     ]
    }
   ],
   "source": [
    "x2 = torch.rand(1, 20, 1, 128)\n",
    "print(x2.shape)\n",
    "x2 = x2.squeeze(dim=2) # [1, 20, 1, 128] -> [1, 20, 128]\n",
    "print(x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b24b185-85fe-4cb9-8a0b-06a0e6a56c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "x = x.unsqueeze(0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7f1459-b00e-45fe-90df-84ae44855236",
   "metadata": {},
   "source": [
    "### multiplication and concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17c9c7bd-35e1-4799-9c17-9d2606abd2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.],\n",
      "        [12., 13., 14.]])\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [3., 3., 3.]])\n",
      "tensor([[ 0.,  3.,  6.],\n",
      "        [ 9., 12., 15.],\n",
      "        [18., 21., 24.],\n",
      "        [27., 30., 33.],\n",
      "        [36., 39., 42.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(15).reshape(5,3).to(dtype=torch.float32)\n",
    "y = torch.ones(5, 3)+2\n",
    "z = x * y\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45327a1e-ae86-434e-b3d8-ba59d36f97f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n",
      "tensor([[  9.,   9.,   9.,   9.,   9.],\n",
      "        [ 36.,  36.,  36.,  36.,  36.],\n",
      "        [ 63.,  63.,  63.,  63.,  63.],\n",
      "        [ 90.,  90.,  90.,  90.,  90.],\n",
      "        [117., 117., 117., 117., 117.]]) torch.Size([5, 5])\n",
      "tensor([[  9.,   9.,   9.,   9.,   9.],\n",
      "        [ 36.,  36.,  36.,  36.,  36.],\n",
      "        [ 63.,  63.,  63.,  63.,  63.],\n",
      "        [ 90.,  90.,  90.,  90.,  90.],\n",
      "        [117., 117., 117., 117., 117.]])\n"
     ]
    }
   ],
   "source": [
    "## matrix multiplication\n",
    "#y = W.T * x + b\n",
    "z= torch.matmul(x, y.t())\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(z, z.shape)\n",
    "w = x @ y.T\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "095d597b-d427-43dc-b8a7-35f232c54502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.],\n",
      "        [12., 13., 14.]])\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [3., 3., 3.]])\n",
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.],\n",
      "        [12., 13., 14.],\n",
      "        [ 3.,  3.,  3.],\n",
      "        [ 3.,  3.,  3.],\n",
      "        [ 3.,  3.,  3.],\n",
      "        [ 3.,  3.,  3.],\n",
      "        [ 3.,  3.,  3.]])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "z = torch.cat([x, y], dim=0)\n",
    "print(z)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4026366e-e14b-4fb6-9429-e7138d25fbc1",
   "metadata": {},
   "source": [
    "### 넘파이의 다양한 operation들이 토치에 같은 함수나 변형된 함수로 대부분 탑재 되어있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1946cd3a-7069-4363-886b-ddab96c32704",
   "metadata": {},
   "source": [
    "---\n",
    "## PyTorch의 Autograd: automatic differentiation\n",
    "* Autograd package는 Tensors가 사용할 수 있는 모든 Operation의 Gradient를 자동으로 계산해준다.\n",
    "* Tensor의 required_grad attribute를 이용해 gradient의 계산여부를 결정할 수 있다.\n",
    "  * 계산이 완료된 이후에 .backward()를 호출하면 자동으로 gradient를 계산한다.\n",
    "  * .grad attribute를 통해 마찬가지로 gradient에 접근할 수 있다. \n",
    "  * .grad_fn attribute를 통해 해당 Variable이 어떻게 생성되었는지 확인할 수 있다. 해당 값으로 해당 노드의 local gradient 구할 수 있게 됨.\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bdf3364-0249-4c91-b10d-e656b23d54d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "True\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create a variable\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "\n",
    "print(x)\n",
    "print(x.requires_grad)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fa930f7-8472-4f24-b51a-f2900951bbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)\n",
    "z = y * y * 3\n",
    "print(z)\n",
    "out = z.mean()\n",
    "print(out)\n",
    "\n",
    "out.retain_grad()\n",
    "z.retain_grad()\n",
    "y.retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fd3b5a2-8743-4102-ae26-b0e7e2fe74d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(27.) None <MeanBackward0 object at 0x7f2d060258b0>\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]]) None <MulBackward0 object at 0x7f2d060254c0>\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]]) None <AddBackward0 object at 0x7f2d060258b0>\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]]) None None\n"
     ]
    }
   ],
   "source": [
    "# y,z는 operation으로 생성된 결과이기 때문에 grad_fn이 있지만 , x는 없다.\n",
    "print(out.data, out.grad, out.grad_fn)\n",
    "print(z.data, z.grad, z.grad_fn)\n",
    "print(y.data, y.grad, y.grad_fn)\n",
    "print(x.data, x.grad, x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60ab368d-6abd-4870-9306-f32ec7191a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(27.) tensor(1.)\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]]) tensor([[0.2500, 0.2500],\n",
      "        [0.2500, 0.2500]])\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]]) tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]]) tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "out.backward()\n",
    "\n",
    "print(out.data, out.grad)\n",
    "print(z.data, z.grad)\n",
    "print(y.data, y.grad)\n",
    "print(x.data, x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c3b621-c1e3-455a-9935-f7e7feaf5c0b",
   "metadata": {},
   "source": [
    "* 실제로 Gradient 를 계산하면 다음과 같다. <br>\n",
    "$$\\frac{\\partial o}{\\partial o} = 1 $$\n",
    "\n",
    "$$o = \\frac{1}{4}\\sum_{i} z_{i}$$ \n",
    "\n",
    "$$\\frac{\\partial o}{\\partial z_{i}} = 0.25 $$\n",
    "\n",
    "$$z_{i}=3(y_{i})^{2}$$\n",
    "\n",
    "$$\\frac{\\partial o}{\\partial y_{i}} = 0.25 * \\frac{\\partial z_{i}}{\\partial y_{i}} = 1.5 * y_{i}|_{y_{i}=3} = 4.5 $$\n",
    "\n",
    "$$y = x + 2  $$\n",
    "\n",
    "$$\\frac{\\partial o}{\\partial x_{i}}|_{x_{i}=1} = \\frac{\\partial o}{\\partial y_{i}} = 4.5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b1356f-9e1d-47ec-be6e-cac8d14e2805",
   "metadata": {},
   "source": [
    "### Gradients \n",
    "* out.backward()을 하면 out의 gradient를 1로 시작해 Back-propagation을 시작한다.\n",
    "* .backward()를 호출한 이후부터는 .grad를 통해 각 변수의 gradient를 구할 수 있다.\n",
    "* https://teamdable.github.io/techblog/PyTorch-Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fcea8519-7065-4b81-a60b-6b36ced5898a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor(5.)\n",
      "y tensor(125.)\n",
      "z tensor(4.8283)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(5.0)\n",
    "y = x ** 3\n",
    "z = torch.log(y)\n",
    "\n",
    "print('x', x)\n",
    "print('y', y)\n",
    "print('z', z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cb662cd-af01-4541-b8c1-a80da1263527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x requires_grad(False) is_leaf(True) retains_grad(False) grad_fn(None) grad(None) tensor(tensor(5.))\n",
      "y requires_grad(False) is_leaf(True) retains_grad(False) grad_fn(None) grad(None) tensor(tensor(125.))\n",
      "z requires_grad(False) is_leaf(True) retains_grad(False) grad_fn(None) grad(None) tensor(tensor(4.8283))\n"
     ]
    }
   ],
   "source": [
    "def get_tensor_info(tensor):\n",
    "  info = []\n",
    "  for name in ['requires_grad', 'is_leaf', 'retains_grad', 'grad_fn', 'grad']:\n",
    "    info.append(f'{name}({getattr(tensor, name, None)})')\n",
    "  info.append(f'tensor({str(tensor)})')\n",
    "  return ' '.join(info)\n",
    "\n",
    "x = torch.tensor(5.0)\n",
    "y = x ** 3\n",
    "z = torch.log(y)\n",
    "\n",
    "print('x', get_tensor_info(x))\n",
    "print('y', get_tensor_info(y))\n",
    "print('z', get_tensor_info(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "513c6147-8c91-46db-82c2-d3450fc17f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x requires_grad(True) is_leaf(True) retains_grad(False) grad_fn(None) grad(None) tensor(tensor(5., requires_grad=True))\n",
      "y requires_grad(True) is_leaf(False) retains_grad(False) grad_fn(<PowBackward0 object at 0x7f2d0602a610>) grad(None) tensor(tensor(125., grad_fn=<PowBackward0>))\n",
      "z requires_grad(True) is_leaf(False) retains_grad(False) grad_fn(<LogBackward0 object at 0x7f2d0602a700>) grad(None) tensor(tensor(4.8283, grad_fn=<LogBackward0>))\n",
      "x_after_backward requires_grad(True) is_leaf(True) retains_grad(False) grad_fn(None) grad(0.6000000238418579) tensor(tensor(5., requires_grad=True))\n",
      "y_after_backward requires_grad(True) is_leaf(False) retains_grad(False) grad_fn(<PowBackward0 object at 0x7f2da2c6aa00>) grad(None) tensor(tensor(125., grad_fn=<PowBackward0>))\n",
      "z_after_backward requires_grad(True) is_leaf(False) retains_grad(False) grad_fn(<LogBackward0 object at 0x7f2d0602a8e0>) grad(None) tensor(tensor(4.8283, grad_fn=<LogBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.8/site-packages/torch/_tensor.py:1013: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1641297139223/work/build/aten/src/ATen/core/TensorBody.h:417.)\n",
      "  return self._grad\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(5.0, requires_grad=True)\n",
    "y = x ** 3\n",
    "z = torch.log(y)\n",
    "\n",
    "print('x', get_tensor_info(x))\n",
    "print('y', get_tensor_info(y))\n",
    "print('z', get_tensor_info(z))\n",
    "\n",
    "z.backward()\n",
    "\n",
    "print('x_after_backward', get_tensor_info(x))\n",
    "print('y_after_backward', get_tensor_info(y))\n",
    "print('z_after_backward', get_tensor_info(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb893c12-1cf0-4820-b8ec-fc646e7c0190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_before_backward : requires_grad(True) is_leaf(True) retains_grad(False) grad_fn(None) grad(None) tensor(tensor(5., requires_grad=True))\n",
      "y_before_backward : requires_grad(True) is_leaf(False) retains_grad(False) grad_fn(<PowBackward0 object at 0x7f2d0602a8e0>) grad(None) tensor(tensor(125., grad_fn=<PowBackward0>))\n",
      "z_before_backward : requires_grad(True) is_leaf(False) retains_grad(False) grad_fn(<LogBackward0 object at 0x7f2d0602a550>) grad(None) tensor(tensor(4.8283, grad_fn=<LogBackward0>))\n",
      "x_after_backward : requires_grad(True) is_leaf(True) retains_grad(False) grad_fn(None) grad(0.6000000238418579) tensor(tensor(5., requires_grad=True))\n",
      "y_after_backward : requires_grad(True) is_leaf(False) retains_grad(True) grad_fn(<PowBackward0 object at 0x7f2d0f3fbd60>) grad(0.00800000037997961) tensor(tensor(125., grad_fn=<PowBackward0>))\n",
      "z_after_backward : requires_grad(True) is_leaf(False) retains_grad(True) grad_fn(<LogBackward0 object at 0x7f2d0602a640>) grad(1.0) tensor(tensor(4.8283, grad_fn=<LogBackward0>))\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(5.0, requires_grad=True)\n",
    "y = x ** 3\n",
    "z = torch.log(y)\n",
    "\n",
    "print('x_before_backward :', get_tensor_info(x))\n",
    "print('y_before_backward :', get_tensor_info(y))\n",
    "print('z_before_backward :', get_tensor_info(z))\n",
    "\n",
    "y.retain_grad()\n",
    "z.retain_grad()\n",
    "z.backward()\n",
    "\n",
    "print('x_after_backward :', get_tensor_info(x))\n",
    "print('y_after_backward :', get_tensor_info(y))\n",
    "print('z_after_backward :', get_tensor_info(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "524b5976-574f-4189-a3b5-0d9be8c5e36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x requires_grad(True) is_leaf(True) retains_grad(False) grad_fn(None) grad(None) tensor(tensor(5., requires_grad=True))\n",
      "y requires_grad(True) is_leaf(False) retains_grad(False) grad_fn(<PowBackward0 object at 0x7f2d0602ae20>) grad(None) tensor(tensor(125., grad_fn=<PowBackward0>))\n",
      "z requires_grad(True) is_leaf(False) retains_grad(False) grad_fn(<LogBackward0 object at 0x7f2d0602a370>) grad(None) tensor(tensor(4.8283, grad_fn=<LogBackward0>))\n",
      "x_after_backward requires_grad(True) is_leaf(True) retains_grad(False) grad_fn(None) grad(0.6000000238418579) tensor(tensor(5., requires_grad=True))\n",
      "y_after_backward requires_grad(True) is_leaf(False) retains_grad(False) grad_fn(<PowBackward0 object at 0x7f2d0602a4f0>) grad(None) tensor(tensor(125., grad_fn=<PowBackward0>))\n",
      "z_after_backward requires_grad(True) is_leaf(False) retains_grad(False) grad_fn(<LogBackward0 object at 0x7f2d0602a370>) grad(None) tensor(tensor(4.8283, grad_fn=<LogBackward0>))\n",
      "x_after_2backward requires_grad(True) is_leaf(True) retains_grad(False) grad_fn(None) grad(1.2000000476837158) tensor(tensor(5., requires_grad=True))\n",
      "y_after_2backward requires_grad(True) is_leaf(False) retains_grad(False) grad_fn(<PowBackward0 object at 0x7f2d0602a730>) grad(None) tensor(tensor(125., grad_fn=<PowBackward0>))\n",
      "z_after_2backward requires_grad(True) is_leaf(False) retains_grad(False) grad_fn(<LogBackward0 object at 0x7f2d0602a790>) grad(None) tensor(tensor(4.8283, grad_fn=<LogBackward0>))\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(5.0, requires_grad=True)\n",
    "y = x ** 3\n",
    "z = torch.log(y)\n",
    "\n",
    "print('x', get_tensor_info(x))\n",
    "print('y', get_tensor_info(y))\n",
    "print('z', get_tensor_info(z))\n",
    "\n",
    "z.backward(retain_graph=True)\n",
    "\n",
    "print('x_after_backward', get_tensor_info(x))\n",
    "print('y_after_backward', get_tensor_info(y))\n",
    "print('z_after_backward', get_tensor_info(z))\n",
    "\n",
    "z.backward()\n",
    "\n",
    "print('x_after_2backward', get_tensor_info(x))\n",
    "print('y_after_2backward', get_tensor_info(y))\n",
    "print('z_after_2backward', get_tensor_info(z))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
