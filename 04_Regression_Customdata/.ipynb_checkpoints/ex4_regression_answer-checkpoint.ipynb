{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 414,
     "status": "ok",
     "timestamp": 1636095070674,
     "user": {
      "displayName": "Ji Ye Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05110516000762554458"
     },
     "user_tz": -540
    },
    "id": "7TOE8d5f1RAx"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fileid: 12XWUcct4LA_bZXaccScYUBC97S9R90L1\n",
    "# filename: crop_part1.tar.gz\n",
    "!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=12XWUcct4LA_bZXaccScYUBC97S9R90L1' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=12XWUcct4LA_bZXaccScYUBC97S9R90L1\" -O crop_part1.tar.gz && rm -rf ~/cookies.txt\n",
    "!tar -zxvf crop_part1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1636095075960,
     "user": {
      "displayName": "Ji Ye Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05110516000762554458"
     },
     "user_tz": -540
    },
    "id": "0TKNT_GB1RA0"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "class FaceDataset(Dataset):# \"./crop_part1\"\n",
    "    def __init__(self, root_dir, transform):\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.root_dir = root_dir\n",
    "        ##1\n",
    "#         self.image_path = [f for f in os.listdir(self.root_dir) if os.path.isfile(os.path.join(self.root_dir, f))]\n",
    "        ##2\n",
    "        self.image_path = []\n",
    "        for f in os.listdir(self.root_dir):\n",
    "            if os.path.isfile(os.path.join(self.root_dir, f)):\n",
    "                self.image_path.append(f)\n",
    "        \n",
    "#         print(self.image_path)\n",
    "    def __len__(self):\n",
    "        return len(self.image_path)\n",
    "        \n",
    "    def __getitem__(self, idx): #idx 가 들어오면 이미지와 레이블 리턴\n",
    "        path = self.image_path[idx]\n",
    "        img = Image.open(os.path.join(self.root_dir, path)).convert(\"RGB\")\n",
    "        \n",
    "        img = self.transform(img)\n",
    "        \n",
    "        label = path.split(\"_\")[0]\n",
    "        label = float(label)\n",
    "        \n",
    "        return img, label\n",
    "    ##implement this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "executionInfo": {
     "elapsed": 434,
     "status": "error",
     "timestamp": 1636095078157,
     "user": {
      "displayName": "Ji Ye Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05110516000762554458"
     },
     "user_tz": -540
    },
    "id": "uLqm2n9D1RA1",
    "outputId": "c5d5ba40-5550-4472-b348-7734f9344246",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "##implement dataset and dataloader\n",
    "dataset = FaceDataset(\"./crop_part1\", transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display some images\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(20,12))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# print labels\n",
    "print(' '.join('%15s' % str(labels[j].item()) for j in range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oW7_lfc51RA1"
   },
   "outputs": [],
   "source": [
    "# vgg16 pretrained network 받아서 씀\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, use_pretrained=True):\n",
    "        super(Net, self).__init__()\n",
    "        ##implement this\n",
    "        # [3, 224, 224]\n",
    "        self.vgg = models.vgg16(pretrained = use_pretrained).features #fc layer 3 는 빼고 가져옴\n",
    "        self.fc1 = nn.Linear(512 *7*7, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ##implement this\n",
    "        x = self.vgg(x)\n",
    "        x = x.view(-1, 512*7*7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlKuWHM81RA2"
   },
   "outputs": [],
   "source": [
    "#implement criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model = Net()\n",
    "summary(model, batch_size=-1, input_size=(3, 224, 224), device='cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSAhUAcL1RA2"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for batch_idx, (data, target) in enumerate(trainloader):\n",
    "        target = target.type(torch.float).view(-1,1)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(trainloader.dataset),\n",
    "                100. * batch_idx / len(trainloader), total_loss/(batch_idx+1)))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in testloader:\n",
    "        target = target.type(torch.float).view(-1,1)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).item() # sum up batch loss\n",
    "        \n",
    "\n",
    "    test_loss /= len(testloader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}'.format(\n",
    "        test_loss, correct, len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9H1obP41RA3",
    "outputId": "7fee7717-260c-4dc2-9c66-271a9314b4c5",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCnFRBzB1RA4"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "#print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GrondTruth: ', ' '.join('%5s' % labels[j].item() for j in range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1O0j_7Rr1RA5"
   },
   "outputs": [],
   "source": [
    "images = images.to(device)\n",
    "outputs = model(images)\n",
    "\n",
    "outputs = outputs.squeeze()\n",
    "\n",
    "print('Predicted: ', ' '.join('%.1f' % outputs[j].item() for j in range(8))) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Face_Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
