{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset Practice\n",
    "- Manual transforms\n",
    "- Custom Dataset\n",
    "- Custom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 414,
     "status": "ok",
     "timestamp": 1636095070674,
     "user": {
      "displayName": "Ji Ye Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05110516000762554458"
     },
     "user_tz": -540
    },
    "id": "7TOE8d5f1RAx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fileid: 0BxYys69jI14kRjNmM0gyVWM2bHM\n",
    "# filename: crop_part1.tar.gz\n",
    "\n",
    "!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=0BxYys69jI14kRjNmM0gyVWM2bHM' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=0BxYys69jI14kRjNmM0gyVWM2bHM\" -O crop_part1.tar.gz && rm -rf ~/cookies.txt\n",
    "!tar -zxvf crop_part1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "\n",
    "folder_dir = 'crop_part1'\n",
    "files_list = glob.glob(folder_dir+'/*')\n",
    "for files in files_list:\n",
    "    if len(os.path.split(files)[1].split('_')) != 4:\n",
    "        print(files)\n",
    "        os.remove(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = os.listdir('./crop_part1')\n",
    "print(len(tmp))\n",
    "print(tmp[0])\n",
    "!cd crop_part1 && ls | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '1_1_0_20161219204750596.jpg.chip.jpg'\n",
    "splits = fname.split('_')\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\n",
    "    './crop_part1/1_1_0_20161219204750596.jpg.chip.jpg').convert('RGB')\n",
    "print(img.size)\n",
    "import numpy as np\n",
    "npimg = np.array(img)\n",
    "print(npimg.shape)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tr = transforms.Compose([\n",
    "    transforms.RandomOrder([\n",
    "#         transforms.Grayscale(),\n",
    "#         transforms.CenterCrop(220),\n",
    "        transforms.ColorJitter(0, 0, 0, 0),\n",
    "        transforms.GaussianBlur(kernel_size=9, sigma=(0.1, 10.0)),\n",
    "        transforms.RandomAffine((0,360),translate=(0.1, 0.1), scale = (0.8,1.2), shear=(-30,30)),\n",
    "        ]),\n",
    "    transforms.Resize((200,200)),\n",
    "    ])\n",
    "\n",
    "tr(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1636095075960,
     "user": {
      "displayName": "Ji Ye Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05110516000762554458"
     },
     "user_tz": -540
    },
    "id": "0TKNT_GB1RA0"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1636095075960,
     "user": {
      "displayName": "Ji Ye Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05110516000762554458"
     },
     "user_tz": -540
    },
    "id": "0TKNT_GB1RA0"
   },
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform):\n",
    "        # implement this.\n",
    "        # 필요한 정보들 생성.\n",
    "        # Hint: os.listdir(directory) -> List[filename]\n",
    "        self.root_dir = root_dir\n",
    "        self.filenames = os.listdir(root_dir)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        # implement this.\n",
    "        # 데이터 셋의 크기가 얼마인지? (또는, image가 몇장 있는지)\n",
    "        return len(self.filenames)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # implement this\n",
    "        # 인덱스 (idx)를 받아서, 해당 idx 의 data 와 label 을 반환.\n",
    "        # Hint: Image.open(filename).convert('RGB')\n",
    "        # Hint: '1' -> 1. 로 바꾸기 위해선 float() 을 사용.\n",
    "        # Hint: filename = {age}_{gender}_{race}_{time}.jpg\n",
    "        filename = self.filenames[idx]\n",
    "        splits = filename.split('_')\n",
    "        age = float(splits[0])\n",
    "        gender = float(splits[1])\n",
    "        race = float(splits[2])\n",
    "        img = Image.open(os.path.join(self.root_dir, filename)).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        return {\n",
    "            \"image\": img, # [3, 224, 224]\n",
    "            \"age\": age,\n",
    "            \"gender\": gender,\n",
    "            \"race\": race,\n",
    "            \"filename\": filename\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "executionInfo": {
     "elapsed": 434,
     "status": "error",
     "timestamp": 1636095078157,
     "user": {
      "displayName": "Ji Ye Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05110516000762554458"
     },
     "user_tz": -540
    },
    "id": "uLqm2n9D1RA1",
    "outputId": "c5d5ba40-5550-4472-b348-7734f9344246",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "##implement dataset and dataloader\n",
    "dataset = FaceDataset(\"./crop_part1\", transform)\n",
    "train_length = int(len(dataset) * 0.9)\n",
    "test_length = len(dataset) - train_length\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [train_length, test_length])\n",
    "print(len(train_set), len(test_set))\n",
    "train_set, val_set = torch.utils.data.random_split(train_set, [int(len(train_set)*0.7), len(train_set)- int(len(train_set)*0.7)])\n",
    "print(len(train_set), len(val_set), len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate_fn(list_data):\n",
    "#     [dataset.__getitem__(0), ..., dataset.__getitem__(7)]\n",
    "    data_dicts = {\n",
    "        \"image\": [],\n",
    "        \"age\": [],\n",
    "        \"gender\": [],\n",
    "        \"race\": [],\n",
    "        \"filename\": []\n",
    "    }\n",
    "    batch_size = len(list_data)\n",
    "    for i in range(batch_size):\n",
    "        data = list_data[i] # {\"image\": torch.Tensor, \"age\": float, \"filename\": str}\n",
    "        data_dicts[\"image\"].append(data[\"image\"].unsqueeze(0)) # [1, 3, 224, 224]\n",
    "        data_dicts[\"age\"].append(data[\"age\"])\n",
    "        data_dicts[\"gender\"].append(data[\"gender\"])\n",
    "        data_dicts[\"race\"].append(data[\"race\"])\n",
    "        data_dicts[\"filename\"].append(data[\"filename\"])\n",
    "    data_dicts[\"image\"] = torch.cat(data_dicts[\"image\"], dim=0)\n",
    "    data_dicts[\"age\"] = torch.tensor(data_dicts[\"age\"])\n",
    "    data_dicts[\"gender\"] = torch.tensor(data_dicts[\"gender\"])\n",
    "    data_dicts[\"race\"] = torch.tensor(data_dicts[\"race\"])\n",
    "    return data_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "trainloader = DataLoader(\n",
    "    train_set, batch_size = batch_size, shuffle = True, collate_fn=my_collate_fn\n",
    ")\n",
    "testloader = DataLoader(\n",
    "    test_set, batch_size = batch_size, shuffle = False, collate_fn=my_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display some images\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(20,12))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "data_dicts = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(data_dicts[\"image\"]))\n",
    "\n",
    "# print labels\n",
    "Gender_dict = {0 : 'Male', 1 : 'Female'}\n",
    "Race_dict = {0 : 'White', 1 : 'Black', 2 : 'Asian', 3: 'Indian', 4 : 'Others'}\n",
    "print('Age    : ', ' '.join('%6s' % str(data_dicts[\"age\"][j].item()) for j in range(8)))\n",
    "print('Gender : ', ' '.join('%6s' % Gender_dict[int(data_dicts[\"gender\"][j].item())] for j in range(8)))\n",
    "print('Race   : ',' '.join('%6s' % Race_dict[int(data_dicts[\"race\"][j].item())] for j in range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oW7_lfc51RA1"
   },
   "outputs": [],
   "source": [
    "# ResNet18 pretrained network 받아서 씀\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, use_pretrained=True):\n",
    "        super(Net, self).__init__()\n",
    "        ##implement this\n",
    "        # [3, 224, 224]\n",
    "        self.net = models.resnet18(pretrained = use_pretrained) #fc layer 3 는 빼고 가져옴\n",
    "        in_features = self.net.fc.in_features\n",
    "        self.net.fc = nn.Linear(in_features, 1) #512, 1\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ##implement this\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlKuWHM81RA2",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#implement criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model = Net(use_pretrained=True)\n",
    "summary(model, batch_size=-1, input_size=(3, 224, 224), device='cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSAhUAcL1RA2"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for batch_idx, data_dict in enumerate(trainloader):\n",
    "        data = data_dict[\"image\"].to(device)\n",
    "        target = data_dict[\"age\"].to(dtype=torch.float32, device = device).view(-1,1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch+1, batch_idx * len(data), len(trainloader.dataset),\n",
    "                100. * batch_idx / len(trainloader), total_loss/(batch_idx+1)))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        correct = np.zeros(1)\n",
    "        total = np.zeros(1)\n",
    "        for data_dict in testloader:\n",
    "            target = data_dict[\"age\"].to(dtype=torch.float32, device = device).view(-1,1)\n",
    "            \n",
    "            data, target = data_dict[\"image\"].to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss\n",
    "            \n",
    "            correct += np.sum(np.array(target.to('cpu')) == np.round(np.array(output.to('cpu'))), 0)\n",
    "            total += len(target)\n",
    "            \n",
    "        acc = correct/total\n",
    "        test_loss /= len(testloader.dataset)\n",
    "        print(f'\\nTest set: Average loss: {test_loss:.4f}',\n",
    "                f'Correct Labels for Ages : {acc[0]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9H1obP41RA3",
    "outputId": "7fee7717-260c-4dc2-9c66-271a9314b4c5",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCnFRBzB1RA4"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "data_dict = dataiter.next()\n",
    "images = data_dict['image']\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GrondTruth: ', ' '.join('%5s' % data_dict['age'][j].item() for j in range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1O0j_7Rr1RA5"
   },
   "outputs": [],
   "source": [
    "images = images.to(device)\n",
    "outputs = model(images)\n",
    "\n",
    "outputs = outputs.squeeze()\n",
    "\n",
    "print('Predicted: ', ' '.join('%.1f' % outputs[j].item() for j in range(8))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet18 pretrained network 받아서 씀\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, use_pretrained=True):\n",
    "        super(Net, self).__init__()\n",
    "        ##implement this\n",
    "        # [3, 224, 224]\n",
    "        self.net = models.resnet18(pretrained = use_pretrained) #fc layer 3 는 빼고 가져옴\n",
    "        in_features = self.net.fc.in_features\n",
    "        self.net.fc = nn.Linear(in_features, 3) #512, 1\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ##implement this\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model = Net(use_pretrained=True)\n",
    "summary(model, batch_size=-1, input_size=(3, 224, 224), device='cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement for 3 class regression\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for batch_idx, data_dict in enumerate(trainloader):\n",
    "        data = data_dict[\"image\"].to(device)\n",
    "        target1 = data_dict[\"age\"].to(dtype=torch.float32, device = device).view(-1,1)\n",
    "        target2 = data_dict[\"gender\"].to(dtype=torch.float32, device = device).view(-1,1)\n",
    "        target3 = data_dict[\"race\"].to(dtype=torch.float32, device = device).view(-1,1)\n",
    "        target = torch.hstack([target1, target2, target3])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch+1, batch_idx * len(data), len(trainloader.dataset),\n",
    "                100. * batch_idx / len(trainloader), total_loss/(batch_idx+1)))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        correct = np.zeros(3)\n",
    "        total = np.zeros(3)\n",
    "        for data_dict in testloader:\n",
    "            target1 = data_dict[\"age\"].to(dtype=torch.float32, device = device).view(-1,1)\n",
    "            target2 = data_dict[\"gender\"].to(dtype=torch.float32, device = device).view(-1,1)\n",
    "            target3 = data_dict[\"race\"].to(dtype=torch.float32, device = device).view(-1,1)\n",
    "            target = torch.hstack([target1, target2, target3])\n",
    "            \n",
    "            data, target = data_dict[\"image\"].to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss\n",
    "            \n",
    "            correct += np.sum(np.array(target.to('cpu')) == np.round(np.array(output.to('cpu'))), 0)\n",
    "            total += len(target)\n",
    "            \n",
    "        acc = correct/total\n",
    "        test_loss /= len(testloader.dataset)\n",
    "        print(f'\\nTest set: Average loss: {test_loss:.4f}',\n",
    "                f'Correct Labels for Ages : {acc[0]:.3f}, Gender : {acc[1]:.3f}, Race : {acc[1]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(testloader)\n",
    "data_dict = dataiter.next()\n",
    "images = data_dicts['image']\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('Age    : ', ' '.join('%6s' % str(data_dicts[\"age\"][j].item()) for j in range(8)))\n",
    "print('Gender : ', ' '.join('%6s' % Gender_dict[int(data_dicts[\"gender\"][j].item())] for j in range(8)))\n",
    "print('Race   : ',' '.join('%6s' % Race_dict[int(data_dicts[\"race\"][j].item())] for j in range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.to(device)\n",
    "outputs = model(images)\n",
    "outputs = np.array(outputs.detach().to('cpu'))\n",
    "pred_ages = outputs[:,0]\n",
    "pred_gender = ((outputs[:, 1])>0.5).astype(int)\n",
    "race = outputs[:,2]\n",
    "for idx in range(len(race)):\n",
    "    val = race[idx]\n",
    "    if val <= 0.5:\n",
    "        race[idx] = 0\n",
    "    elif val > 3.5:\n",
    "        race[idx] = 4\n",
    "    else:\n",
    "        race[idx] = np.round(val)\n",
    "pred_race = race.astype(int)\n",
    "\n",
    "# print('Predicted: ', ' '.join('%.1f' % outputs[j].item() for j in range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Age    : ', ' '.join('%6.1f' % pred_ages[j] for j in range(8)))\n",
    "print('Gender : ', ' '.join('%6s' % Gender_dict[pred_gender[j]] for j in range(8)))\n",
    "print('Race   : ',' '.join('%6s' % Race_dict[pred_race[j]] for j in range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Face_Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
