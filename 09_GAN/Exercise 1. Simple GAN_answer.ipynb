{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09c410a3-b828-4bb3-bc73-df20473d9a43",
   "metadata": {},
   "source": [
    "Referecnce : https://github.com/eriklindernoren/PyTorch-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2afbd92-67d7-4d49-8f9a-3bd71ff89243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b2f3ac-9e09-473f-ab69-9d9360dad41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            \n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            \n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            \n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "                    *block(100,256,normalize=True),\n",
    "                    *block(256,512,normalize=True),\n",
    "                    *block(512,1024,normalize=True),\n",
    "                    nn.Dropout(),\n",
    "                    nn.Linear(1024, 784),\n",
    "                    nn.Tanh()\n",
    "                    )\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        \n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 1, 28, 28)\n",
    "        \n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "                    nn.Dropout(),\n",
    "                    nn.Linear(784, 512),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.Linear(512, 256),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.Linear(256, 1),\n",
    "                    nn.Sigmoid()\n",
    "                    )\n",
    "\n",
    "    def forward(self, img):\n",
    "        \n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        out = self.model(img_flat)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8728f4c-c09b-405a-9712-f8549c0626da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator().cuda()\n",
    "discriminator = Discriminator().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b86e60d-6340-45e2-8767-5795a46a080e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "decaef430a0847aa886fdced2f3e3582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9aa6d2fa8643688c77b0629a82c931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548b9fb2ac5e46769aa0edaae5ca8ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4aafc2fa15b4755867595c2206167e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.MNIST(\"./mnist\", train=True, download=True, \n",
    "                         transform=transforms.Compose([transforms.Resize(28), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d249fb70-78cf-4191-9d58-afd3d6d4572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.9999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad6e2e40-5b60-4ddc-9d55-4a4faf66a756",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/64] [Batch 0/937] [D loss: 0.695439] [G loss: 0.675042]\n",
      "[Epoch 0/64] [Batch 100/937] [D loss: 0.321986] [G loss: 0.846146]\n",
      "[Epoch 0/64] [Batch 200/937] [D loss: 0.473571] [G loss: 0.766429]\n",
      "[Epoch 0/64] [Batch 300/937] [D loss: 0.386632] [G loss: 0.967008]\n",
      "[Epoch 0/64] [Batch 400/937] [D loss: 0.585910] [G loss: 0.692223]\n",
      "[Epoch 0/64] [Batch 500/937] [D loss: 0.434597] [G loss: 1.185722]\n",
      "[Epoch 0/64] [Batch 600/937] [D loss: 0.385554] [G loss: 1.080754]\n",
      "[Epoch 0/64] [Batch 700/937] [D loss: 0.390274] [G loss: 1.138490]\n",
      "[Epoch 0/64] [Batch 800/937] [D loss: 0.366427] [G loss: 2.059252]\n",
      "[Epoch 0/64] [Batch 900/937] [D loss: 0.415237] [G loss: 1.506824]\n",
      "[Epoch 1/64] [Batch 63/937] [D loss: 0.372891] [G loss: 1.246332]\n",
      "[Epoch 1/64] [Batch 163/937] [D loss: 0.498919] [G loss: 0.651340]\n",
      "[Epoch 1/64] [Batch 263/937] [D loss: 0.426200] [G loss: 1.418907]\n",
      "[Epoch 1/64] [Batch 363/937] [D loss: 0.628441] [G loss: 0.586570]\n",
      "[Epoch 1/64] [Batch 463/937] [D loss: 0.619569] [G loss: 0.533368]\n",
      "[Epoch 1/64] [Batch 563/937] [D loss: 0.514790] [G loss: 0.723944]\n",
      "[Epoch 1/64] [Batch 663/937] [D loss: 0.387040] [G loss: 1.460779]\n",
      "[Epoch 1/64] [Batch 763/937] [D loss: 0.487069] [G loss: 1.190985]\n",
      "[Epoch 1/64] [Batch 863/937] [D loss: 0.449006] [G loss: 1.329027]\n",
      "[Epoch 2/64] [Batch 26/937] [D loss: 0.525845] [G loss: 1.275254]\n",
      "[Epoch 2/64] [Batch 126/937] [D loss: 0.403427] [G loss: 1.411652]\n",
      "[Epoch 2/64] [Batch 226/937] [D loss: 0.484892] [G loss: 1.239332]\n",
      "[Epoch 2/64] [Batch 326/937] [D loss: 0.525688] [G loss: 1.254317]\n",
      "[Epoch 2/64] [Batch 426/937] [D loss: 0.437363] [G loss: 1.612778]\n",
      "[Epoch 2/64] [Batch 526/937] [D loss: 0.529659] [G loss: 1.215169]\n",
      "[Epoch 2/64] [Batch 626/937] [D loss: 0.573681] [G loss: 2.228186]\n",
      "[Epoch 2/64] [Batch 726/937] [D loss: 0.502187] [G loss: 0.822361]\n",
      "[Epoch 2/64] [Batch 826/937] [D loss: 0.497245] [G loss: 1.388251]\n",
      "[Epoch 2/64] [Batch 926/937] [D loss: 0.508024] [G loss: 0.749708]\n",
      "[Epoch 3/64] [Batch 89/937] [D loss: 0.457726] [G loss: 0.941193]\n",
      "[Epoch 3/64] [Batch 189/937] [D loss: 0.462268] [G loss: 1.176105]\n",
      "[Epoch 3/64] [Batch 289/937] [D loss: 0.509900] [G loss: 1.289657]\n",
      "[Epoch 3/64] [Batch 389/937] [D loss: 0.512711] [G loss: 1.737637]\n",
      "[Epoch 3/64] [Batch 489/937] [D loss: 0.447967] [G loss: 1.267447]\n",
      "[Epoch 3/64] [Batch 589/937] [D loss: 0.468603] [G loss: 1.105544]\n",
      "[Epoch 3/64] [Batch 689/937] [D loss: 0.479513] [G loss: 1.624273]\n",
      "[Epoch 3/64] [Batch 789/937] [D loss: 0.494594] [G loss: 1.425273]\n",
      "[Epoch 3/64] [Batch 889/937] [D loss: 0.422978] [G loss: 1.315076]\n",
      "[Epoch 4/64] [Batch 52/937] [D loss: 0.459076] [G loss: 1.644644]\n",
      "[Epoch 4/64] [Batch 152/937] [D loss: 0.493863] [G loss: 1.880206]\n",
      "[Epoch 4/64] [Batch 252/937] [D loss: 0.394628] [G loss: 1.584178]\n",
      "[Epoch 4/64] [Batch 352/937] [D loss: 0.439552] [G loss: 1.524971]\n",
      "[Epoch 4/64] [Batch 452/937] [D loss: 0.576580] [G loss: 2.499146]\n",
      "[Epoch 4/64] [Batch 552/937] [D loss: 0.375206] [G loss: 1.747653]\n",
      "[Epoch 4/64] [Batch 652/937] [D loss: 0.424135] [G loss: 1.412791]\n",
      "[Epoch 4/64] [Batch 752/937] [D loss: 0.589407] [G loss: 0.765484]\n",
      "[Epoch 4/64] [Batch 852/937] [D loss: 0.388136] [G loss: 1.341247]\n",
      "[Epoch 5/64] [Batch 15/937] [D loss: 0.401220] [G loss: 1.309800]\n",
      "[Epoch 5/64] [Batch 115/937] [D loss: 0.393642] [G loss: 1.221227]\n",
      "[Epoch 5/64] [Batch 215/937] [D loss: 0.420691] [G loss: 2.004450]\n",
      "[Epoch 5/64] [Batch 315/937] [D loss: 0.417751] [G loss: 0.933058]\n",
      "[Epoch 5/64] [Batch 415/937] [D loss: 0.444477] [G loss: 1.343133]\n",
      "[Epoch 5/64] [Batch 515/937] [D loss: 0.459552] [G loss: 1.470031]\n",
      "[Epoch 5/64] [Batch 615/937] [D loss: 0.353713] [G loss: 1.796390]\n",
      "[Epoch 5/64] [Batch 715/937] [D loss: 0.443129] [G loss: 1.371849]\n",
      "[Epoch 5/64] [Batch 815/937] [D loss: 0.533278] [G loss: 1.967988]\n",
      "[Epoch 5/64] [Batch 915/937] [D loss: 0.566616] [G loss: 1.226814]\n",
      "[Epoch 6/64] [Batch 78/937] [D loss: 0.361344] [G loss: 1.556070]\n",
      "[Epoch 6/64] [Batch 178/937] [D loss: 0.426891] [G loss: 1.485555]\n",
      "[Epoch 6/64] [Batch 278/937] [D loss: 0.476042] [G loss: 1.893971]\n",
      "[Epoch 6/64] [Batch 378/937] [D loss: 0.534740] [G loss: 1.925642]\n",
      "[Epoch 6/64] [Batch 478/937] [D loss: 0.391583] [G loss: 1.499544]\n",
      "[Epoch 6/64] [Batch 578/937] [D loss: 0.482499] [G loss: 1.256927]\n",
      "[Epoch 6/64] [Batch 678/937] [D loss: 0.560076] [G loss: 1.406610]\n",
      "[Epoch 6/64] [Batch 778/937] [D loss: 0.465361] [G loss: 1.790801]\n",
      "[Epoch 6/64] [Batch 878/937] [D loss: 0.469791] [G loss: 1.273504]\n",
      "[Epoch 7/64] [Batch 41/937] [D loss: 0.532646] [G loss: 0.899268]\n",
      "[Epoch 7/64] [Batch 141/937] [D loss: 0.497244] [G loss: 0.939876]\n",
      "[Epoch 7/64] [Batch 241/937] [D loss: 0.529660] [G loss: 0.920664]\n",
      "[Epoch 7/64] [Batch 341/937] [D loss: 0.514045] [G loss: 1.136365]\n",
      "[Epoch 7/64] [Batch 441/937] [D loss: 0.501719] [G loss: 1.250220]\n",
      "[Epoch 7/64] [Batch 541/937] [D loss: 0.477961] [G loss: 1.351394]\n",
      "[Epoch 7/64] [Batch 641/937] [D loss: 0.555624] [G loss: 1.264785]\n",
      "[Epoch 7/64] [Batch 741/937] [D loss: 0.530073] [G loss: 1.100575]\n",
      "[Epoch 7/64] [Batch 841/937] [D loss: 0.536378] [G loss: 1.299490]\n",
      "[Epoch 8/64] [Batch 4/937] [D loss: 0.560125] [G loss: 1.161964]\n",
      "[Epoch 8/64] [Batch 104/937] [D loss: 0.465308] [G loss: 1.249588]\n",
      "[Epoch 8/64] [Batch 204/937] [D loss: 0.529088] [G loss: 1.548098]\n",
      "[Epoch 8/64] [Batch 304/937] [D loss: 0.494333] [G loss: 1.557301]\n",
      "[Epoch 8/64] [Batch 404/937] [D loss: 0.518016] [G loss: 1.417069]\n",
      "[Epoch 8/64] [Batch 504/937] [D loss: 0.485212] [G loss: 1.478845]\n",
      "[Epoch 8/64] [Batch 604/937] [D loss: 0.563079] [G loss: 0.920425]\n",
      "[Epoch 8/64] [Batch 704/937] [D loss: 0.528041] [G loss: 1.205749]\n",
      "[Epoch 8/64] [Batch 804/937] [D loss: 0.522609] [G loss: 1.057040]\n",
      "[Epoch 8/64] [Batch 904/937] [D loss: 0.586259] [G loss: 0.758188]\n",
      "[Epoch 9/64] [Batch 67/937] [D loss: 0.595313] [G loss: 1.025506]\n",
      "[Epoch 9/64] [Batch 167/937] [D loss: 0.572624] [G loss: 1.468114]\n",
      "[Epoch 9/64] [Batch 267/937] [D loss: 0.515248] [G loss: 0.940276]\n",
      "[Epoch 9/64] [Batch 367/937] [D loss: 0.637430] [G loss: 1.097201]\n",
      "[Epoch 9/64] [Batch 467/937] [D loss: 0.502747] [G loss: 0.949235]\n",
      "[Epoch 9/64] [Batch 567/937] [D loss: 0.609461] [G loss: 0.774945]\n",
      "[Epoch 9/64] [Batch 667/937] [D loss: 0.526968] [G loss: 1.103570]\n",
      "[Epoch 9/64] [Batch 767/937] [D loss: 0.533172] [G loss: 0.843123]\n",
      "[Epoch 9/64] [Batch 867/937] [D loss: 0.591527] [G loss: 1.390487]\n",
      "[Epoch 10/64] [Batch 30/937] [D loss: 0.554394] [G loss: 1.052916]\n",
      "[Epoch 10/64] [Batch 130/937] [D loss: 0.597090] [G loss: 0.907765]\n",
      "[Epoch 10/64] [Batch 230/937] [D loss: 0.622524] [G loss: 1.060989]\n",
      "[Epoch 10/64] [Batch 330/937] [D loss: 0.554458] [G loss: 1.358114]\n",
      "[Epoch 10/64] [Batch 430/937] [D loss: 0.617280] [G loss: 1.010463]\n",
      "[Epoch 10/64] [Batch 530/937] [D loss: 0.508123] [G loss: 1.130779]\n",
      "[Epoch 10/64] [Batch 630/937] [D loss: 0.536976] [G loss: 1.152449]\n",
      "[Epoch 10/64] [Batch 730/937] [D loss: 0.539510] [G loss: 1.054232]\n",
      "[Epoch 10/64] [Batch 830/937] [D loss: 0.513535] [G loss: 1.252794]\n",
      "[Epoch 10/64] [Batch 930/937] [D loss: 0.543897] [G loss: 1.008331]\n",
      "[Epoch 11/64] [Batch 93/937] [D loss: 0.570858] [G loss: 0.983289]\n",
      "[Epoch 11/64] [Batch 193/937] [D loss: 0.550077] [G loss: 0.968368]\n",
      "[Epoch 11/64] [Batch 293/937] [D loss: 0.626024] [G loss: 0.815634]\n",
      "[Epoch 11/64] [Batch 393/937] [D loss: 0.553212] [G loss: 0.932080]\n",
      "[Epoch 11/64] [Batch 493/937] [D loss: 0.591173] [G loss: 0.700042]\n",
      "[Epoch 11/64] [Batch 593/937] [D loss: 0.583014] [G loss: 1.122396]\n",
      "[Epoch 11/64] [Batch 693/937] [D loss: 0.553612] [G loss: 1.205243]\n",
      "[Epoch 11/64] [Batch 793/937] [D loss: 0.581506] [G loss: 0.807177]\n",
      "[Epoch 11/64] [Batch 893/937] [D loss: 0.578959] [G loss: 0.982548]\n",
      "[Epoch 12/64] [Batch 56/937] [D loss: 0.543230] [G loss: 1.107077]\n",
      "[Epoch 12/64] [Batch 156/937] [D loss: 0.663034] [G loss: 0.878663]\n",
      "[Epoch 12/64] [Batch 256/937] [D loss: 0.579587] [G loss: 1.031931]\n",
      "[Epoch 12/64] [Batch 356/937] [D loss: 0.585801] [G loss: 1.227446]\n",
      "[Epoch 12/64] [Batch 456/937] [D loss: 0.623406] [G loss: 0.767983]\n",
      "[Epoch 12/64] [Batch 556/937] [D loss: 0.588368] [G loss: 0.973548]\n",
      "[Epoch 12/64] [Batch 656/937] [D loss: 0.558550] [G loss: 1.102648]\n",
      "[Epoch 12/64] [Batch 756/937] [D loss: 0.645391] [G loss: 0.902172]\n",
      "[Epoch 12/64] [Batch 856/937] [D loss: 0.569001] [G loss: 0.749354]\n",
      "[Epoch 13/64] [Batch 19/937] [D loss: 0.603366] [G loss: 0.741928]\n",
      "[Epoch 13/64] [Batch 119/937] [D loss: 0.643084] [G loss: 0.976114]\n",
      "[Epoch 13/64] [Batch 219/937] [D loss: 0.543942] [G loss: 1.210018]\n",
      "[Epoch 13/64] [Batch 319/937] [D loss: 0.594655] [G loss: 0.772988]\n",
      "[Epoch 13/64] [Batch 419/937] [D loss: 0.541762] [G loss: 1.048196]\n",
      "[Epoch 13/64] [Batch 519/937] [D loss: 0.560560] [G loss: 1.107267]\n",
      "[Epoch 13/64] [Batch 619/937] [D loss: 0.564811] [G loss: 1.076502]\n",
      "[Epoch 13/64] [Batch 719/937] [D loss: 0.622957] [G loss: 0.862306]\n",
      "[Epoch 13/64] [Batch 819/937] [D loss: 0.529003] [G loss: 1.157922]\n",
      "[Epoch 13/64] [Batch 919/937] [D loss: 0.632853] [G loss: 1.286380]\n",
      "[Epoch 14/64] [Batch 82/937] [D loss: 0.659819] [G loss: 0.840090]\n",
      "[Epoch 14/64] [Batch 182/937] [D loss: 0.580034] [G loss: 0.984295]\n",
      "[Epoch 14/64] [Batch 282/937] [D loss: 0.566305] [G loss: 0.893813]\n",
      "[Epoch 14/64] [Batch 382/937] [D loss: 0.568717] [G loss: 0.988715]\n",
      "[Epoch 14/64] [Batch 482/937] [D loss: 0.587944] [G loss: 1.109800]\n",
      "[Epoch 14/64] [Batch 582/937] [D loss: 0.598971] [G loss: 1.000882]\n",
      "[Epoch 14/64] [Batch 682/937] [D loss: 0.660690] [G loss: 0.910362]\n",
      "[Epoch 14/64] [Batch 782/937] [D loss: 0.588402] [G loss: 1.014499]\n",
      "[Epoch 14/64] [Batch 882/937] [D loss: 0.638593] [G loss: 0.841760]\n",
      "[Epoch 15/64] [Batch 45/937] [D loss: 0.565584] [G loss: 1.001171]\n",
      "[Epoch 15/64] [Batch 145/937] [D loss: 0.625539] [G loss: 1.203379]\n",
      "[Epoch 15/64] [Batch 245/937] [D loss: 0.564711] [G loss: 1.080005]\n",
      "[Epoch 15/64] [Batch 345/937] [D loss: 0.597657] [G loss: 0.991665]\n",
      "[Epoch 15/64] [Batch 445/937] [D loss: 0.556449] [G loss: 1.091110]\n",
      "[Epoch 15/64] [Batch 545/937] [D loss: 0.621458] [G loss: 1.155637]\n",
      "[Epoch 15/64] [Batch 645/937] [D loss: 0.553508] [G loss: 1.019476]\n",
      "[Epoch 15/64] [Batch 745/937] [D loss: 0.611048] [G loss: 1.049977]\n",
      "[Epoch 15/64] [Batch 845/937] [D loss: 0.605336] [G loss: 1.118627]\n",
      "[Epoch 16/64] [Batch 8/937] [D loss: 0.584108] [G loss: 0.984372]\n",
      "[Epoch 16/64] [Batch 108/937] [D loss: 0.545321] [G loss: 1.067785]\n",
      "[Epoch 16/64] [Batch 208/937] [D loss: 0.599693] [G loss: 0.993601]\n",
      "[Epoch 16/64] [Batch 308/937] [D loss: 0.545991] [G loss: 1.131923]\n",
      "[Epoch 16/64] [Batch 408/937] [D loss: 0.597315] [G loss: 1.012867]\n",
      "[Epoch 16/64] [Batch 508/937] [D loss: 0.556641] [G loss: 1.131151]\n",
      "[Epoch 16/64] [Batch 608/937] [D loss: 0.595272] [G loss: 0.936367]\n",
      "[Epoch 16/64] [Batch 708/937] [D loss: 0.609064] [G loss: 1.371217]\n",
      "[Epoch 16/64] [Batch 808/937] [D loss: 0.531427] [G loss: 1.221689]\n",
      "[Epoch 16/64] [Batch 908/937] [D loss: 0.691488] [G loss: 0.730434]\n",
      "[Epoch 17/64] [Batch 71/937] [D loss: 0.547928] [G loss: 0.911043]\n",
      "[Epoch 17/64] [Batch 171/937] [D loss: 0.606205] [G loss: 1.233859]\n",
      "[Epoch 17/64] [Batch 271/937] [D loss: 0.598348] [G loss: 0.757042]\n",
      "[Epoch 17/64] [Batch 371/937] [D loss: 0.592661] [G loss: 1.179873]\n",
      "[Epoch 17/64] [Batch 471/937] [D loss: 0.624733] [G loss: 1.172912]\n",
      "[Epoch 17/64] [Batch 571/937] [D loss: 0.611251] [G loss: 1.072287]\n",
      "[Epoch 17/64] [Batch 671/937] [D loss: 0.561125] [G loss: 1.040874]\n",
      "[Epoch 17/64] [Batch 771/937] [D loss: 0.588870] [G loss: 0.841627]\n",
      "[Epoch 17/64] [Batch 871/937] [D loss: 0.566994] [G loss: 0.843499]\n",
      "[Epoch 18/64] [Batch 34/937] [D loss: 0.582172] [G loss: 1.060506]\n",
      "[Epoch 18/64] [Batch 134/937] [D loss: 0.650868] [G loss: 0.704124]\n",
      "[Epoch 18/64] [Batch 234/937] [D loss: 0.592870] [G loss: 1.017313]\n",
      "[Epoch 18/64] [Batch 334/937] [D loss: 0.543955] [G loss: 0.996251]\n",
      "[Epoch 18/64] [Batch 434/937] [D loss: 0.600845] [G loss: 0.879784]\n",
      "[Epoch 18/64] [Batch 534/937] [D loss: 0.593875] [G loss: 1.140620]\n",
      "[Epoch 18/64] [Batch 634/937] [D loss: 0.576722] [G loss: 0.944798]\n",
      "[Epoch 18/64] [Batch 734/937] [D loss: 0.571790] [G loss: 0.995784]\n",
      "[Epoch 18/64] [Batch 834/937] [D loss: 0.579675] [G loss: 0.842462]\n",
      "[Epoch 18/64] [Batch 934/937] [D loss: 0.617803] [G loss: 0.839223]\n",
      "[Epoch 19/64] [Batch 97/937] [D loss: 0.615951] [G loss: 1.206611]\n",
      "[Epoch 19/64] [Batch 197/937] [D loss: 0.554986] [G loss: 1.129703]\n",
      "[Epoch 19/64] [Batch 297/937] [D loss: 0.635204] [G loss: 1.046658]\n",
      "[Epoch 19/64] [Batch 397/937] [D loss: 0.585841] [G loss: 1.255028]\n",
      "[Epoch 19/64] [Batch 497/937] [D loss: 0.573880] [G loss: 0.921595]\n",
      "[Epoch 19/64] [Batch 597/937] [D loss: 0.600067] [G loss: 1.080356]\n",
      "[Epoch 19/64] [Batch 697/937] [D loss: 0.632439] [G loss: 0.929059]\n",
      "[Epoch 19/64] [Batch 797/937] [D loss: 0.575976] [G loss: 1.150014]\n",
      "[Epoch 19/64] [Batch 897/937] [D loss: 0.555876] [G loss: 0.939717]\n",
      "[Epoch 20/64] [Batch 60/937] [D loss: 0.509219] [G loss: 1.085885]\n",
      "[Epoch 20/64] [Batch 160/937] [D loss: 0.589470] [G loss: 1.061091]\n",
      "[Epoch 20/64] [Batch 260/937] [D loss: 0.622670] [G loss: 0.737460]\n",
      "[Epoch 20/64] [Batch 360/937] [D loss: 0.613859] [G loss: 1.014462]\n",
      "[Epoch 20/64] [Batch 460/937] [D loss: 0.601927] [G loss: 0.706543]\n",
      "[Epoch 20/64] [Batch 560/937] [D loss: 0.596727] [G loss: 0.879929]\n",
      "[Epoch 20/64] [Batch 660/937] [D loss: 0.589767] [G loss: 1.082019]\n",
      "[Epoch 20/64] [Batch 760/937] [D loss: 0.607301] [G loss: 0.919617]\n",
      "[Epoch 20/64] [Batch 860/937] [D loss: 0.604465] [G loss: 0.800266]\n",
      "[Epoch 21/64] [Batch 23/937] [D loss: 0.611470] [G loss: 1.016307]\n",
      "[Epoch 21/64] [Batch 123/937] [D loss: 0.630864] [G loss: 1.028192]\n",
      "[Epoch 21/64] [Batch 223/937] [D loss: 0.559020] [G loss: 1.010975]\n",
      "[Epoch 21/64] [Batch 323/937] [D loss: 0.612484] [G loss: 1.082439]\n",
      "[Epoch 21/64] [Batch 423/937] [D loss: 0.623716] [G loss: 0.793530]\n",
      "[Epoch 21/64] [Batch 523/937] [D loss: 0.635701] [G loss: 0.950412]\n",
      "[Epoch 21/64] [Batch 623/937] [D loss: 0.608121] [G loss: 1.077194]\n",
      "[Epoch 21/64] [Batch 723/937] [D loss: 0.660432] [G loss: 0.883016]\n",
      "[Epoch 21/64] [Batch 823/937] [D loss: 0.583254] [G loss: 0.874288]\n",
      "[Epoch 21/64] [Batch 923/937] [D loss: 0.631045] [G loss: 0.865718]\n",
      "[Epoch 22/64] [Batch 86/937] [D loss: 0.599142] [G loss: 1.152453]\n",
      "[Epoch 22/64] [Batch 186/937] [D loss: 0.552178] [G loss: 0.857587]\n",
      "[Epoch 22/64] [Batch 286/937] [D loss: 0.595406] [G loss: 1.201889]\n",
      "[Epoch 22/64] [Batch 386/937] [D loss: 0.565750] [G loss: 0.925346]\n",
      "[Epoch 22/64] [Batch 486/937] [D loss: 0.585318] [G loss: 0.952865]\n",
      "[Epoch 22/64] [Batch 586/937] [D loss: 0.584351] [G loss: 0.825661]\n",
      "[Epoch 22/64] [Batch 686/937] [D loss: 0.598095] [G loss: 0.978613]\n",
      "[Epoch 22/64] [Batch 786/937] [D loss: 0.637757] [G loss: 1.067938]\n",
      "[Epoch 22/64] [Batch 886/937] [D loss: 0.583438] [G loss: 0.927262]\n",
      "[Epoch 23/64] [Batch 49/937] [D loss: 0.643182] [G loss: 1.091882]\n",
      "[Epoch 23/64] [Batch 149/937] [D loss: 0.601177] [G loss: 0.922361]\n",
      "[Epoch 23/64] [Batch 249/937] [D loss: 0.592776] [G loss: 0.873914]\n",
      "[Epoch 23/64] [Batch 349/937] [D loss: 0.617466] [G loss: 0.783327]\n",
      "[Epoch 23/64] [Batch 449/937] [D loss: 0.516592] [G loss: 1.065440]\n",
      "[Epoch 23/64] [Batch 549/937] [D loss: 0.584650] [G loss: 1.064760]\n",
      "[Epoch 23/64] [Batch 649/937] [D loss: 0.594930] [G loss: 0.969036]\n",
      "[Epoch 23/64] [Batch 749/937] [D loss: 0.573880] [G loss: 1.034779]\n",
      "[Epoch 23/64] [Batch 849/937] [D loss: 0.583341] [G loss: 0.867970]\n",
      "[Epoch 24/64] [Batch 12/937] [D loss: 0.552771] [G loss: 1.045464]\n",
      "[Epoch 24/64] [Batch 112/937] [D loss: 0.603312] [G loss: 1.010025]\n",
      "[Epoch 24/64] [Batch 212/937] [D loss: 0.652720] [G loss: 0.920328]\n",
      "[Epoch 24/64] [Batch 312/937] [D loss: 0.575463] [G loss: 1.024247]\n",
      "[Epoch 24/64] [Batch 412/937] [D loss: 0.597823] [G loss: 1.041802]\n",
      "[Epoch 24/64] [Batch 512/937] [D loss: 0.682188] [G loss: 1.171535]\n",
      "[Epoch 24/64] [Batch 612/937] [D loss: 0.550212] [G loss: 0.997635]\n",
      "[Epoch 24/64] [Batch 712/937] [D loss: 0.617462] [G loss: 1.053485]\n",
      "[Epoch 24/64] [Batch 812/937] [D loss: 0.630941] [G loss: 0.989681]\n",
      "[Epoch 24/64] [Batch 912/937] [D loss: 0.609388] [G loss: 0.936619]\n",
      "[Epoch 25/64] [Batch 75/937] [D loss: 0.600333] [G loss: 0.970549]\n",
      "[Epoch 25/64] [Batch 175/937] [D loss: 0.654764] [G loss: 0.780117]\n",
      "[Epoch 25/64] [Batch 275/937] [D loss: 0.614562] [G loss: 0.903609]\n",
      "[Epoch 25/64] [Batch 375/937] [D loss: 0.609059] [G loss: 0.854288]\n",
      "[Epoch 25/64] [Batch 475/937] [D loss: 0.542460] [G loss: 1.166938]\n",
      "[Epoch 25/64] [Batch 575/937] [D loss: 0.597359] [G loss: 0.993201]\n",
      "[Epoch 25/64] [Batch 675/937] [D loss: 0.599856] [G loss: 1.012488]\n",
      "[Epoch 25/64] [Batch 775/937] [D loss: 0.567497] [G loss: 1.027838]\n",
      "[Epoch 25/64] [Batch 875/937] [D loss: 0.698983] [G loss: 0.858840]\n",
      "[Epoch 26/64] [Batch 38/937] [D loss: 0.586823] [G loss: 0.888222]\n",
      "[Epoch 26/64] [Batch 138/937] [D loss: 0.582926] [G loss: 1.086292]\n",
      "[Epoch 26/64] [Batch 238/937] [D loss: 0.647971] [G loss: 0.920018]\n",
      "[Epoch 26/64] [Batch 338/937] [D loss: 0.634995] [G loss: 0.918053]\n",
      "[Epoch 26/64] [Batch 438/937] [D loss: 0.555196] [G loss: 1.167923]\n",
      "[Epoch 26/64] [Batch 538/937] [D loss: 0.593654] [G loss: 0.909676]\n",
      "[Epoch 26/64] [Batch 638/937] [D loss: 0.620418] [G loss: 0.883986]\n",
      "[Epoch 26/64] [Batch 738/937] [D loss: 0.627642] [G loss: 0.781766]\n",
      "[Epoch 26/64] [Batch 838/937] [D loss: 0.605096] [G loss: 1.031292]\n",
      "[Epoch 27/64] [Batch 1/937] [D loss: 0.547283] [G loss: 0.938586]\n",
      "[Epoch 27/64] [Batch 101/937] [D loss: 0.614946] [G loss: 0.910417]\n",
      "[Epoch 27/64] [Batch 201/937] [D loss: 0.626974] [G loss: 1.058015]\n",
      "[Epoch 27/64] [Batch 301/937] [D loss: 0.697486] [G loss: 0.707537]\n",
      "[Epoch 27/64] [Batch 401/937] [D loss: 0.612978] [G loss: 0.887663]\n",
      "[Epoch 27/64] [Batch 501/937] [D loss: 0.629304] [G loss: 0.956270]\n",
      "[Epoch 27/64] [Batch 601/937] [D loss: 0.620495] [G loss: 0.850941]\n",
      "[Epoch 27/64] [Batch 701/937] [D loss: 0.567585] [G loss: 0.921496]\n",
      "[Epoch 27/64] [Batch 801/937] [D loss: 0.647704] [G loss: 0.751278]\n",
      "[Epoch 27/64] [Batch 901/937] [D loss: 0.579049] [G loss: 0.919348]\n",
      "[Epoch 28/64] [Batch 64/937] [D loss: 0.589277] [G loss: 1.020488]\n",
      "[Epoch 28/64] [Batch 164/937] [D loss: 0.548858] [G loss: 0.891931]\n",
      "[Epoch 28/64] [Batch 264/937] [D loss: 0.585033] [G loss: 0.888184]\n",
      "[Epoch 28/64] [Batch 364/937] [D loss: 0.585775] [G loss: 1.050111]\n",
      "[Epoch 28/64] [Batch 464/937] [D loss: 0.637055] [G loss: 0.865301]\n",
      "[Epoch 28/64] [Batch 564/937] [D loss: 0.621608] [G loss: 0.937158]\n",
      "[Epoch 28/64] [Batch 664/937] [D loss: 0.649560] [G loss: 0.847059]\n",
      "[Epoch 28/64] [Batch 764/937] [D loss: 0.622704] [G loss: 0.944075]\n",
      "[Epoch 28/64] [Batch 864/937] [D loss: 0.594897] [G loss: 0.993385]\n",
      "[Epoch 29/64] [Batch 27/937] [D loss: 0.598275] [G loss: 0.906223]\n",
      "[Epoch 29/64] [Batch 127/937] [D loss: 0.691566] [G loss: 1.091114]\n",
      "[Epoch 29/64] [Batch 227/937] [D loss: 0.642366] [G loss: 0.965926]\n",
      "[Epoch 29/64] [Batch 327/937] [D loss: 0.565930] [G loss: 0.968156]\n",
      "[Epoch 29/64] [Batch 427/937] [D loss: 0.588297] [G loss: 0.864945]\n",
      "[Epoch 29/64] [Batch 527/937] [D loss: 0.583310] [G loss: 0.892491]\n",
      "[Epoch 29/64] [Batch 627/937] [D loss: 0.546831] [G loss: 0.918210]\n",
      "[Epoch 29/64] [Batch 727/937] [D loss: 0.521438] [G loss: 0.949344]\n",
      "[Epoch 29/64] [Batch 827/937] [D loss: 0.615486] [G loss: 1.130506]\n",
      "[Epoch 29/64] [Batch 927/937] [D loss: 0.618132] [G loss: 1.081856]\n",
      "[Epoch 30/64] [Batch 90/937] [D loss: 0.624859] [G loss: 0.945993]\n",
      "[Epoch 30/64] [Batch 190/937] [D loss: 0.667840] [G loss: 0.867309]\n",
      "[Epoch 30/64] [Batch 290/937] [D loss: 0.581753] [G loss: 0.928403]\n",
      "[Epoch 30/64] [Batch 390/937] [D loss: 0.631544] [G loss: 0.939881]\n",
      "[Epoch 30/64] [Batch 490/937] [D loss: 0.593833] [G loss: 0.896118]\n",
      "[Epoch 30/64] [Batch 590/937] [D loss: 0.579974] [G loss: 0.765427]\n",
      "[Epoch 30/64] [Batch 690/937] [D loss: 0.613501] [G loss: 1.141383]\n",
      "[Epoch 30/64] [Batch 790/937] [D loss: 0.585791] [G loss: 0.969726]\n",
      "[Epoch 30/64] [Batch 890/937] [D loss: 0.622483] [G loss: 0.981114]\n",
      "[Epoch 31/64] [Batch 53/937] [D loss: 0.553802] [G loss: 1.000867]\n",
      "[Epoch 31/64] [Batch 153/937] [D loss: 0.606716] [G loss: 1.101887]\n",
      "[Epoch 31/64] [Batch 253/937] [D loss: 0.562593] [G loss: 1.034648]\n",
      "[Epoch 31/64] [Batch 353/937] [D loss: 0.645372] [G loss: 0.832865]\n",
      "[Epoch 31/64] [Batch 453/937] [D loss: 0.621611] [G loss: 0.993107]\n",
      "[Epoch 31/64] [Batch 553/937] [D loss: 0.595586] [G loss: 0.924816]\n",
      "[Epoch 31/64] [Batch 653/937] [D loss: 0.524606] [G loss: 1.016946]\n",
      "[Epoch 31/64] [Batch 753/937] [D loss: 0.651418] [G loss: 0.889153]\n",
      "[Epoch 31/64] [Batch 853/937] [D loss: 0.630543] [G loss: 1.099883]\n",
      "[Epoch 32/64] [Batch 16/937] [D loss: 0.578418] [G loss: 1.049825]\n",
      "[Epoch 32/64] [Batch 116/937] [D loss: 0.629431] [G loss: 0.874364]\n",
      "[Epoch 32/64] [Batch 216/937] [D loss: 0.597752] [G loss: 0.993174]\n",
      "[Epoch 32/64] [Batch 316/937] [D loss: 0.632808] [G loss: 0.829363]\n",
      "[Epoch 32/64] [Batch 416/937] [D loss: 0.622795] [G loss: 0.846458]\n",
      "[Epoch 32/64] [Batch 516/937] [D loss: 0.590856] [G loss: 1.031100]\n",
      "[Epoch 32/64] [Batch 616/937] [D loss: 0.579124] [G loss: 0.918730]\n",
      "[Epoch 32/64] [Batch 716/937] [D loss: 0.663267] [G loss: 0.910028]\n",
      "[Epoch 32/64] [Batch 816/937] [D loss: 0.608116] [G loss: 0.978306]\n",
      "[Epoch 32/64] [Batch 916/937] [D loss: 0.567594] [G loss: 0.971151]\n",
      "[Epoch 33/64] [Batch 79/937] [D loss: 0.607308] [G loss: 1.044506]\n",
      "[Epoch 33/64] [Batch 179/937] [D loss: 0.626654] [G loss: 1.026887]\n",
      "[Epoch 33/64] [Batch 279/937] [D loss: 0.660018] [G loss: 0.857864]\n",
      "[Epoch 33/64] [Batch 379/937] [D loss: 0.619916] [G loss: 0.969379]\n",
      "[Epoch 33/64] [Batch 479/937] [D loss: 0.597714] [G loss: 1.009789]\n",
      "[Epoch 33/64] [Batch 579/937] [D loss: 0.592759] [G loss: 0.897727]\n",
      "[Epoch 33/64] [Batch 679/937] [D loss: 0.628860] [G loss: 0.957347]\n",
      "[Epoch 33/64] [Batch 779/937] [D loss: 0.602700] [G loss: 1.023694]\n",
      "[Epoch 33/64] [Batch 879/937] [D loss: 0.563597] [G loss: 0.857623]\n",
      "[Epoch 34/64] [Batch 42/937] [D loss: 0.620881] [G loss: 0.816133]\n",
      "[Epoch 34/64] [Batch 142/937] [D loss: 0.581803] [G loss: 0.981984]\n",
      "[Epoch 34/64] [Batch 242/937] [D loss: 0.634249] [G loss: 1.158243]\n",
      "[Epoch 34/64] [Batch 342/937] [D loss: 0.663965] [G loss: 0.922900]\n",
      "[Epoch 34/64] [Batch 442/937] [D loss: 0.624400] [G loss: 0.893387]\n",
      "[Epoch 34/64] [Batch 542/937] [D loss: 0.625355] [G loss: 0.865816]\n",
      "[Epoch 34/64] [Batch 642/937] [D loss: 0.609576] [G loss: 0.877841]\n",
      "[Epoch 34/64] [Batch 742/937] [D loss: 0.604717] [G loss: 0.763615]\n",
      "[Epoch 34/64] [Batch 842/937] [D loss: 0.571925] [G loss: 1.037286]\n",
      "[Epoch 35/64] [Batch 5/937] [D loss: 0.600609] [G loss: 0.970839]\n",
      "[Epoch 35/64] [Batch 105/937] [D loss: 0.583569] [G loss: 1.010079]\n",
      "[Epoch 35/64] [Batch 205/937] [D loss: 0.597441] [G loss: 0.846500]\n",
      "[Epoch 35/64] [Batch 305/937] [D loss: 0.682178] [G loss: 1.016999]\n",
      "[Epoch 35/64] [Batch 405/937] [D loss: 0.675029] [G loss: 0.875782]\n",
      "[Epoch 35/64] [Batch 505/937] [D loss: 0.559721] [G loss: 1.097767]\n",
      "[Epoch 35/64] [Batch 605/937] [D loss: 0.585151] [G loss: 0.783353]\n",
      "[Epoch 35/64] [Batch 705/937] [D loss: 0.662962] [G loss: 0.817783]\n",
      "[Epoch 35/64] [Batch 805/937] [D loss: 0.628748] [G loss: 0.926711]\n",
      "[Epoch 35/64] [Batch 905/937] [D loss: 0.591510] [G loss: 0.844029]\n",
      "[Epoch 36/64] [Batch 68/937] [D loss: 0.607383] [G loss: 0.899362]\n",
      "[Epoch 36/64] [Batch 168/937] [D loss: 0.619428] [G loss: 0.931427]\n",
      "[Epoch 36/64] [Batch 268/937] [D loss: 0.614985] [G loss: 0.919961]\n",
      "[Epoch 36/64] [Batch 368/937] [D loss: 0.607539] [G loss: 0.983377]\n",
      "[Epoch 36/64] [Batch 468/937] [D loss: 0.573210] [G loss: 1.017676]\n",
      "[Epoch 36/64] [Batch 568/937] [D loss: 0.608487] [G loss: 0.927044]\n",
      "[Epoch 36/64] [Batch 668/937] [D loss: 0.591876] [G loss: 1.009868]\n",
      "[Epoch 36/64] [Batch 768/937] [D loss: 0.613361] [G loss: 1.100874]\n",
      "[Epoch 36/64] [Batch 868/937] [D loss: 0.637823] [G loss: 1.005891]\n",
      "[Epoch 37/64] [Batch 31/937] [D loss: 0.615633] [G loss: 0.971864]\n",
      "[Epoch 37/64] [Batch 131/937] [D loss: 0.581799] [G loss: 0.851304]\n",
      "[Epoch 37/64] [Batch 231/937] [D loss: 0.641883] [G loss: 0.937737]\n",
      "[Epoch 37/64] [Batch 331/937] [D loss: 0.559838] [G loss: 1.000554]\n",
      "[Epoch 37/64] [Batch 431/937] [D loss: 0.618486] [G loss: 0.813732]\n",
      "[Epoch 37/64] [Batch 531/937] [D loss: 0.628879] [G loss: 0.824409]\n",
      "[Epoch 37/64] [Batch 631/937] [D loss: 0.651579] [G loss: 0.876546]\n",
      "[Epoch 37/64] [Batch 731/937] [D loss: 0.629489] [G loss: 1.015376]\n",
      "[Epoch 37/64] [Batch 831/937] [D loss: 0.623347] [G loss: 0.875600]\n",
      "[Epoch 37/64] [Batch 931/937] [D loss: 0.554625] [G loss: 0.888710]\n",
      "[Epoch 38/64] [Batch 94/937] [D loss: 0.621229] [G loss: 1.069887]\n",
      "[Epoch 38/64] [Batch 194/937] [D loss: 0.600700] [G loss: 1.041508]\n",
      "[Epoch 38/64] [Batch 294/937] [D loss: 0.549352] [G loss: 0.923663]\n",
      "[Epoch 38/64] [Batch 394/937] [D loss: 0.614726] [G loss: 0.977055]\n",
      "[Epoch 38/64] [Batch 494/937] [D loss: 0.608650] [G loss: 1.165144]\n",
      "[Epoch 38/64] [Batch 594/937] [D loss: 0.654709] [G loss: 0.793394]\n",
      "[Epoch 38/64] [Batch 694/937] [D loss: 0.591610] [G loss: 0.939979]\n",
      "[Epoch 38/64] [Batch 794/937] [D loss: 0.585705] [G loss: 0.920274]\n",
      "[Epoch 38/64] [Batch 894/937] [D loss: 0.628092] [G loss: 0.915204]\n",
      "[Epoch 39/64] [Batch 57/937] [D loss: 0.623454] [G loss: 0.890651]\n",
      "[Epoch 39/64] [Batch 157/937] [D loss: 0.626379] [G loss: 0.980924]\n",
      "[Epoch 39/64] [Batch 257/937] [D loss: 0.579376] [G loss: 0.907882]\n",
      "[Epoch 39/64] [Batch 357/937] [D loss: 0.596764] [G loss: 0.873765]\n",
      "[Epoch 39/64] [Batch 457/937] [D loss: 0.606601] [G loss: 0.962200]\n",
      "[Epoch 39/64] [Batch 557/937] [D loss: 0.596935] [G loss: 1.012641]\n",
      "[Epoch 39/64] [Batch 657/937] [D loss: 0.590727] [G loss: 1.026146]\n",
      "[Epoch 39/64] [Batch 757/937] [D loss: 0.613084] [G loss: 1.027854]\n",
      "[Epoch 39/64] [Batch 857/937] [D loss: 0.600043] [G loss: 0.950180]\n",
      "[Epoch 40/64] [Batch 20/937] [D loss: 0.620320] [G loss: 0.938499]\n",
      "[Epoch 40/64] [Batch 120/937] [D loss: 0.584496] [G loss: 0.895358]\n",
      "[Epoch 40/64] [Batch 220/937] [D loss: 0.621959] [G loss: 0.983824]\n",
      "[Epoch 40/64] [Batch 320/937] [D loss: 0.561424] [G loss: 1.002248]\n",
      "[Epoch 40/64] [Batch 420/937] [D loss: 0.577852] [G loss: 0.935052]\n",
      "[Epoch 40/64] [Batch 520/937] [D loss: 0.576577] [G loss: 1.025579]\n",
      "[Epoch 40/64] [Batch 620/937] [D loss: 0.605197] [G loss: 0.844871]\n",
      "[Epoch 40/64] [Batch 720/937] [D loss: 0.614917] [G loss: 0.946732]\n",
      "[Epoch 40/64] [Batch 820/937] [D loss: 0.595305] [G loss: 0.954430]\n",
      "[Epoch 40/64] [Batch 920/937] [D loss: 0.603023] [G loss: 0.756992]\n",
      "[Epoch 41/64] [Batch 83/937] [D loss: 0.650333] [G loss: 1.072047]\n",
      "[Epoch 41/64] [Batch 183/937] [D loss: 0.572497] [G loss: 1.049240]\n",
      "[Epoch 41/64] [Batch 283/937] [D loss: 0.609204] [G loss: 0.771074]\n",
      "[Epoch 41/64] [Batch 383/937] [D loss: 0.542636] [G loss: 0.975847]\n",
      "[Epoch 41/64] [Batch 483/937] [D loss: 0.599759] [G loss: 0.906450]\n",
      "[Epoch 41/64] [Batch 583/937] [D loss: 0.581673] [G loss: 0.935747]\n",
      "[Epoch 41/64] [Batch 683/937] [D loss: 0.639531] [G loss: 0.860746]\n",
      "[Epoch 41/64] [Batch 783/937] [D loss: 0.624369] [G loss: 0.847389]\n",
      "[Epoch 41/64] [Batch 883/937] [D loss: 0.624641] [G loss: 0.878454]\n",
      "[Epoch 42/64] [Batch 46/937] [D loss: 0.604977] [G loss: 1.011113]\n",
      "[Epoch 42/64] [Batch 146/937] [D loss: 0.562661] [G loss: 1.003388]\n",
      "[Epoch 42/64] [Batch 246/937] [D loss: 0.619961] [G loss: 1.055612]\n",
      "[Epoch 42/64] [Batch 346/937] [D loss: 0.629926] [G loss: 1.088538]\n",
      "[Epoch 42/64] [Batch 446/937] [D loss: 0.618633] [G loss: 0.923425]\n",
      "[Epoch 42/64] [Batch 546/937] [D loss: 0.676897] [G loss: 0.837571]\n",
      "[Epoch 42/64] [Batch 646/937] [D loss: 0.618883] [G loss: 0.858924]\n",
      "[Epoch 42/64] [Batch 746/937] [D loss: 0.619679] [G loss: 0.880665]\n",
      "[Epoch 42/64] [Batch 846/937] [D loss: 0.572266] [G loss: 0.940564]\n",
      "[Epoch 43/64] [Batch 9/937] [D loss: 0.622629] [G loss: 0.972668]\n",
      "[Epoch 43/64] [Batch 109/937] [D loss: 0.611429] [G loss: 0.905046]\n",
      "[Epoch 43/64] [Batch 209/937] [D loss: 0.615836] [G loss: 0.861773]\n",
      "[Epoch 43/64] [Batch 309/937] [D loss: 0.628987] [G loss: 0.923244]\n",
      "[Epoch 43/64] [Batch 409/937] [D loss: 0.614252] [G loss: 0.878276]\n",
      "[Epoch 43/64] [Batch 509/937] [D loss: 0.605256] [G loss: 0.885009]\n",
      "[Epoch 43/64] [Batch 609/937] [D loss: 0.582193] [G loss: 0.894458]\n",
      "[Epoch 43/64] [Batch 709/937] [D loss: 0.609770] [G loss: 0.963835]\n",
      "[Epoch 43/64] [Batch 809/937] [D loss: 0.647367] [G loss: 1.052577]\n",
      "[Epoch 43/64] [Batch 909/937] [D loss: 0.634271] [G loss: 0.823781]\n",
      "[Epoch 44/64] [Batch 72/937] [D loss: 0.617829] [G loss: 0.963456]\n",
      "[Epoch 44/64] [Batch 172/937] [D loss: 0.633832] [G loss: 0.949141]\n",
      "[Epoch 44/64] [Batch 272/937] [D loss: 0.611791] [G loss: 0.842114]\n",
      "[Epoch 44/64] [Batch 372/937] [D loss: 0.662200] [G loss: 0.985207]\n",
      "[Epoch 44/64] [Batch 472/937] [D loss: 0.572753] [G loss: 0.994543]\n",
      "[Epoch 44/64] [Batch 572/937] [D loss: 0.614957] [G loss: 0.939059]\n",
      "[Epoch 44/64] [Batch 672/937] [D loss: 0.562909] [G loss: 1.053682]\n",
      "[Epoch 44/64] [Batch 772/937] [D loss: 0.577844] [G loss: 0.886421]\n",
      "[Epoch 44/64] [Batch 872/937] [D loss: 0.606460] [G loss: 0.936358]\n",
      "[Epoch 45/64] [Batch 35/937] [D loss: 0.612559] [G loss: 1.033344]\n",
      "[Epoch 45/64] [Batch 135/937] [D loss: 0.588176] [G loss: 0.919695]\n",
      "[Epoch 45/64] [Batch 235/937] [D loss: 0.591301] [G loss: 1.012894]\n",
      "[Epoch 45/64] [Batch 335/937] [D loss: 0.659531] [G loss: 0.823341]\n",
      "[Epoch 45/64] [Batch 435/937] [D loss: 0.664294] [G loss: 0.976107]\n",
      "[Epoch 45/64] [Batch 535/937] [D loss: 0.623608] [G loss: 0.842832]\n",
      "[Epoch 45/64] [Batch 635/937] [D loss: 0.612279] [G loss: 0.960276]\n",
      "[Epoch 45/64] [Batch 735/937] [D loss: 0.628532] [G loss: 0.996017]\n",
      "[Epoch 45/64] [Batch 835/937] [D loss: 0.614992] [G loss: 0.993320]\n",
      "[Epoch 45/64] [Batch 935/937] [D loss: 0.644727] [G loss: 0.949466]\n",
      "[Epoch 46/64] [Batch 98/937] [D loss: 0.658692] [G loss: 0.881586]\n",
      "[Epoch 46/64] [Batch 198/937] [D loss: 0.645359] [G loss: 0.896886]\n",
      "[Epoch 46/64] [Batch 298/937] [D loss: 0.671083] [G loss: 0.930393]\n",
      "[Epoch 46/64] [Batch 398/937] [D loss: 0.611304] [G loss: 1.036495]\n",
      "[Epoch 46/64] [Batch 498/937] [D loss: 0.626992] [G loss: 0.984017]\n",
      "[Epoch 46/64] [Batch 598/937] [D loss: 0.659978] [G loss: 1.046459]\n",
      "[Epoch 46/64] [Batch 698/937] [D loss: 0.618137] [G loss: 0.865515]\n",
      "[Epoch 46/64] [Batch 798/937] [D loss: 0.615680] [G loss: 0.937871]\n",
      "[Epoch 46/64] [Batch 898/937] [D loss: 0.612383] [G loss: 0.975028]\n",
      "[Epoch 47/64] [Batch 61/937] [D loss: 0.670345] [G loss: 0.910620]\n",
      "[Epoch 47/64] [Batch 161/937] [D loss: 0.666660] [G loss: 0.907930]\n",
      "[Epoch 47/64] [Batch 261/937] [D loss: 0.660988] [G loss: 0.841230]\n",
      "[Epoch 47/64] [Batch 361/937] [D loss: 0.587420] [G loss: 1.016431]\n",
      "[Epoch 47/64] [Batch 461/937] [D loss: 0.592491] [G loss: 0.957590]\n",
      "[Epoch 47/64] [Batch 561/937] [D loss: 0.600848] [G loss: 0.896594]\n",
      "[Epoch 47/64] [Batch 661/937] [D loss: 0.624923] [G loss: 0.790228]\n",
      "[Epoch 47/64] [Batch 761/937] [D loss: 0.612267] [G loss: 0.964717]\n",
      "[Epoch 47/64] [Batch 861/937] [D loss: 0.583977] [G loss: 0.963005]\n",
      "[Epoch 48/64] [Batch 24/937] [D loss: 0.592106] [G loss: 0.926947]\n",
      "[Epoch 48/64] [Batch 124/937] [D loss: 0.633013] [G loss: 1.076260]\n",
      "[Epoch 48/64] [Batch 224/937] [D loss: 0.558887] [G loss: 0.947294]\n",
      "[Epoch 48/64] [Batch 324/937] [D loss: 0.625950] [G loss: 0.983904]\n",
      "[Epoch 48/64] [Batch 424/937] [D loss: 0.661790] [G loss: 0.880859]\n",
      "[Epoch 48/64] [Batch 524/937] [D loss: 0.609776] [G loss: 0.919081]\n",
      "[Epoch 48/64] [Batch 624/937] [D loss: 0.556344] [G loss: 1.090908]\n",
      "[Epoch 48/64] [Batch 724/937] [D loss: 0.578007] [G loss: 0.822282]\n",
      "[Epoch 48/64] [Batch 824/937] [D loss: 0.610421] [G loss: 0.943228]\n",
      "[Epoch 48/64] [Batch 924/937] [D loss: 0.655523] [G loss: 0.904193]\n",
      "[Epoch 49/64] [Batch 87/937] [D loss: 0.607365] [G loss: 0.906446]\n",
      "[Epoch 49/64] [Batch 187/937] [D loss: 0.607521] [G loss: 1.014002]\n",
      "[Epoch 49/64] [Batch 287/937] [D loss: 0.528789] [G loss: 0.953496]\n",
      "[Epoch 49/64] [Batch 387/937] [D loss: 0.627003] [G loss: 1.005316]\n",
      "[Epoch 49/64] [Batch 487/937] [D loss: 0.619556] [G loss: 0.899705]\n",
      "[Epoch 49/64] [Batch 587/937] [D loss: 0.595674] [G loss: 0.967615]\n",
      "[Epoch 49/64] [Batch 687/937] [D loss: 0.604018] [G loss: 1.052146]\n",
      "[Epoch 49/64] [Batch 787/937] [D loss: 0.594537] [G loss: 0.955782]\n",
      "[Epoch 49/64] [Batch 887/937] [D loss: 0.632428] [G loss: 1.062447]\n",
      "[Epoch 50/64] [Batch 50/937] [D loss: 0.585576] [G loss: 0.947037]\n",
      "[Epoch 50/64] [Batch 150/937] [D loss: 0.659844] [G loss: 1.025496]\n",
      "[Epoch 50/64] [Batch 250/937] [D loss: 0.638264] [G loss: 0.842072]\n",
      "[Epoch 50/64] [Batch 350/937] [D loss: 0.598640] [G loss: 0.830393]\n",
      "[Epoch 50/64] [Batch 450/937] [D loss: 0.666190] [G loss: 1.084357]\n",
      "[Epoch 50/64] [Batch 550/937] [D loss: 0.615116] [G loss: 0.948828]\n",
      "[Epoch 50/64] [Batch 650/937] [D loss: 0.639356] [G loss: 0.912387]\n",
      "[Epoch 50/64] [Batch 750/937] [D loss: 0.581974] [G loss: 1.034752]\n",
      "[Epoch 50/64] [Batch 850/937] [D loss: 0.619528] [G loss: 0.956147]\n",
      "[Epoch 51/64] [Batch 13/937] [D loss: 0.593282] [G loss: 1.025298]\n",
      "[Epoch 51/64] [Batch 113/937] [D loss: 0.604044] [G loss: 0.824018]\n",
      "[Epoch 51/64] [Batch 213/937] [D loss: 0.608984] [G loss: 0.992329]\n",
      "[Epoch 51/64] [Batch 313/937] [D loss: 0.631781] [G loss: 1.033912]\n",
      "[Epoch 51/64] [Batch 413/937] [D loss: 0.606454] [G loss: 0.906980]\n",
      "[Epoch 51/64] [Batch 513/937] [D loss: 0.627183] [G loss: 0.929472]\n",
      "[Epoch 51/64] [Batch 613/937] [D loss: 0.643335] [G loss: 0.778165]\n",
      "[Epoch 51/64] [Batch 713/937] [D loss: 0.588083] [G loss: 0.952785]\n",
      "[Epoch 51/64] [Batch 813/937] [D loss: 0.643542] [G loss: 0.918388]\n",
      "[Epoch 51/64] [Batch 913/937] [D loss: 0.615637] [G loss: 0.962081]\n",
      "[Epoch 52/64] [Batch 76/937] [D loss: 0.622242] [G loss: 0.935897]\n",
      "[Epoch 52/64] [Batch 176/937] [D loss: 0.588636] [G loss: 0.930682]\n",
      "[Epoch 52/64] [Batch 276/937] [D loss: 0.578002] [G loss: 0.947652]\n",
      "[Epoch 52/64] [Batch 376/937] [D loss: 0.627258] [G loss: 0.998251]\n",
      "[Epoch 52/64] [Batch 476/937] [D loss: 0.583084] [G loss: 0.777089]\n",
      "[Epoch 52/64] [Batch 576/937] [D loss: 0.609850] [G loss: 0.942212]\n",
      "[Epoch 52/64] [Batch 676/937] [D loss: 0.617996] [G loss: 0.946300]\n",
      "[Epoch 52/64] [Batch 776/937] [D loss: 0.636908] [G loss: 0.865577]\n",
      "[Epoch 52/64] [Batch 876/937] [D loss: 0.641360] [G loss: 0.970460]\n",
      "[Epoch 53/64] [Batch 39/937] [D loss: 0.572994] [G loss: 0.968946]\n",
      "[Epoch 53/64] [Batch 139/937] [D loss: 0.629128] [G loss: 0.709891]\n",
      "[Epoch 53/64] [Batch 239/937] [D loss: 0.613273] [G loss: 0.896029]\n",
      "[Epoch 53/64] [Batch 339/937] [D loss: 0.613754] [G loss: 1.021421]\n",
      "[Epoch 53/64] [Batch 439/937] [D loss: 0.599823] [G loss: 0.937690]\n",
      "[Epoch 53/64] [Batch 539/937] [D loss: 0.689086] [G loss: 0.949827]\n",
      "[Epoch 53/64] [Batch 639/937] [D loss: 0.639248] [G loss: 0.785970]\n",
      "[Epoch 53/64] [Batch 739/937] [D loss: 0.678059] [G loss: 0.982022]\n",
      "[Epoch 53/64] [Batch 839/937] [D loss: 0.604676] [G loss: 0.948409]\n",
      "[Epoch 54/64] [Batch 2/937] [D loss: 0.708358] [G loss: 0.849474]\n",
      "[Epoch 54/64] [Batch 102/937] [D loss: 0.617316] [G loss: 0.862686]\n",
      "[Epoch 54/64] [Batch 202/937] [D loss: 0.697212] [G loss: 0.790843]\n",
      "[Epoch 54/64] [Batch 302/937] [D loss: 0.613381] [G loss: 1.088699]\n",
      "[Epoch 54/64] [Batch 402/937] [D loss: 0.632125] [G loss: 0.999159]\n",
      "[Epoch 54/64] [Batch 502/937] [D loss: 0.596270] [G loss: 0.992226]\n",
      "[Epoch 54/64] [Batch 602/937] [D loss: 0.613725] [G loss: 0.890568]\n",
      "[Epoch 54/64] [Batch 702/937] [D loss: 0.652637] [G loss: 0.687928]\n",
      "[Epoch 54/64] [Batch 802/937] [D loss: 0.646282] [G loss: 0.882911]\n",
      "[Epoch 54/64] [Batch 902/937] [D loss: 0.665796] [G loss: 0.841510]\n",
      "[Epoch 55/64] [Batch 65/937] [D loss: 0.674406] [G loss: 0.989607]\n",
      "[Epoch 55/64] [Batch 165/937] [D loss: 0.649551] [G loss: 0.826272]\n",
      "[Epoch 55/64] [Batch 265/937] [D loss: 0.661407] [G loss: 0.920181]\n",
      "[Epoch 55/64] [Batch 365/937] [D loss: 0.634338] [G loss: 0.809564]\n",
      "[Epoch 55/64] [Batch 465/937] [D loss: 0.652257] [G loss: 0.906434]\n",
      "[Epoch 55/64] [Batch 565/937] [D loss: 0.606006] [G loss: 0.888478]\n",
      "[Epoch 55/64] [Batch 665/937] [D loss: 0.618874] [G loss: 1.021762]\n",
      "[Epoch 55/64] [Batch 765/937] [D loss: 0.610690] [G loss: 0.899051]\n",
      "[Epoch 55/64] [Batch 865/937] [D loss: 0.652295] [G loss: 1.028714]\n",
      "[Epoch 56/64] [Batch 28/937] [D loss: 0.582589] [G loss: 0.852352]\n",
      "[Epoch 56/64] [Batch 128/937] [D loss: 0.598737] [G loss: 0.876309]\n",
      "[Epoch 56/64] [Batch 228/937] [D loss: 0.675781] [G loss: 0.918419]\n",
      "[Epoch 56/64] [Batch 328/937] [D loss: 0.600270] [G loss: 0.798689]\n",
      "[Epoch 56/64] [Batch 428/937] [D loss: 0.612324] [G loss: 0.788534]\n",
      "[Epoch 56/64] [Batch 528/937] [D loss: 0.622700] [G loss: 0.863401]\n",
      "[Epoch 56/64] [Batch 628/937] [D loss: 0.632159] [G loss: 1.110642]\n",
      "[Epoch 56/64] [Batch 728/937] [D loss: 0.667295] [G loss: 0.803039]\n",
      "[Epoch 56/64] [Batch 828/937] [D loss: 0.601887] [G loss: 0.844073]\n",
      "[Epoch 56/64] [Batch 928/937] [D loss: 0.597841] [G loss: 0.945214]\n",
      "[Epoch 57/64] [Batch 91/937] [D loss: 0.617005] [G loss: 0.934738]\n",
      "[Epoch 57/64] [Batch 191/937] [D loss: 0.632206] [G loss: 0.831597]\n",
      "[Epoch 57/64] [Batch 291/937] [D loss: 0.643113] [G loss: 0.960293]\n",
      "[Epoch 57/64] [Batch 391/937] [D loss: 0.643443] [G loss: 1.165003]\n",
      "[Epoch 57/64] [Batch 491/937] [D loss: 0.580557] [G loss: 0.920203]\n",
      "[Epoch 57/64] [Batch 591/937] [D loss: 0.650683] [G loss: 0.965871]\n",
      "[Epoch 57/64] [Batch 691/937] [D loss: 0.613350] [G loss: 0.908137]\n",
      "[Epoch 57/64] [Batch 791/937] [D loss: 0.632424] [G loss: 0.709041]\n",
      "[Epoch 57/64] [Batch 891/937] [D loss: 0.608375] [G loss: 1.087777]\n",
      "[Epoch 58/64] [Batch 54/937] [D loss: 0.611523] [G loss: 0.924487]\n",
      "[Epoch 58/64] [Batch 154/937] [D loss: 0.618157] [G loss: 0.985311]\n",
      "[Epoch 58/64] [Batch 254/937] [D loss: 0.646005] [G loss: 0.886135]\n",
      "[Epoch 58/64] [Batch 354/937] [D loss: 0.645914] [G loss: 0.870402]\n",
      "[Epoch 58/64] [Batch 454/937] [D loss: 0.664185] [G loss: 0.862380]\n",
      "[Epoch 58/64] [Batch 554/937] [D loss: 0.584979] [G loss: 0.903263]\n",
      "[Epoch 58/64] [Batch 654/937] [D loss: 0.620120] [G loss: 0.876046]\n",
      "[Epoch 58/64] [Batch 754/937] [D loss: 0.622269] [G loss: 1.002784]\n",
      "[Epoch 58/64] [Batch 854/937] [D loss: 0.561236] [G loss: 0.923790]\n",
      "[Epoch 59/64] [Batch 17/937] [D loss: 0.632821] [G loss: 0.937531]\n",
      "[Epoch 59/64] [Batch 117/937] [D loss: 0.596344] [G loss: 0.932588]\n",
      "[Epoch 59/64] [Batch 217/937] [D loss: 0.603379] [G loss: 0.958737]\n",
      "[Epoch 59/64] [Batch 317/937] [D loss: 0.610617] [G loss: 0.904490]\n",
      "[Epoch 59/64] [Batch 417/937] [D loss: 0.668641] [G loss: 0.993286]\n",
      "[Epoch 59/64] [Batch 517/937] [D loss: 0.631371] [G loss: 0.848798]\n",
      "[Epoch 59/64] [Batch 617/937] [D loss: 0.625401] [G loss: 0.926158]\n",
      "[Epoch 59/64] [Batch 717/937] [D loss: 0.596098] [G loss: 0.865577]\n",
      "[Epoch 59/64] [Batch 817/937] [D loss: 0.582108] [G loss: 0.814267]\n",
      "[Epoch 59/64] [Batch 917/937] [D loss: 0.607537] [G loss: 0.981130]\n",
      "[Epoch 60/64] [Batch 80/937] [D loss: 0.660458] [G loss: 0.959641]\n",
      "[Epoch 60/64] [Batch 180/937] [D loss: 0.587220] [G loss: 0.952776]\n",
      "[Epoch 60/64] [Batch 280/937] [D loss: 0.633888] [G loss: 1.060275]\n",
      "[Epoch 60/64] [Batch 380/937] [D loss: 0.687546] [G loss: 1.038375]\n",
      "[Epoch 60/64] [Batch 480/937] [D loss: 0.595111] [G loss: 0.954874]\n",
      "[Epoch 60/64] [Batch 580/937] [D loss: 0.620887] [G loss: 0.929199]\n",
      "[Epoch 60/64] [Batch 680/937] [D loss: 0.609597] [G loss: 1.031091]\n",
      "[Epoch 60/64] [Batch 780/937] [D loss: 0.681367] [G loss: 0.912822]\n",
      "[Epoch 60/64] [Batch 880/937] [D loss: 0.646141] [G loss: 0.854509]\n",
      "[Epoch 61/64] [Batch 43/937] [D loss: 0.649905] [G loss: 0.822675]\n",
      "[Epoch 61/64] [Batch 143/937] [D loss: 0.573232] [G loss: 0.891423]\n",
      "[Epoch 61/64] [Batch 243/937] [D loss: 0.677550] [G loss: 0.966594]\n",
      "[Epoch 61/64] [Batch 343/937] [D loss: 0.675059] [G loss: 0.973348]\n",
      "[Epoch 61/64] [Batch 443/937] [D loss: 0.623813] [G loss: 0.991876]\n",
      "[Epoch 61/64] [Batch 543/937] [D loss: 0.635536] [G loss: 0.937460]\n",
      "[Epoch 61/64] [Batch 643/937] [D loss: 0.589017] [G loss: 1.050996]\n",
      "[Epoch 61/64] [Batch 743/937] [D loss: 0.594092] [G loss: 1.025663]\n",
      "[Epoch 61/64] [Batch 843/937] [D loss: 0.623856] [G loss: 0.939838]\n",
      "[Epoch 62/64] [Batch 6/937] [D loss: 0.655008] [G loss: 0.990844]\n",
      "[Epoch 62/64] [Batch 106/937] [D loss: 0.596112] [G loss: 0.879476]\n",
      "[Epoch 62/64] [Batch 206/937] [D loss: 0.568327] [G loss: 0.936732]\n",
      "[Epoch 62/64] [Batch 306/937] [D loss: 0.569552] [G loss: 1.019415]\n",
      "[Epoch 62/64] [Batch 406/937] [D loss: 0.669976] [G loss: 0.706724]\n",
      "[Epoch 62/64] [Batch 506/937] [D loss: 0.642561] [G loss: 0.949091]\n",
      "[Epoch 62/64] [Batch 606/937] [D loss: 0.614532] [G loss: 0.939632]\n",
      "[Epoch 62/64] [Batch 706/937] [D loss: 0.607812] [G loss: 0.898209]\n",
      "[Epoch 62/64] [Batch 806/937] [D loss: 0.654098] [G loss: 0.940917]\n",
      "[Epoch 62/64] [Batch 906/937] [D loss: 0.617127] [G loss: 0.780361]\n",
      "[Epoch 63/64] [Batch 69/937] [D loss: 0.689788] [G loss: 0.872016]\n",
      "[Epoch 63/64] [Batch 169/937] [D loss: 0.567155] [G loss: 0.972275]\n",
      "[Epoch 63/64] [Batch 269/937] [D loss: 0.613183] [G loss: 0.896983]\n",
      "[Epoch 63/64] [Batch 369/937] [D loss: 0.640839] [G loss: 0.995394]\n",
      "[Epoch 63/64] [Batch 469/937] [D loss: 0.636140] [G loss: 0.862971]\n",
      "[Epoch 63/64] [Batch 569/937] [D loss: 0.640116] [G loss: 1.062915]\n",
      "[Epoch 63/64] [Batch 669/937] [D loss: 0.644602] [G loss: 0.842874]\n",
      "[Epoch 63/64] [Batch 769/937] [D loss: 0.596655] [G loss: 0.838531]\n",
      "[Epoch 63/64] [Batch 869/937] [D loss: 0.616074] [G loss: 0.918102]\n",
      "[Epoch 64/64] [Batch 32/937] [D loss: 0.569945] [G loss: 0.865774]\n",
      "[Epoch 64/64] [Batch 132/937] [D loss: 0.602453] [G loss: 0.822212]\n",
      "[Epoch 64/64] [Batch 232/937] [D loss: 0.603292] [G loss: 0.891338]\n",
      "[Epoch 64/64] [Batch 332/937] [D loss: 0.565405] [G loss: 1.061662]\n",
      "[Epoch 64/64] [Batch 432/937] [D loss: 0.611121] [G loss: 0.964072]\n",
      "[Epoch 64/64] [Batch 532/937] [D loss: 0.600478] [G loss: 0.972072]\n",
      "[Epoch 64/64] [Batch 632/937] [D loss: 0.621953] [G loss: 0.944349]\n",
      "[Epoch 64/64] [Batch 732/937] [D loss: 0.654789] [G loss: 0.864538]\n",
      "[Epoch 64/64] [Batch 832/937] [D loss: 0.592141] [G loss: 0.909613]\n",
      "[Epoch 64/64] [Batch 932/937] [D loss: 0.532298] [G loss: 1.003542]\n",
      "[Epoch 65/64] [Batch 95/937] [D loss: 0.588746] [G loss: 0.940361]\n",
      "[Epoch 65/64] [Batch 195/937] [D loss: 0.587366] [G loss: 0.949180]\n",
      "[Epoch 65/64] [Batch 295/937] [D loss: 0.586948] [G loss: 1.022642]\n",
      "[Epoch 65/64] [Batch 395/937] [D loss: 0.598991] [G loss: 0.916628]\n",
      "[Epoch 65/64] [Batch 495/937] [D loss: 0.629713] [G loss: 0.952580]\n",
      "[Epoch 65/64] [Batch 595/937] [D loss: 0.617471] [G loss: 1.003601]\n",
      "[Epoch 65/64] [Batch 695/937] [D loss: 0.636498] [G loss: 0.873086]\n",
      "[Epoch 65/64] [Batch 795/937] [D loss: 0.635798] [G loss: 0.841042]\n",
      "[Epoch 65/64] [Batch 895/937] [D loss: 0.557390] [G loss: 0.944760]\n",
      "[Epoch 66/64] [Batch 58/937] [D loss: 0.617842] [G loss: 0.923896]\n",
      "[Epoch 66/64] [Batch 158/937] [D loss: 0.674638] [G loss: 1.070146]\n",
      "[Epoch 66/64] [Batch 258/937] [D loss: 0.670247] [G loss: 0.959832]\n",
      "[Epoch 66/64] [Batch 358/937] [D loss: 0.579414] [G loss: 0.945412]\n",
      "[Epoch 66/64] [Batch 458/937] [D loss: 0.627203] [G loss: 0.859778]\n",
      "[Epoch 66/64] [Batch 558/937] [D loss: 0.613854] [G loss: 0.987221]\n",
      "[Epoch 66/64] [Batch 658/937] [D loss: 0.596424] [G loss: 1.003465]\n",
      "[Epoch 66/64] [Batch 758/937] [D loss: 0.642645] [G loss: 0.903586]\n",
      "[Epoch 66/64] [Batch 858/937] [D loss: 0.629756] [G loss: 1.029128]\n",
      "[Epoch 67/64] [Batch 21/937] [D loss: 0.618941] [G loss: 1.001740]\n",
      "[Epoch 67/64] [Batch 121/937] [D loss: 0.650454] [G loss: 0.909197]\n",
      "[Epoch 67/64] [Batch 221/937] [D loss: 0.654079] [G loss: 0.894283]\n",
      "[Epoch 67/64] [Batch 321/937] [D loss: 0.625855] [G loss: 0.815260]\n",
      "[Epoch 67/64] [Batch 421/937] [D loss: 0.597600] [G loss: 0.886292]\n",
      "[Epoch 67/64] [Batch 521/937] [D loss: 0.610522] [G loss: 1.018402]\n",
      "[Epoch 67/64] [Batch 621/937] [D loss: 0.624556] [G loss: 0.887315]\n",
      "[Epoch 67/64] [Batch 721/937] [D loss: 0.647069] [G loss: 1.024141]\n",
      "[Epoch 67/64] [Batch 821/937] [D loss: 0.637867] [G loss: 0.912350]\n",
      "[Epoch 67/64] [Batch 921/937] [D loss: 0.637894] [G loss: 0.923091]\n",
      "[Epoch 68/64] [Batch 84/937] [D loss: 0.629962] [G loss: 0.968172]\n",
      "[Epoch 68/64] [Batch 184/937] [D loss: 0.659811] [G loss: 0.888068]\n",
      "[Epoch 68/64] [Batch 284/937] [D loss: 0.646337] [G loss: 0.932230]\n",
      "[Epoch 68/64] [Batch 384/937] [D loss: 0.650238] [G loss: 1.043221]\n",
      "[Epoch 68/64] [Batch 484/937] [D loss: 0.602787] [G loss: 0.884830]\n",
      "[Epoch 68/64] [Batch 584/937] [D loss: 0.608320] [G loss: 0.856068]\n",
      "[Epoch 68/64] [Batch 684/937] [D loss: 0.572692] [G loss: 0.994668]\n",
      "[Epoch 68/64] [Batch 784/937] [D loss: 0.618267] [G loss: 0.873994]\n",
      "[Epoch 68/64] [Batch 884/937] [D loss: 0.683685] [G loss: 0.857445]\n",
      "[Epoch 69/64] [Batch 47/937] [D loss: 0.639507] [G loss: 0.997154]\n",
      "[Epoch 69/64] [Batch 147/937] [D loss: 0.628923] [G loss: 0.891665]\n",
      "[Epoch 69/64] [Batch 247/937] [D loss: 0.636147] [G loss: 0.894881]\n",
      "[Epoch 69/64] [Batch 347/937] [D loss: 0.565360] [G loss: 0.925602]\n",
      "[Epoch 69/64] [Batch 447/937] [D loss: 0.559987] [G loss: 1.111549]\n",
      "[Epoch 69/64] [Batch 547/937] [D loss: 0.676785] [G loss: 0.828106]\n",
      "[Epoch 69/64] [Batch 647/937] [D loss: 0.635427] [G loss: 0.903746]\n",
      "[Epoch 69/64] [Batch 747/937] [D loss: 0.617763] [G loss: 1.171861]\n",
      "[Epoch 69/64] [Batch 847/937] [D loss: 0.636182] [G loss: 0.958086]\n",
      "[Epoch 70/64] [Batch 10/937] [D loss: 0.606168] [G loss: 0.963707]\n",
      "[Epoch 70/64] [Batch 110/937] [D loss: 0.660660] [G loss: 0.807756]\n",
      "[Epoch 70/64] [Batch 210/937] [D loss: 0.590130] [G loss: 1.018459]\n",
      "[Epoch 70/64] [Batch 310/937] [D loss: 0.627244] [G loss: 0.979759]\n",
      "[Epoch 70/64] [Batch 410/937] [D loss: 0.637264] [G loss: 1.024891]\n",
      "[Epoch 70/64] [Batch 510/937] [D loss: 0.656170] [G loss: 0.803653]\n",
      "[Epoch 70/64] [Batch 610/937] [D loss: 0.592053] [G loss: 0.897065]\n",
      "[Epoch 70/64] [Batch 710/937] [D loss: 0.613265] [G loss: 0.948808]\n",
      "[Epoch 70/64] [Batch 810/937] [D loss: 0.600426] [G loss: 1.019665]\n",
      "[Epoch 70/64] [Batch 910/937] [D loss: 0.626712] [G loss: 0.879584]\n",
      "[Epoch 71/64] [Batch 73/937] [D loss: 0.593987] [G loss: 0.991754]\n",
      "[Epoch 71/64] [Batch 173/937] [D loss: 0.599482] [G loss: 0.847863]\n",
      "[Epoch 71/64] [Batch 273/937] [D loss: 0.618386] [G loss: 0.937003]\n",
      "[Epoch 71/64] [Batch 373/937] [D loss: 0.606210] [G loss: 0.894181]\n",
      "[Epoch 71/64] [Batch 473/937] [D loss: 0.670208] [G loss: 0.985267]\n",
      "[Epoch 71/64] [Batch 573/937] [D loss: 0.669161] [G loss: 0.856170]\n",
      "[Epoch 71/64] [Batch 673/937] [D loss: 0.604020] [G loss: 0.962671]\n",
      "[Epoch 71/64] [Batch 773/937] [D loss: 0.594763] [G loss: 0.863878]\n",
      "[Epoch 71/64] [Batch 873/937] [D loss: 0.630988] [G loss: 0.862115]\n",
      "[Epoch 72/64] [Batch 36/937] [D loss: 0.606526] [G loss: 0.912852]\n",
      "[Epoch 72/64] [Batch 136/937] [D loss: 0.633511] [G loss: 0.881543]\n",
      "[Epoch 72/64] [Batch 236/937] [D loss: 0.649580] [G loss: 0.949726]\n",
      "[Epoch 72/64] [Batch 336/937] [D loss: 0.603040] [G loss: 0.824938]\n",
      "[Epoch 72/64] [Batch 436/937] [D loss: 0.609125] [G loss: 0.967338]\n",
      "[Epoch 72/64] [Batch 536/937] [D loss: 0.683147] [G loss: 0.880912]\n",
      "[Epoch 72/64] [Batch 636/937] [D loss: 0.618903] [G loss: 0.974928]\n",
      "[Epoch 72/64] [Batch 736/937] [D loss: 0.617164] [G loss: 0.861818]\n",
      "[Epoch 72/64] [Batch 836/937] [D loss: 0.669277] [G loss: 0.993348]\n",
      "[Epoch 72/64] [Batch 936/937] [D loss: 0.589611] [G loss: 0.985460]\n",
      "[Epoch 73/64] [Batch 99/937] [D loss: 0.621526] [G loss: 0.990622]\n",
      "[Epoch 73/64] [Batch 199/937] [D loss: 0.659030] [G loss: 0.986907]\n",
      "[Epoch 73/64] [Batch 299/937] [D loss: 0.628075] [G loss: 0.983092]\n",
      "[Epoch 73/64] [Batch 399/937] [D loss: 0.590447] [G loss: 0.922295]\n",
      "[Epoch 73/64] [Batch 499/937] [D loss: 0.679275] [G loss: 0.891685]\n",
      "[Epoch 73/64] [Batch 599/937] [D loss: 0.615552] [G loss: 0.989894]\n",
      "[Epoch 73/64] [Batch 699/937] [D loss: 0.571850] [G loss: 1.006128]\n",
      "[Epoch 73/64] [Batch 799/937] [D loss: 0.637942] [G loss: 0.898135]\n",
      "[Epoch 73/64] [Batch 899/937] [D loss: 0.623015] [G loss: 0.917970]\n",
      "[Epoch 74/64] [Batch 62/937] [D loss: 0.657004] [G loss: 0.874411]\n",
      "[Epoch 74/64] [Batch 162/937] [D loss: 0.669957] [G loss: 1.042177]\n",
      "[Epoch 74/64] [Batch 262/937] [D loss: 0.627615] [G loss: 0.837140]\n",
      "[Epoch 74/64] [Batch 362/937] [D loss: 0.631897] [G loss: 0.787534]\n",
      "[Epoch 74/64] [Batch 462/937] [D loss: 0.629634] [G loss: 0.897053]\n",
      "[Epoch 74/64] [Batch 562/937] [D loss: 0.693195] [G loss: 0.975913]\n",
      "[Epoch 74/64] [Batch 662/937] [D loss: 0.590300] [G loss: 0.841905]\n",
      "[Epoch 74/64] [Batch 762/937] [D loss: 0.611055] [G loss: 0.859190]\n",
      "[Epoch 74/64] [Batch 862/937] [D loss: 0.620679] [G loss: 0.878734]\n",
      "[Epoch 75/64] [Batch 25/937] [D loss: 0.607102] [G loss: 0.922740]\n",
      "[Epoch 75/64] [Batch 125/937] [D loss: 0.689530] [G loss: 0.879680]\n",
      "[Epoch 75/64] [Batch 225/937] [D loss: 0.626367] [G loss: 0.754371]\n",
      "[Epoch 75/64] [Batch 325/937] [D loss: 0.673009] [G loss: 0.869307]\n",
      "[Epoch 75/64] [Batch 425/937] [D loss: 0.608614] [G loss: 0.919147]\n",
      "[Epoch 75/64] [Batch 525/937] [D loss: 0.679047] [G loss: 0.770778]\n",
      "[Epoch 75/64] [Batch 625/937] [D loss: 0.668470] [G loss: 1.141912]\n",
      "[Epoch 75/64] [Batch 725/937] [D loss: 0.638483] [G loss: 1.006606]\n",
      "[Epoch 75/64] [Batch 825/937] [D loss: 0.639717] [G loss: 0.902863]\n",
      "[Epoch 75/64] [Batch 925/937] [D loss: 0.576834] [G loss: 0.986691]\n",
      "[Epoch 76/64] [Batch 88/937] [D loss: 0.635631] [G loss: 1.070613]\n",
      "[Epoch 76/64] [Batch 188/937] [D loss: 0.647598] [G loss: 0.929262]\n",
      "[Epoch 76/64] [Batch 288/937] [D loss: 0.706172] [G loss: 0.879104]\n",
      "[Epoch 76/64] [Batch 388/937] [D loss: 0.654522] [G loss: 0.836204]\n",
      "[Epoch 76/64] [Batch 488/937] [D loss: 0.612167] [G loss: 0.900863]\n",
      "[Epoch 76/64] [Batch 588/937] [D loss: 0.588488] [G loss: 0.971771]\n",
      "[Epoch 76/64] [Batch 688/937] [D loss: 0.617575] [G loss: 1.019522]\n",
      "[Epoch 76/64] [Batch 788/937] [D loss: 0.639616] [G loss: 0.878317]\n",
      "[Epoch 76/64] [Batch 888/937] [D loss: 0.613685] [G loss: 0.869528]\n",
      "[Epoch 77/64] [Batch 51/937] [D loss: 0.621206] [G loss: 0.971361]\n",
      "[Epoch 77/64] [Batch 151/937] [D loss: 0.629415] [G loss: 0.895202]\n",
      "[Epoch 77/64] [Batch 251/937] [D loss: 0.576402] [G loss: 0.842443]\n",
      "[Epoch 77/64] [Batch 351/937] [D loss: 0.611387] [G loss: 0.884267]\n",
      "[Epoch 77/64] [Batch 451/937] [D loss: 0.598744] [G loss: 0.806060]\n",
      "[Epoch 77/64] [Batch 551/937] [D loss: 0.595140] [G loss: 0.924805]\n",
      "[Epoch 77/64] [Batch 651/937] [D loss: 0.651039] [G loss: 0.929799]\n",
      "[Epoch 77/64] [Batch 751/937] [D loss: 0.671855] [G loss: 0.869754]\n",
      "[Epoch 77/64] [Batch 851/937] [D loss: 0.676411] [G loss: 0.772134]\n",
      "[Epoch 78/64] [Batch 14/937] [D loss: 0.662193] [G loss: 0.874197]\n",
      "[Epoch 78/64] [Batch 114/937] [D loss: 0.634772] [G loss: 0.886934]\n",
      "[Epoch 78/64] [Batch 214/937] [D loss: 0.648413] [G loss: 1.038152]\n",
      "[Epoch 78/64] [Batch 314/937] [D loss: 0.636130] [G loss: 0.859098]\n",
      "[Epoch 78/64] [Batch 414/937] [D loss: 0.712280] [G loss: 0.779729]\n",
      "[Epoch 78/64] [Batch 514/937] [D loss: 0.663898] [G loss: 0.807330]\n",
      "[Epoch 78/64] [Batch 614/937] [D loss: 0.651674] [G loss: 1.009925]\n",
      "[Epoch 78/64] [Batch 714/937] [D loss: 0.610218] [G loss: 0.941440]\n",
      "[Epoch 78/64] [Batch 814/937] [D loss: 0.691650] [G loss: 0.861855]\n",
      "[Epoch 78/64] [Batch 914/937] [D loss: 0.626474] [G loss: 0.990100]\n",
      "[Epoch 79/64] [Batch 77/937] [D loss: 0.591610] [G loss: 1.002591]\n",
      "[Epoch 79/64] [Batch 177/937] [D loss: 0.624617] [G loss: 1.086605]\n",
      "[Epoch 79/64] [Batch 277/937] [D loss: 0.590765] [G loss: 0.925718]\n",
      "[Epoch 79/64] [Batch 377/937] [D loss: 0.680425] [G loss: 0.871364]\n",
      "[Epoch 79/64] [Batch 477/937] [D loss: 0.645420] [G loss: 0.930609]\n",
      "[Epoch 79/64] [Batch 577/937] [D loss: 0.653338] [G loss: 0.975639]\n",
      "[Epoch 79/64] [Batch 677/937] [D loss: 0.658479] [G loss: 1.078561]\n",
      "[Epoch 79/64] [Batch 777/937] [D loss: 0.629337] [G loss: 0.808372]\n",
      "[Epoch 79/64] [Batch 877/937] [D loss: 0.636886] [G loss: 0.965902]\n",
      "[Epoch 80/64] [Batch 40/937] [D loss: 0.595299] [G loss: 0.940881]\n",
      "[Epoch 80/64] [Batch 140/937] [D loss: 0.613547] [G loss: 0.915110]\n",
      "[Epoch 80/64] [Batch 240/937] [D loss: 0.625842] [G loss: 0.940788]\n",
      "[Epoch 80/64] [Batch 340/937] [D loss: 0.577118] [G loss: 1.041689]\n",
      "[Epoch 80/64] [Batch 440/937] [D loss: 0.613306] [G loss: 0.866965]\n",
      "[Epoch 80/64] [Batch 540/937] [D loss: 0.596902] [G loss: 0.954954]\n",
      "[Epoch 80/64] [Batch 640/937] [D loss: 0.613462] [G loss: 0.993302]\n",
      "[Epoch 80/64] [Batch 740/937] [D loss: 0.641082] [G loss: 0.909838]\n",
      "[Epoch 80/64] [Batch 840/937] [D loss: 0.614065] [G loss: 0.861660]\n",
      "[Epoch 81/64] [Batch 3/937] [D loss: 0.638932] [G loss: 0.866383]\n",
      "[Epoch 81/64] [Batch 103/937] [D loss: 0.625824] [G loss: 0.966551]\n",
      "[Epoch 81/64] [Batch 203/937] [D loss: 0.626255] [G loss: 0.846659]\n",
      "[Epoch 81/64] [Batch 303/937] [D loss: 0.611426] [G loss: 0.830463]\n",
      "[Epoch 81/64] [Batch 403/937] [D loss: 0.601680] [G loss: 0.881633]\n",
      "[Epoch 81/64] [Batch 503/937] [D loss: 0.597041] [G loss: 1.040379]\n",
      "[Epoch 81/64] [Batch 603/937] [D loss: 0.618471] [G loss: 0.945666]\n",
      "[Epoch 81/64] [Batch 703/937] [D loss: 0.636375] [G loss: 0.901206]\n",
      "[Epoch 81/64] [Batch 803/937] [D loss: 0.605574] [G loss: 0.904123]\n",
      "[Epoch 81/64] [Batch 903/937] [D loss: 0.594482] [G loss: 0.984369]\n",
      "[Epoch 82/64] [Batch 66/937] [D loss: 0.595766] [G loss: 0.904725]\n",
      "[Epoch 82/64] [Batch 166/937] [D loss: 0.596860] [G loss: 1.026170]\n",
      "[Epoch 82/64] [Batch 266/937] [D loss: 0.598122] [G loss: 0.935441]\n",
      "[Epoch 82/64] [Batch 366/937] [D loss: 0.656303] [G loss: 0.912274]\n",
      "[Epoch 82/64] [Batch 466/937] [D loss: 0.618235] [G loss: 0.890057]\n",
      "[Epoch 82/64] [Batch 566/937] [D loss: 0.599537] [G loss: 1.042763]\n",
      "[Epoch 82/64] [Batch 666/937] [D loss: 0.602599] [G loss: 0.941017]\n",
      "[Epoch 82/64] [Batch 766/937] [D loss: 0.639096] [G loss: 0.886648]\n",
      "[Epoch 82/64] [Batch 866/937] [D loss: 0.653344] [G loss: 0.894372]\n",
      "[Epoch 83/64] [Batch 29/937] [D loss: 0.578403] [G loss: 0.982114]\n",
      "[Epoch 83/64] [Batch 129/937] [D loss: 0.615838] [G loss: 0.957477]\n",
      "[Epoch 83/64] [Batch 229/937] [D loss: 0.701068] [G loss: 0.897494]\n",
      "[Epoch 83/64] [Batch 329/937] [D loss: 0.693521] [G loss: 0.861832]\n",
      "[Epoch 83/64] [Batch 429/937] [D loss: 0.614097] [G loss: 0.995250]\n",
      "[Epoch 83/64] [Batch 529/937] [D loss: 0.630685] [G loss: 0.932524]\n",
      "[Epoch 83/64] [Batch 629/937] [D loss: 0.655366] [G loss: 0.937639]\n",
      "[Epoch 83/64] [Batch 729/937] [D loss: 0.627160] [G loss: 0.843682]\n",
      "[Epoch 83/64] [Batch 829/937] [D loss: 0.590242] [G loss: 0.931004]\n",
      "[Epoch 83/64] [Batch 929/937] [D loss: 0.642724] [G loss: 0.950054]\n",
      "[Epoch 84/64] [Batch 92/937] [D loss: 0.594266] [G loss: 0.882453]\n",
      "[Epoch 84/64] [Batch 192/937] [D loss: 0.635255] [G loss: 0.905619]\n",
      "[Epoch 84/64] [Batch 292/937] [D loss: 0.613974] [G loss: 0.944626]\n",
      "[Epoch 84/64] [Batch 392/937] [D loss: 0.599668] [G loss: 0.897412]\n",
      "[Epoch 84/64] [Batch 492/937] [D loss: 0.632964] [G loss: 0.836062]\n",
      "[Epoch 84/64] [Batch 592/937] [D loss: 0.635336] [G loss: 0.924531]\n",
      "[Epoch 84/64] [Batch 692/937] [D loss: 0.614693] [G loss: 1.019943]\n",
      "[Epoch 84/64] [Batch 792/937] [D loss: 0.649281] [G loss: 0.722613]\n",
      "[Epoch 84/64] [Batch 892/937] [D loss: 0.639325] [G loss: 0.999909]\n",
      "[Epoch 85/64] [Batch 55/937] [D loss: 0.676910] [G loss: 0.830204]\n",
      "[Epoch 85/64] [Batch 155/937] [D loss: 0.649518] [G loss: 0.865440]\n",
      "[Epoch 85/64] [Batch 255/937] [D loss: 0.645887] [G loss: 0.821139]\n",
      "[Epoch 85/64] [Batch 355/937] [D loss: 0.673150] [G loss: 0.892146]\n",
      "[Epoch 85/64] [Batch 455/937] [D loss: 0.661554] [G loss: 0.973727]\n",
      "[Epoch 85/64] [Batch 555/937] [D loss: 0.622508] [G loss: 0.895926]\n",
      "[Epoch 85/64] [Batch 655/937] [D loss: 0.695690] [G loss: 0.876601]\n",
      "[Epoch 85/64] [Batch 755/937] [D loss: 0.563609] [G loss: 0.867279]\n",
      "[Epoch 85/64] [Batch 855/937] [D loss: 0.679848] [G loss: 0.803401]\n",
      "[Epoch 86/64] [Batch 18/937] [D loss: 0.638666] [G loss: 0.911893]\n",
      "[Epoch 86/64] [Batch 118/937] [D loss: 0.611978] [G loss: 0.907344]\n",
      "[Epoch 86/64] [Batch 218/937] [D loss: 0.693770] [G loss: 0.905078]\n",
      "[Epoch 86/64] [Batch 318/937] [D loss: 0.607643] [G loss: 0.836470]\n",
      "[Epoch 86/64] [Batch 418/937] [D loss: 0.603860] [G loss: 0.906806]\n",
      "[Epoch 86/64] [Batch 518/937] [D loss: 0.586919] [G loss: 0.941819]\n",
      "[Epoch 86/64] [Batch 618/937] [D loss: 0.669004] [G loss: 0.992056]\n",
      "[Epoch 86/64] [Batch 718/937] [D loss: 0.595462] [G loss: 0.865848]\n",
      "[Epoch 86/64] [Batch 818/937] [D loss: 0.670554] [G loss: 0.871044]\n",
      "[Epoch 86/64] [Batch 918/937] [D loss: 0.585314] [G loss: 0.851318]\n",
      "[Epoch 87/64] [Batch 81/937] [D loss: 0.581005] [G loss: 1.077567]\n",
      "[Epoch 87/64] [Batch 181/937] [D loss: 0.615377] [G loss: 0.987778]\n",
      "[Epoch 87/64] [Batch 281/937] [D loss: 0.631975] [G loss: 0.791608]\n",
      "[Epoch 87/64] [Batch 381/937] [D loss: 0.614913] [G loss: 0.839092]\n",
      "[Epoch 87/64] [Batch 481/937] [D loss: 0.578754] [G loss: 0.934470]\n",
      "[Epoch 87/64] [Batch 581/937] [D loss: 0.669679] [G loss: 0.850504]\n",
      "[Epoch 87/64] [Batch 681/937] [D loss: 0.605425] [G loss: 0.881650]\n",
      "[Epoch 87/64] [Batch 781/937] [D loss: 0.626467] [G loss: 0.968434]\n",
      "[Epoch 87/64] [Batch 881/937] [D loss: 0.580640] [G loss: 0.854342]\n",
      "[Epoch 88/64] [Batch 44/937] [D loss: 0.621090] [G loss: 0.928977]\n",
      "[Epoch 88/64] [Batch 144/937] [D loss: 0.645033] [G loss: 0.839362]\n",
      "[Epoch 88/64] [Batch 244/937] [D loss: 0.653833] [G loss: 0.911275]\n",
      "[Epoch 88/64] [Batch 344/937] [D loss: 0.651665] [G loss: 0.896011]\n",
      "[Epoch 88/64] [Batch 444/937] [D loss: 0.610644] [G loss: 0.845291]\n",
      "[Epoch 88/64] [Batch 544/937] [D loss: 0.652384] [G loss: 0.951213]\n",
      "[Epoch 88/64] [Batch 644/937] [D loss: 0.664068] [G loss: 0.945326]\n",
      "[Epoch 88/64] [Batch 744/937] [D loss: 0.570845] [G loss: 0.920714]\n",
      "[Epoch 88/64] [Batch 844/937] [D loss: 0.626331] [G loss: 0.889001]\n",
      "[Epoch 89/64] [Batch 7/937] [D loss: 0.654470] [G loss: 0.955195]\n",
      "[Epoch 89/64] [Batch 107/937] [D loss: 0.623708] [G loss: 0.813441]\n",
      "[Epoch 89/64] [Batch 207/937] [D loss: 0.571484] [G loss: 0.922000]\n",
      "[Epoch 89/64] [Batch 307/937] [D loss: 0.593439] [G loss: 0.967705]\n",
      "[Epoch 89/64] [Batch 407/937] [D loss: 0.631549] [G loss: 0.950021]\n",
      "[Epoch 89/64] [Batch 507/937] [D loss: 0.653937] [G loss: 0.910284]\n",
      "[Epoch 89/64] [Batch 607/937] [D loss: 0.607757] [G loss: 0.899145]\n",
      "[Epoch 89/64] [Batch 707/937] [D loss: 0.623123] [G loss: 0.856801]\n",
      "[Epoch 89/64] [Batch 807/937] [D loss: 0.648439] [G loss: 0.889092]\n",
      "[Epoch 89/64] [Batch 907/937] [D loss: 0.625516] [G loss: 0.979782]\n",
      "[Epoch 90/64] [Batch 70/937] [D loss: 0.642990] [G loss: 0.966136]\n",
      "[Epoch 90/64] [Batch 170/937] [D loss: 0.596254] [G loss: 0.952602]\n",
      "[Epoch 90/64] [Batch 270/937] [D loss: 0.572969] [G loss: 1.035736]\n",
      "[Epoch 90/64] [Batch 370/937] [D loss: 0.607266] [G loss: 0.930159]\n",
      "[Epoch 90/64] [Batch 470/937] [D loss: 0.667537] [G loss: 0.844932]\n",
      "[Epoch 90/64] [Batch 570/937] [D loss: 0.597262] [G loss: 0.865995]\n",
      "[Epoch 90/64] [Batch 670/937] [D loss: 0.620526] [G loss: 0.823336]\n",
      "[Epoch 90/64] [Batch 770/937] [D loss: 0.634834] [G loss: 0.888253]\n",
      "[Epoch 90/64] [Batch 870/937] [D loss: 0.620406] [G loss: 0.898509]\n",
      "[Epoch 91/64] [Batch 33/937] [D loss: 0.659219] [G loss: 0.868383]\n",
      "[Epoch 91/64] [Batch 133/937] [D loss: 0.625994] [G loss: 0.972357]\n",
      "[Epoch 91/64] [Batch 233/937] [D loss: 0.593423] [G loss: 0.864342]\n",
      "[Epoch 91/64] [Batch 333/937] [D loss: 0.602684] [G loss: 0.870494]\n",
      "[Epoch 91/64] [Batch 433/937] [D loss: 0.605608] [G loss: 0.876499]\n",
      "[Epoch 91/64] [Batch 533/937] [D loss: 0.633793] [G loss: 0.871819]\n",
      "[Epoch 91/64] [Batch 633/937] [D loss: 0.594400] [G loss: 0.973616]\n",
      "[Epoch 91/64] [Batch 733/937] [D loss: 0.639777] [G loss: 0.993070]\n",
      "[Epoch 91/64] [Batch 833/937] [D loss: 0.642894] [G loss: 0.811744]\n",
      "[Epoch 91/64] [Batch 933/937] [D loss: 0.614534] [G loss: 0.869756]\n",
      "[Epoch 92/64] [Batch 96/937] [D loss: 0.674046] [G loss: 0.925284]\n",
      "[Epoch 92/64] [Batch 196/937] [D loss: 0.600052] [G loss: 0.879725]\n",
      "[Epoch 92/64] [Batch 296/937] [D loss: 0.655957] [G loss: 0.849768]\n",
      "[Epoch 92/64] [Batch 396/937] [D loss: 0.642651] [G loss: 0.928170]\n",
      "[Epoch 92/64] [Batch 496/937] [D loss: 0.630104] [G loss: 0.928605]\n",
      "[Epoch 92/64] [Batch 596/937] [D loss: 0.652126] [G loss: 0.941233]\n",
      "[Epoch 92/64] [Batch 696/937] [D loss: 0.625567] [G loss: 0.973612]\n",
      "[Epoch 92/64] [Batch 796/937] [D loss: 0.615607] [G loss: 0.948800]\n",
      "[Epoch 92/64] [Batch 896/937] [D loss: 0.602645] [G loss: 0.934164]\n",
      "[Epoch 93/64] [Batch 59/937] [D loss: 0.704257] [G loss: 0.904531]\n",
      "[Epoch 93/64] [Batch 159/937] [D loss: 0.631891] [G loss: 0.923706]\n",
      "[Epoch 93/64] [Batch 259/937] [D loss: 0.616406] [G loss: 0.896909]\n",
      "[Epoch 93/64] [Batch 359/937] [D loss: 0.628072] [G loss: 0.802043]\n",
      "[Epoch 93/64] [Batch 459/937] [D loss: 0.609671] [G loss: 0.921726]\n",
      "[Epoch 93/64] [Batch 559/937] [D loss: 0.661421] [G loss: 0.845370]\n",
      "[Epoch 93/64] [Batch 659/937] [D loss: 0.620546] [G loss: 1.042731]\n",
      "[Epoch 93/64] [Batch 759/937] [D loss: 0.631650] [G loss: 1.068290]\n",
      "[Epoch 93/64] [Batch 859/937] [D loss: 0.629606] [G loss: 0.854648]\n",
      "[Epoch 94/64] [Batch 22/937] [D loss: 0.618794] [G loss: 0.839970]\n",
      "[Epoch 94/64] [Batch 122/937] [D loss: 0.645618] [G loss: 0.908620]\n",
      "[Epoch 94/64] [Batch 222/937] [D loss: 0.646658] [G loss: 0.892817]\n",
      "[Epoch 94/64] [Batch 322/937] [D loss: 0.596212] [G loss: 0.808248]\n",
      "[Epoch 94/64] [Batch 422/937] [D loss: 0.601627] [G loss: 0.780627]\n",
      "[Epoch 94/64] [Batch 522/937] [D loss: 0.642945] [G loss: 0.831300]\n",
      "[Epoch 94/64] [Batch 622/937] [D loss: 0.650775] [G loss: 0.954517]\n",
      "[Epoch 94/64] [Batch 722/937] [D loss: 0.644411] [G loss: 0.909396]\n",
      "[Epoch 94/64] [Batch 822/937] [D loss: 0.576394] [G loss: 0.914523]\n",
      "[Epoch 94/64] [Batch 922/937] [D loss: 0.625517] [G loss: 0.958613]\n",
      "[Epoch 95/64] [Batch 85/937] [D loss: 0.669413] [G loss: 0.865101]\n",
      "[Epoch 95/64] [Batch 185/937] [D loss: 0.624777] [G loss: 0.903214]\n",
      "[Epoch 95/64] [Batch 285/937] [D loss: 0.641237] [G loss: 0.900849]\n",
      "[Epoch 95/64] [Batch 385/937] [D loss: 0.638384] [G loss: 0.805628]\n",
      "[Epoch 95/64] [Batch 485/937] [D loss: 0.655348] [G loss: 0.904626]\n",
      "[Epoch 95/64] [Batch 585/937] [D loss: 0.667287] [G loss: 0.896200]\n",
      "[Epoch 95/64] [Batch 685/937] [D loss: 0.685108] [G loss: 1.039788]\n",
      "[Epoch 95/64] [Batch 785/937] [D loss: 0.651716] [G loss: 0.871976]\n",
      "[Epoch 95/64] [Batch 885/937] [D loss: 0.656762] [G loss: 0.853577]\n",
      "[Epoch 96/64] [Batch 48/937] [D loss: 0.635961] [G loss: 0.852406]\n",
      "[Epoch 96/64] [Batch 148/937] [D loss: 0.613073] [G loss: 0.868001]\n",
      "[Epoch 96/64] [Batch 248/937] [D loss: 0.663233] [G loss: 0.977773]\n",
      "[Epoch 96/64] [Batch 348/937] [D loss: 0.633600] [G loss: 0.972292]\n",
      "[Epoch 96/64] [Batch 448/937] [D loss: 0.598475] [G loss: 0.948460]\n",
      "[Epoch 96/64] [Batch 548/937] [D loss: 0.631778] [G loss: 0.991731]\n",
      "[Epoch 96/64] [Batch 648/937] [D loss: 0.645665] [G loss: 0.872798]\n",
      "[Epoch 96/64] [Batch 748/937] [D loss: 0.605390] [G loss: 0.907718]\n",
      "[Epoch 96/64] [Batch 848/937] [D loss: 0.667832] [G loss: 0.863799]\n",
      "[Epoch 97/64] [Batch 11/937] [D loss: 0.638182] [G loss: 0.798199]\n",
      "[Epoch 97/64] [Batch 111/937] [D loss: 0.632294] [G loss: 0.988267]\n",
      "[Epoch 97/64] [Batch 211/937] [D loss: 0.629471] [G loss: 0.878874]\n",
      "[Epoch 97/64] [Batch 311/937] [D loss: 0.609146] [G loss: 0.953009]\n",
      "[Epoch 97/64] [Batch 411/937] [D loss: 0.627478] [G loss: 0.914901]\n",
      "[Epoch 97/64] [Batch 511/937] [D loss: 0.617081] [G loss: 0.921509]\n",
      "[Epoch 97/64] [Batch 611/937] [D loss: 0.661354] [G loss: 0.798225]\n",
      "[Epoch 97/64] [Batch 711/937] [D loss: 0.606772] [G loss: 0.910624]\n",
      "[Epoch 97/64] [Batch 811/937] [D loss: 0.674490] [G loss: 0.843916]\n",
      "[Epoch 97/64] [Batch 911/937] [D loss: 0.668195] [G loss: 0.942797]\n",
      "[Epoch 98/64] [Batch 74/937] [D loss: 0.693028] [G loss: 0.923245]\n",
      "[Epoch 98/64] [Batch 174/937] [D loss: 0.613371] [G loss: 0.825783]\n",
      "[Epoch 98/64] [Batch 274/937] [D loss: 0.624768] [G loss: 0.883619]\n",
      "[Epoch 98/64] [Batch 374/937] [D loss: 0.621916] [G loss: 0.841344]\n",
      "[Epoch 98/64] [Batch 474/937] [D loss: 0.608830] [G loss: 0.845569]\n",
      "[Epoch 98/64] [Batch 574/937] [D loss: 0.637051] [G loss: 0.825165]\n",
      "[Epoch 98/64] [Batch 674/937] [D loss: 0.617705] [G loss: 0.860861]\n",
      "[Epoch 98/64] [Batch 774/937] [D loss: 0.643990] [G loss: 0.845193]\n",
      "[Epoch 98/64] [Batch 874/937] [D loss: 0.661534] [G loss: 0.949641]\n",
      "[Epoch 99/64] [Batch 37/937] [D loss: 0.604485] [G loss: 0.929196]\n",
      "[Epoch 99/64] [Batch 137/937] [D loss: 0.621354] [G loss: 0.947265]\n",
      "[Epoch 99/64] [Batch 237/937] [D loss: 0.624005] [G loss: 0.906998]\n",
      "[Epoch 99/64] [Batch 337/937] [D loss: 0.687985] [G loss: 0.944029]\n",
      "[Epoch 99/64] [Batch 437/937] [D loss: 0.619919] [G loss: 0.933868]\n",
      "[Epoch 99/64] [Batch 537/937] [D loss: 0.580932] [G loss: 0.866242]\n",
      "[Epoch 99/64] [Batch 637/937] [D loss: 0.643630] [G loss: 0.983611]\n",
      "[Epoch 99/64] [Batch 737/937] [D loss: 0.599252] [G loss: 0.914596]\n",
      "[Epoch 99/64] [Batch 837/937] [D loss: 0.648452] [G loss: 0.904169]\n",
      "[Epoch 100/64] [Batch 0/937] [D loss: 0.615625] [G loss: 0.962072]\n",
      "[Epoch 100/64] [Batch 100/937] [D loss: 0.625160] [G loss: 0.850596]\n",
      "[Epoch 100/64] [Batch 200/937] [D loss: 0.626370] [G loss: 0.939867]\n",
      "[Epoch 100/64] [Batch 300/937] [D loss: 0.656203] [G loss: 0.991894]\n",
      "[Epoch 100/64] [Batch 400/937] [D loss: 0.616232] [G loss: 1.001362]\n",
      "[Epoch 100/64] [Batch 500/937] [D loss: 0.644330] [G loss: 0.797954]\n",
      "[Epoch 100/64] [Batch 600/937] [D loss: 0.667157] [G loss: 0.808670]\n",
      "[Epoch 100/64] [Batch 700/937] [D loss: 0.609222] [G loss: 0.979120]\n",
      "[Epoch 100/64] [Batch 800/937] [D loss: 0.569216] [G loss: 0.888575]\n",
      "[Epoch 100/64] [Batch 900/937] [D loss: 0.644503] [G loss: 0.934545]\n",
      "[Epoch 101/64] [Batch 63/937] [D loss: 0.619785] [G loss: 0.972567]\n",
      "[Epoch 101/64] [Batch 163/937] [D loss: 0.657706] [G loss: 0.803418]\n",
      "[Epoch 101/64] [Batch 263/937] [D loss: 0.606154] [G loss: 0.882376]\n",
      "[Epoch 101/64] [Batch 363/937] [D loss: 0.612520] [G loss: 0.999619]\n",
      "[Epoch 101/64] [Batch 463/937] [D loss: 0.598666] [G loss: 0.854861]\n",
      "[Epoch 101/64] [Batch 563/937] [D loss: 0.624026] [G loss: 1.009996]\n",
      "[Epoch 101/64] [Batch 663/937] [D loss: 0.634048] [G loss: 0.935018]\n",
      "[Epoch 101/64] [Batch 763/937] [D loss: 0.573924] [G loss: 1.056606]\n",
      "[Epoch 101/64] [Batch 863/937] [D loss: 0.619215] [G loss: 0.942484]\n",
      "[Epoch 102/64] [Batch 26/937] [D loss: 0.582598] [G loss: 0.929902]\n",
      "[Epoch 102/64] [Batch 126/937] [D loss: 0.653636] [G loss: 0.956128]\n",
      "[Epoch 102/64] [Batch 226/937] [D loss: 0.648331] [G loss: 0.918168]\n",
      "[Epoch 102/64] [Batch 326/937] [D loss: 0.626794] [G loss: 1.007353]\n",
      "[Epoch 102/64] [Batch 426/937] [D loss: 0.625522] [G loss: 0.922175]\n",
      "[Epoch 102/64] [Batch 526/937] [D loss: 0.605387] [G loss: 0.788121]\n",
      "[Epoch 102/64] [Batch 626/937] [D loss: 0.646351] [G loss: 0.869396]\n",
      "[Epoch 102/64] [Batch 726/937] [D loss: 0.636277] [G loss: 0.922986]\n",
      "[Epoch 102/64] [Batch 826/937] [D loss: 0.639401] [G loss: 0.838069]\n",
      "[Epoch 102/64] [Batch 926/937] [D loss: 0.636279] [G loss: 0.932476]\n",
      "[Epoch 103/64] [Batch 89/937] [D loss: 0.635255] [G loss: 0.965156]\n",
      "[Epoch 103/64] [Batch 189/937] [D loss: 0.637149] [G loss: 0.865240]\n",
      "[Epoch 103/64] [Batch 289/937] [D loss: 0.647964] [G loss: 0.915698]\n",
      "[Epoch 103/64] [Batch 389/937] [D loss: 0.635262] [G loss: 0.857197]\n",
      "[Epoch 103/64] [Batch 489/937] [D loss: 0.636803] [G loss: 0.948156]\n",
      "[Epoch 103/64] [Batch 589/937] [D loss: 0.598667] [G loss: 0.922113]\n",
      "[Epoch 103/64] [Batch 689/937] [D loss: 0.679094] [G loss: 0.831064]\n",
      "[Epoch 103/64] [Batch 789/937] [D loss: 0.638296] [G loss: 0.797848]\n",
      "[Epoch 103/64] [Batch 889/937] [D loss: 0.636630] [G loss: 0.972957]\n",
      "[Epoch 104/64] [Batch 52/937] [D loss: 0.635733] [G loss: 0.788792]\n",
      "[Epoch 104/64] [Batch 152/937] [D loss: 0.595780] [G loss: 0.978870]\n",
      "[Epoch 104/64] [Batch 252/937] [D loss: 0.660391] [G loss: 0.908013]\n",
      "[Epoch 104/64] [Batch 352/937] [D loss: 0.609175] [G loss: 0.939353]\n",
      "[Epoch 104/64] [Batch 452/937] [D loss: 0.637772] [G loss: 0.861287]\n",
      "[Epoch 104/64] [Batch 552/937] [D loss: 0.650207] [G loss: 0.915250]\n",
      "[Epoch 104/64] [Batch 652/937] [D loss: 0.632643] [G loss: 0.948131]\n",
      "[Epoch 104/64] [Batch 752/937] [D loss: 0.637848] [G loss: 0.882022]\n",
      "[Epoch 104/64] [Batch 852/937] [D loss: 0.641253] [G loss: 0.958583]\n",
      "[Epoch 105/64] [Batch 15/937] [D loss: 0.621387] [G loss: 0.989624]\n",
      "[Epoch 105/64] [Batch 115/937] [D loss: 0.684984] [G loss: 0.776783]\n",
      "[Epoch 105/64] [Batch 215/937] [D loss: 0.598888] [G loss: 0.951944]\n",
      "[Epoch 105/64] [Batch 315/937] [D loss: 0.653458] [G loss: 0.865736]\n",
      "[Epoch 105/64] [Batch 415/937] [D loss: 0.667745] [G loss: 0.861431]\n",
      "[Epoch 105/64] [Batch 515/937] [D loss: 0.624142] [G loss: 0.951325]\n",
      "[Epoch 105/64] [Batch 615/937] [D loss: 0.635127] [G loss: 0.840011]\n",
      "[Epoch 105/64] [Batch 715/937] [D loss: 0.607544] [G loss: 0.945307]\n",
      "[Epoch 105/64] [Batch 815/937] [D loss: 0.639491] [G loss: 1.030677]\n",
      "[Epoch 105/64] [Batch 915/937] [D loss: 0.641246] [G loss: 0.993826]\n",
      "[Epoch 106/64] [Batch 78/937] [D loss: 0.649162] [G loss: 0.986683]\n",
      "[Epoch 106/64] [Batch 178/937] [D loss: 0.675534] [G loss: 0.888955]\n",
      "[Epoch 106/64] [Batch 278/937] [D loss: 0.623604] [G loss: 0.942226]\n",
      "[Epoch 106/64] [Batch 378/937] [D loss: 0.660894] [G loss: 0.945233]\n",
      "[Epoch 106/64] [Batch 478/937] [D loss: 0.634936] [G loss: 0.839147]\n",
      "[Epoch 106/64] [Batch 578/937] [D loss: 0.651931] [G loss: 0.847496]\n",
      "[Epoch 106/64] [Batch 678/937] [D loss: 0.636205] [G loss: 0.804582]\n",
      "[Epoch 106/64] [Batch 778/937] [D loss: 0.635751] [G loss: 0.840464]\n",
      "[Epoch 106/64] [Batch 878/937] [D loss: 0.626434] [G loss: 0.898839]\n",
      "[Epoch 107/64] [Batch 41/937] [D loss: 0.648228] [G loss: 0.897013]\n",
      "[Epoch 107/64] [Batch 141/937] [D loss: 0.615351] [G loss: 0.906280]\n",
      "[Epoch 107/64] [Batch 241/937] [D loss: 0.682785] [G loss: 0.885969]\n",
      "[Epoch 107/64] [Batch 341/937] [D loss: 0.620780] [G loss: 0.803644]\n",
      "[Epoch 107/64] [Batch 441/937] [D loss: 0.671956] [G loss: 1.028570]\n",
      "[Epoch 107/64] [Batch 541/937] [D loss: 0.681273] [G loss: 0.954060]\n",
      "[Epoch 107/64] [Batch 641/937] [D loss: 0.640603] [G loss: 0.937204]\n",
      "[Epoch 107/64] [Batch 741/937] [D loss: 0.615096] [G loss: 0.883950]\n",
      "[Epoch 107/64] [Batch 841/937] [D loss: 0.678123] [G loss: 0.931887]\n",
      "[Epoch 108/64] [Batch 4/937] [D loss: 0.642604] [G loss: 0.844302]\n",
      "[Epoch 108/64] [Batch 104/937] [D loss: 0.617051] [G loss: 0.911482]\n",
      "[Epoch 108/64] [Batch 204/937] [D loss: 0.642880] [G loss: 0.871587]\n",
      "[Epoch 108/64] [Batch 304/937] [D loss: 0.625570] [G loss: 0.946291]\n",
      "[Epoch 108/64] [Batch 404/937] [D loss: 0.631518] [G loss: 0.898588]\n",
      "[Epoch 108/64] [Batch 504/937] [D loss: 0.653792] [G loss: 0.863695]\n",
      "[Epoch 108/64] [Batch 604/937] [D loss: 0.627152] [G loss: 0.878503]\n",
      "[Epoch 108/64] [Batch 704/937] [D loss: 0.590273] [G loss: 0.870606]\n",
      "[Epoch 108/64] [Batch 804/937] [D loss: 0.607838] [G loss: 0.881757]\n",
      "[Epoch 108/64] [Batch 904/937] [D loss: 0.631516] [G loss: 0.868613]\n",
      "[Epoch 109/64] [Batch 67/937] [D loss: 0.663226] [G loss: 1.023139]\n",
      "[Epoch 109/64] [Batch 167/937] [D loss: 0.651715] [G loss: 0.873096]\n",
      "[Epoch 109/64] [Batch 267/937] [D loss: 0.621167] [G loss: 1.032228]\n",
      "[Epoch 109/64] [Batch 367/937] [D loss: 0.601856] [G loss: 0.954865]\n",
      "[Epoch 109/64] [Batch 467/937] [D loss: 0.593495] [G loss: 0.998751]\n",
      "[Epoch 109/64] [Batch 567/937] [D loss: 0.612369] [G loss: 0.892919]\n",
      "[Epoch 109/64] [Batch 667/937] [D loss: 0.624610] [G loss: 0.762084]\n",
      "[Epoch 109/64] [Batch 767/937] [D loss: 0.683478] [G loss: 0.778254]\n",
      "[Epoch 109/64] [Batch 867/937] [D loss: 0.637913] [G loss: 0.878063]\n",
      "[Epoch 110/64] [Batch 30/937] [D loss: 0.650201] [G loss: 0.968352]\n",
      "[Epoch 110/64] [Batch 130/937] [D loss: 0.629643] [G loss: 0.863914]\n",
      "[Epoch 110/64] [Batch 230/937] [D loss: 0.573446] [G loss: 1.008562]\n",
      "[Epoch 110/64] [Batch 330/937] [D loss: 0.644290] [G loss: 0.818880]\n",
      "[Epoch 110/64] [Batch 430/937] [D loss: 0.618598] [G loss: 0.893871]\n",
      "[Epoch 110/64] [Batch 530/937] [D loss: 0.673352] [G loss: 0.797861]\n",
      "[Epoch 110/64] [Batch 630/937] [D loss: 0.611430] [G loss: 0.843166]\n",
      "[Epoch 110/64] [Batch 730/937] [D loss: 0.630012] [G loss: 0.793137]\n",
      "[Epoch 110/64] [Batch 830/937] [D loss: 0.629176] [G loss: 0.924494]\n",
      "[Epoch 110/64] [Batch 930/937] [D loss: 0.663435] [G loss: 0.890821]\n",
      "[Epoch 111/64] [Batch 93/937] [D loss: 0.632877] [G loss: 0.870504]\n",
      "[Epoch 111/64] [Batch 193/937] [D loss: 0.579514] [G loss: 1.039035]\n",
      "[Epoch 111/64] [Batch 293/937] [D loss: 0.663005] [G loss: 0.957019]\n",
      "[Epoch 111/64] [Batch 393/937] [D loss: 0.607577] [G loss: 0.875647]\n",
      "[Epoch 111/64] [Batch 493/937] [D loss: 0.559704] [G loss: 0.992866]\n",
      "[Epoch 111/64] [Batch 593/937] [D loss: 0.644979] [G loss: 0.805552]\n",
      "[Epoch 111/64] [Batch 693/937] [D loss: 0.623912] [G loss: 0.964803]\n",
      "[Epoch 111/64] [Batch 793/937] [D loss: 0.639795] [G loss: 0.817784]\n",
      "[Epoch 111/64] [Batch 893/937] [D loss: 0.638797] [G loss: 0.840822]\n",
      "[Epoch 112/64] [Batch 56/937] [D loss: 0.654256] [G loss: 0.798769]\n",
      "[Epoch 112/64] [Batch 156/937] [D loss: 0.628543] [G loss: 0.990035]\n",
      "[Epoch 112/64] [Batch 256/937] [D loss: 0.622241] [G loss: 0.793627]\n",
      "[Epoch 112/64] [Batch 356/937] [D loss: 0.676599] [G loss: 0.898897]\n",
      "[Epoch 112/64] [Batch 456/937] [D loss: 0.571829] [G loss: 0.885551]\n",
      "[Epoch 112/64] [Batch 556/937] [D loss: 0.623048] [G loss: 0.910275]\n",
      "[Epoch 112/64] [Batch 656/937] [D loss: 0.644273] [G loss: 0.893727]\n",
      "[Epoch 112/64] [Batch 756/937] [D loss: 0.653947] [G loss: 0.848689]\n",
      "[Epoch 112/64] [Batch 856/937] [D loss: 0.613972] [G loss: 0.909229]\n",
      "[Epoch 113/64] [Batch 19/937] [D loss: 0.649818] [G loss: 0.978974]\n",
      "[Epoch 113/64] [Batch 119/937] [D loss: 0.613980] [G loss: 0.877264]\n",
      "[Epoch 113/64] [Batch 219/937] [D loss: 0.654721] [G loss: 0.871944]\n",
      "[Epoch 113/64] [Batch 319/937] [D loss: 0.615187] [G loss: 0.902129]\n",
      "[Epoch 113/64] [Batch 419/937] [D loss: 0.691948] [G loss: 0.802100]\n",
      "[Epoch 113/64] [Batch 519/937] [D loss: 0.607329] [G loss: 0.938756]\n",
      "[Epoch 113/64] [Batch 619/937] [D loss: 0.615403] [G loss: 0.956808]\n",
      "[Epoch 113/64] [Batch 719/937] [D loss: 0.606748] [G loss: 0.837834]\n",
      "[Epoch 113/64] [Batch 819/937] [D loss: 0.612803] [G loss: 0.927498]\n",
      "[Epoch 113/64] [Batch 919/937] [D loss: 0.659565] [G loss: 0.958784]\n",
      "[Epoch 114/64] [Batch 82/937] [D loss: 0.641493] [G loss: 0.919602]\n",
      "[Epoch 114/64] [Batch 182/937] [D loss: 0.605084] [G loss: 0.804320]\n",
      "[Epoch 114/64] [Batch 282/937] [D loss: 0.597075] [G loss: 0.961109]\n",
      "[Epoch 114/64] [Batch 382/937] [D loss: 0.594999] [G loss: 0.787756]\n",
      "[Epoch 114/64] [Batch 482/937] [D loss: 0.584296] [G loss: 0.837924]\n",
      "[Epoch 114/64] [Batch 582/937] [D loss: 0.673741] [G loss: 0.832258]\n",
      "[Epoch 114/64] [Batch 682/937] [D loss: 0.556284] [G loss: 0.930247]\n",
      "[Epoch 114/64] [Batch 782/937] [D loss: 0.635939] [G loss: 0.911111]\n",
      "[Epoch 114/64] [Batch 882/937] [D loss: 0.771125] [G loss: 0.828998]\n",
      "[Epoch 115/64] [Batch 45/937] [D loss: 0.589129] [G loss: 0.854671]\n",
      "[Epoch 115/64] [Batch 145/937] [D loss: 0.630181] [G loss: 0.792372]\n",
      "[Epoch 115/64] [Batch 245/937] [D loss: 0.657892] [G loss: 0.896758]\n",
      "[Epoch 115/64] [Batch 345/937] [D loss: 0.609518] [G loss: 0.822262]\n",
      "[Epoch 115/64] [Batch 445/937] [D loss: 0.664767] [G loss: 0.907073]\n",
      "[Epoch 115/64] [Batch 545/937] [D loss: 0.657805] [G loss: 0.836791]\n",
      "[Epoch 115/64] [Batch 645/937] [D loss: 0.577090] [G loss: 0.851490]\n",
      "[Epoch 115/64] [Batch 745/937] [D loss: 0.637880] [G loss: 0.891765]\n",
      "[Epoch 115/64] [Batch 845/937] [D loss: 0.591271] [G loss: 0.935089]\n",
      "[Epoch 116/64] [Batch 8/937] [D loss: 0.621188] [G loss: 0.930071]\n",
      "[Epoch 116/64] [Batch 108/937] [D loss: 0.609916] [G loss: 0.946742]\n",
      "[Epoch 116/64] [Batch 208/937] [D loss: 0.620719] [G loss: 0.974099]\n",
      "[Epoch 116/64] [Batch 308/937] [D loss: 0.673690] [G loss: 0.929611]\n",
      "[Epoch 116/64] [Batch 408/937] [D loss: 0.615243] [G loss: 0.969464]\n",
      "[Epoch 116/64] [Batch 508/937] [D loss: 0.618187] [G loss: 0.913159]\n",
      "[Epoch 116/64] [Batch 608/937] [D loss: 0.609832] [G loss: 0.858073]\n",
      "[Epoch 116/64] [Batch 708/937] [D loss: 0.636984] [G loss: 0.871184]\n",
      "[Epoch 116/64] [Batch 808/937] [D loss: 0.673664] [G loss: 0.932484]\n",
      "[Epoch 116/64] [Batch 908/937] [D loss: 0.628536] [G loss: 0.888425]\n",
      "[Epoch 117/64] [Batch 71/937] [D loss: 0.608999] [G loss: 1.063933]\n",
      "[Epoch 117/64] [Batch 171/937] [D loss: 0.666655] [G loss: 0.836715]\n",
      "[Epoch 117/64] [Batch 271/937] [D loss: 0.618420] [G loss: 0.976218]\n",
      "[Epoch 117/64] [Batch 371/937] [D loss: 0.579696] [G loss: 1.021473]\n",
      "[Epoch 117/64] [Batch 471/937] [D loss: 0.619707] [G loss: 0.883721]\n",
      "[Epoch 117/64] [Batch 571/937] [D loss: 0.659350] [G loss: 0.862334]\n",
      "[Epoch 117/64] [Batch 671/937] [D loss: 0.671232] [G loss: 0.850437]\n",
      "[Epoch 117/64] [Batch 771/937] [D loss: 0.615568] [G loss: 0.960823]\n",
      "[Epoch 117/64] [Batch 871/937] [D loss: 0.632779] [G loss: 0.878103]\n",
      "[Epoch 118/64] [Batch 34/937] [D loss: 0.677386] [G loss: 0.811675]\n",
      "[Epoch 118/64] [Batch 134/937] [D loss: 0.607336] [G loss: 0.912192]\n",
      "[Epoch 118/64] [Batch 234/937] [D loss: 0.649020] [G loss: 1.016229]\n",
      "[Epoch 118/64] [Batch 334/937] [D loss: 0.621712] [G loss: 0.979841]\n",
      "[Epoch 118/64] [Batch 434/937] [D loss: 0.680890] [G loss: 0.875304]\n",
      "[Epoch 118/64] [Batch 534/937] [D loss: 0.642687] [G loss: 0.826110]\n",
      "[Epoch 118/64] [Batch 634/937] [D loss: 0.626333] [G loss: 0.835878]\n",
      "[Epoch 118/64] [Batch 734/937] [D loss: 0.597894] [G loss: 0.880484]\n",
      "[Epoch 118/64] [Batch 834/937] [D loss: 0.587229] [G loss: 0.920071]\n",
      "[Epoch 118/64] [Batch 934/937] [D loss: 0.558049] [G loss: 0.959968]\n",
      "[Epoch 119/64] [Batch 97/937] [D loss: 0.597938] [G loss: 0.894273]\n",
      "[Epoch 119/64] [Batch 197/937] [D loss: 0.619224] [G loss: 0.831470]\n",
      "[Epoch 119/64] [Batch 297/937] [D loss: 0.649818] [G loss: 0.927832]\n",
      "[Epoch 119/64] [Batch 397/937] [D loss: 0.651215] [G loss: 1.020032]\n",
      "[Epoch 119/64] [Batch 497/937] [D loss: 0.624468] [G loss: 0.901259]\n",
      "[Epoch 119/64] [Batch 597/937] [D loss: 0.681425] [G loss: 0.862910]\n",
      "[Epoch 119/64] [Batch 697/937] [D loss: 0.663344] [G loss: 0.828110]\n",
      "[Epoch 119/64] [Batch 797/937] [D loss: 0.598732] [G loss: 0.904598]\n",
      "[Epoch 119/64] [Batch 897/937] [D loss: 0.656180] [G loss: 0.910956]\n",
      "[Epoch 120/64] [Batch 60/937] [D loss: 0.619718] [G loss: 0.843330]\n",
      "[Epoch 120/64] [Batch 160/937] [D loss: 0.664402] [G loss: 0.835622]\n",
      "[Epoch 120/64] [Batch 260/937] [D loss: 0.645183] [G loss: 0.854019]\n",
      "[Epoch 120/64] [Batch 360/937] [D loss: 0.640586] [G loss: 0.906459]\n",
      "[Epoch 120/64] [Batch 460/937] [D loss: 0.649431] [G loss: 0.973900]\n",
      "[Epoch 120/64] [Batch 560/937] [D loss: 0.630011] [G loss: 1.082760]\n",
      "[Epoch 120/64] [Batch 660/937] [D loss: 0.595444] [G loss: 0.921365]\n",
      "[Epoch 120/64] [Batch 760/937] [D loss: 0.642047] [G loss: 0.965757]\n",
      "[Epoch 120/64] [Batch 860/937] [D loss: 0.667937] [G loss: 0.919984]\n",
      "[Epoch 121/64] [Batch 23/937] [D loss: 0.605710] [G loss: 0.921131]\n",
      "[Epoch 121/64] [Batch 123/937] [D loss: 0.659714] [G loss: 0.924923]\n",
      "[Epoch 121/64] [Batch 223/937] [D loss: 0.622065] [G loss: 0.934728]\n",
      "[Epoch 121/64] [Batch 323/937] [D loss: 0.674076] [G loss: 0.789432]\n",
      "[Epoch 121/64] [Batch 423/937] [D loss: 0.616020] [G loss: 0.825029]\n",
      "[Epoch 121/64] [Batch 523/937] [D loss: 0.672122] [G loss: 0.769545]\n",
      "[Epoch 121/64] [Batch 623/937] [D loss: 0.597077] [G loss: 0.821144]\n",
      "[Epoch 121/64] [Batch 723/937] [D loss: 0.639175] [G loss: 0.851795]\n",
      "[Epoch 121/64] [Batch 823/937] [D loss: 0.616364] [G loss: 0.795693]\n",
      "[Epoch 121/64] [Batch 923/937] [D loss: 0.611145] [G loss: 0.846597]\n",
      "[Epoch 122/64] [Batch 86/937] [D loss: 0.656244] [G loss: 0.923799]\n",
      "[Epoch 122/64] [Batch 186/937] [D loss: 0.627864] [G loss: 0.803884]\n",
      "[Epoch 122/64] [Batch 286/937] [D loss: 0.657974] [G loss: 0.896604]\n",
      "[Epoch 122/64] [Batch 386/937] [D loss: 0.592552] [G loss: 0.931508]\n",
      "[Epoch 122/64] [Batch 486/937] [D loss: 0.661908] [G loss: 0.889301]\n",
      "[Epoch 122/64] [Batch 586/937] [D loss: 0.630059] [G loss: 0.856097]\n",
      "[Epoch 122/64] [Batch 686/937] [D loss: 0.594650] [G loss: 0.822780]\n",
      "[Epoch 122/64] [Batch 786/937] [D loss: 0.588880] [G loss: 0.862400]\n",
      "[Epoch 122/64] [Batch 886/937] [D loss: 0.619900] [G loss: 0.832716]\n",
      "[Epoch 123/64] [Batch 49/937] [D loss: 0.587314] [G loss: 0.959708]\n",
      "[Epoch 123/64] [Batch 149/937] [D loss: 0.581857] [G loss: 0.915285]\n",
      "[Epoch 123/64] [Batch 249/937] [D loss: 0.621302] [G loss: 0.866161]\n",
      "[Epoch 123/64] [Batch 349/937] [D loss: 0.623016] [G loss: 0.927739]\n",
      "[Epoch 123/64] [Batch 449/937] [D loss: 0.655445] [G loss: 0.897144]\n",
      "[Epoch 123/64] [Batch 549/937] [D loss: 0.585477] [G loss: 0.945626]\n",
      "[Epoch 123/64] [Batch 649/937] [D loss: 0.617381] [G loss: 0.934317]\n",
      "[Epoch 123/64] [Batch 749/937] [D loss: 0.621328] [G loss: 0.940008]\n",
      "[Epoch 123/64] [Batch 849/937] [D loss: 0.659191] [G loss: 0.866631]\n",
      "[Epoch 124/64] [Batch 12/937] [D loss: 0.625907] [G loss: 0.917827]\n",
      "[Epoch 124/64] [Batch 112/937] [D loss: 0.660208] [G loss: 0.938715]\n",
      "[Epoch 124/64] [Batch 212/937] [D loss: 0.609778] [G loss: 0.791012]\n",
      "[Epoch 124/64] [Batch 312/937] [D loss: 0.636957] [G loss: 0.904947]\n",
      "[Epoch 124/64] [Batch 412/937] [D loss: 0.664649] [G loss: 0.891250]\n",
      "[Epoch 124/64] [Batch 512/937] [D loss: 0.599457] [G loss: 0.995467]\n",
      "[Epoch 124/64] [Batch 612/937] [D loss: 0.698219] [G loss: 0.844970]\n",
      "[Epoch 124/64] [Batch 712/937] [D loss: 0.628902] [G loss: 0.829326]\n",
      "[Epoch 124/64] [Batch 812/937] [D loss: 0.610611] [G loss: 0.834518]\n",
      "[Epoch 124/64] [Batch 912/937] [D loss: 0.555671] [G loss: 0.903732]\n",
      "[Epoch 125/64] [Batch 75/937] [D loss: 0.620339] [G loss: 1.094980]\n",
      "[Epoch 125/64] [Batch 175/937] [D loss: 0.669586] [G loss: 0.865984]\n",
      "[Epoch 125/64] [Batch 275/937] [D loss: 0.698813] [G loss: 0.835974]\n",
      "[Epoch 125/64] [Batch 375/937] [D loss: 0.628111] [G loss: 0.901706]\n",
      "[Epoch 125/64] [Batch 475/937] [D loss: 0.638989] [G loss: 0.867210]\n",
      "[Epoch 125/64] [Batch 575/937] [D loss: 0.685046] [G loss: 0.763344]\n",
      "[Epoch 125/64] [Batch 675/937] [D loss: 0.658196] [G loss: 0.857685]\n",
      "[Epoch 125/64] [Batch 775/937] [D loss: 0.649506] [G loss: 0.965038]\n",
      "[Epoch 125/64] [Batch 875/937] [D loss: 0.608016] [G loss: 0.903932]\n",
      "[Epoch 126/64] [Batch 38/937] [D loss: 0.647681] [G loss: 0.767417]\n",
      "[Epoch 126/64] [Batch 138/937] [D loss: 0.584841] [G loss: 1.006314]\n",
      "[Epoch 126/64] [Batch 238/937] [D loss: 0.587870] [G loss: 0.816513]\n",
      "[Epoch 126/64] [Batch 338/937] [D loss: 0.628617] [G loss: 0.904358]\n",
      "[Epoch 126/64] [Batch 438/937] [D loss: 0.680858] [G loss: 0.871586]\n",
      "[Epoch 126/64] [Batch 538/937] [D loss: 0.618460] [G loss: 0.913759]\n",
      "[Epoch 126/64] [Batch 638/937] [D loss: 0.612576] [G loss: 0.833054]\n",
      "[Epoch 126/64] [Batch 738/937] [D loss: 0.598106] [G loss: 0.895598]\n",
      "[Epoch 126/64] [Batch 838/937] [D loss: 0.571757] [G loss: 0.828537]\n",
      "[Epoch 127/64] [Batch 1/937] [D loss: 0.610627] [G loss: 0.825351]\n",
      "[Epoch 127/64] [Batch 101/937] [D loss: 0.654003] [G loss: 0.837930]\n",
      "[Epoch 127/64] [Batch 201/937] [D loss: 0.637423] [G loss: 0.863408]\n",
      "[Epoch 127/64] [Batch 301/937] [D loss: 0.599770] [G loss: 0.929767]\n",
      "[Epoch 127/64] [Batch 401/937] [D loss: 0.646166] [G loss: 0.890286]\n",
      "[Epoch 127/64] [Batch 501/937] [D loss: 0.667160] [G loss: 0.849385]\n",
      "[Epoch 127/64] [Batch 601/937] [D loss: 0.615418] [G loss: 0.863913]\n",
      "[Epoch 127/64] [Batch 701/937] [D loss: 0.599094] [G loss: 0.983673]\n",
      "[Epoch 127/64] [Batch 801/937] [D loss: 0.656603] [G loss: 0.845442]\n",
      "[Epoch 127/64] [Batch 901/937] [D loss: 0.680100] [G loss: 0.852473]\n",
      "[Epoch 128/64] [Batch 64/937] [D loss: 0.602865] [G loss: 0.868989]\n",
      "[Epoch 128/64] [Batch 164/937] [D loss: 0.647932] [G loss: 0.840567]\n",
      "[Epoch 128/64] [Batch 264/937] [D loss: 0.637119] [G loss: 0.762376]\n",
      "[Epoch 128/64] [Batch 364/937] [D loss: 0.667655] [G loss: 0.882358]\n",
      "[Epoch 128/64] [Batch 464/937] [D loss: 0.651083] [G loss: 0.864781]\n",
      "[Epoch 128/64] [Batch 564/937] [D loss: 0.670933] [G loss: 0.864726]\n",
      "[Epoch 128/64] [Batch 664/937] [D loss: 0.632842] [G loss: 0.837949]\n",
      "[Epoch 128/64] [Batch 764/937] [D loss: 0.663133] [G loss: 0.907318]\n",
      "[Epoch 128/64] [Batch 864/937] [D loss: 0.636727] [G loss: 0.942562]\n",
      "[Epoch 129/64] [Batch 27/937] [D loss: 0.585886] [G loss: 0.891280]\n",
      "[Epoch 129/64] [Batch 127/937] [D loss: 0.624559] [G loss: 0.957467]\n",
      "[Epoch 129/64] [Batch 227/937] [D loss: 0.623837] [G loss: 0.900201]\n",
      "[Epoch 129/64] [Batch 327/937] [D loss: 0.627879] [G loss: 0.892235]\n",
      "[Epoch 129/64] [Batch 427/937] [D loss: 0.665874] [G loss: 0.814857]\n",
      "[Epoch 129/64] [Batch 527/937] [D loss: 0.689098] [G loss: 0.807893]\n",
      "[Epoch 129/64] [Batch 627/937] [D loss: 0.642881] [G loss: 0.934526]\n",
      "[Epoch 129/64] [Batch 727/937] [D loss: 0.624062] [G loss: 0.672993]\n",
      "[Epoch 129/64] [Batch 827/937] [D loss: 0.630946] [G loss: 0.856405]\n",
      "[Epoch 129/64] [Batch 927/937] [D loss: 0.661499] [G loss: 0.903922]\n",
      "[Epoch 130/64] [Batch 90/937] [D loss: 0.594591] [G loss: 0.895866]\n",
      "[Epoch 130/64] [Batch 190/937] [D loss: 0.680443] [G loss: 0.875160]\n",
      "[Epoch 130/64] [Batch 290/937] [D loss: 0.644086] [G loss: 0.830362]\n",
      "[Epoch 130/64] [Batch 390/937] [D loss: 0.610392] [G loss: 0.885848]\n",
      "[Epoch 130/64] [Batch 490/937] [D loss: 0.624934] [G loss: 0.889825]\n",
      "[Epoch 130/64] [Batch 590/937] [D loss: 0.599957] [G loss: 0.971883]\n",
      "[Epoch 130/64] [Batch 690/937] [D loss: 0.650253] [G loss: 0.892419]\n",
      "[Epoch 130/64] [Batch 790/937] [D loss: 0.662531] [G loss: 0.939337]\n",
      "[Epoch 130/64] [Batch 890/937] [D loss: 0.632195] [G loss: 0.944652]\n",
      "[Epoch 131/64] [Batch 53/937] [D loss: 0.634437] [G loss: 0.916879]\n",
      "[Epoch 131/64] [Batch 153/937] [D loss: 0.628992] [G loss: 0.843949]\n",
      "[Epoch 131/64] [Batch 253/937] [D loss: 0.656123] [G loss: 0.814183]\n",
      "[Epoch 131/64] [Batch 353/937] [D loss: 0.630109] [G loss: 0.913369]\n",
      "[Epoch 131/64] [Batch 453/937] [D loss: 0.615623] [G loss: 0.804189]\n",
      "[Epoch 131/64] [Batch 553/937] [D loss: 0.666016] [G loss: 0.911934]\n",
      "[Epoch 131/64] [Batch 653/937] [D loss: 0.586648] [G loss: 0.978224]\n",
      "[Epoch 131/64] [Batch 753/937] [D loss: 0.660994] [G loss: 0.956233]\n",
      "[Epoch 131/64] [Batch 853/937] [D loss: 0.662081] [G loss: 0.868818]\n",
      "[Epoch 132/64] [Batch 16/937] [D loss: 0.590534] [G loss: 0.990119]\n",
      "[Epoch 132/64] [Batch 116/937] [D loss: 0.634321] [G loss: 0.925895]\n",
      "[Epoch 132/64] [Batch 216/937] [D loss: 0.632709] [G loss: 0.940372]\n",
      "[Epoch 132/64] [Batch 316/937] [D loss: 0.577082] [G loss: 0.840621]\n",
      "[Epoch 132/64] [Batch 416/937] [D loss: 0.624673] [G loss: 1.036330]\n",
      "[Epoch 132/64] [Batch 516/937] [D loss: 0.636024] [G loss: 0.907111]\n",
      "[Epoch 132/64] [Batch 616/937] [D loss: 0.647133] [G loss: 0.917961]\n",
      "[Epoch 132/64] [Batch 716/937] [D loss: 0.615343] [G loss: 0.918239]\n",
      "[Epoch 132/64] [Batch 816/937] [D loss: 0.634095] [G loss: 0.922568]\n",
      "[Epoch 132/64] [Batch 916/937] [D loss: 0.654600] [G loss: 0.822803]\n",
      "[Epoch 133/64] [Batch 79/937] [D loss: 0.641636] [G loss: 0.910108]\n",
      "[Epoch 133/64] [Batch 179/937] [D loss: 0.660163] [G loss: 0.895541]\n",
      "[Epoch 133/64] [Batch 279/937] [D loss: 0.674786] [G loss: 0.854792]\n",
      "[Epoch 133/64] [Batch 379/937] [D loss: 0.605710] [G loss: 0.988882]\n",
      "[Epoch 133/64] [Batch 479/937] [D loss: 0.642086] [G loss: 0.794009]\n",
      "[Epoch 133/64] [Batch 579/937] [D loss: 0.660518] [G loss: 0.910823]\n",
      "[Epoch 133/64] [Batch 679/937] [D loss: 0.639809] [G loss: 0.945450]\n",
      "[Epoch 133/64] [Batch 779/937] [D loss: 0.655298] [G loss: 0.994048]\n",
      "[Epoch 133/64] [Batch 879/937] [D loss: 0.620036] [G loss: 0.910142]\n",
      "[Epoch 134/64] [Batch 42/937] [D loss: 0.632567] [G loss: 0.980340]\n",
      "[Epoch 134/64] [Batch 142/937] [D loss: 0.655807] [G loss: 0.864744]\n",
      "[Epoch 134/64] [Batch 242/937] [D loss: 0.672449] [G loss: 0.943693]\n",
      "[Epoch 134/64] [Batch 342/937] [D loss: 0.674927] [G loss: 0.876094]\n",
      "[Epoch 134/64] [Batch 442/937] [D loss: 0.654306] [G loss: 0.896704]\n",
      "[Epoch 134/64] [Batch 542/937] [D loss: 0.599592] [G loss: 0.990501]\n",
      "[Epoch 134/64] [Batch 642/937] [D loss: 0.622825] [G loss: 0.887519]\n",
      "[Epoch 134/64] [Batch 742/937] [D loss: 0.537475] [G loss: 0.976423]\n",
      "[Epoch 134/64] [Batch 842/937] [D loss: 0.639088] [G loss: 0.860811]\n",
      "[Epoch 135/64] [Batch 5/937] [D loss: 0.611787] [G loss: 1.004885]\n",
      "[Epoch 135/64] [Batch 105/937] [D loss: 0.646831] [G loss: 0.918507]\n",
      "[Epoch 135/64] [Batch 205/937] [D loss: 0.609781] [G loss: 0.960028]\n",
      "[Epoch 135/64] [Batch 305/937] [D loss: 0.629764] [G loss: 0.843332]\n",
      "[Epoch 135/64] [Batch 405/937] [D loss: 0.627633] [G loss: 0.885070]\n",
      "[Epoch 135/64] [Batch 505/937] [D loss: 0.617895] [G loss: 0.915458]\n",
      "[Epoch 135/64] [Batch 605/937] [D loss: 0.603017] [G loss: 0.920442]\n",
      "[Epoch 135/64] [Batch 705/937] [D loss: 0.556867] [G loss: 1.016788]\n",
      "[Epoch 135/64] [Batch 805/937] [D loss: 0.644122] [G loss: 0.783558]\n",
      "[Epoch 135/64] [Batch 905/937] [D loss: 0.617581] [G loss: 0.809902]\n",
      "[Epoch 136/64] [Batch 68/937] [D loss: 0.731313] [G loss: 0.739538]\n",
      "[Epoch 136/64] [Batch 168/937] [D loss: 0.614171] [G loss: 0.921443]\n",
      "[Epoch 136/64] [Batch 268/937] [D loss: 0.691945] [G loss: 0.900212]\n",
      "[Epoch 136/64] [Batch 368/937] [D loss: 0.703548] [G loss: 0.788447]\n",
      "[Epoch 136/64] [Batch 468/937] [D loss: 0.633917] [G loss: 0.833119]\n",
      "[Epoch 136/64] [Batch 568/937] [D loss: 0.664738] [G loss: 0.819435]\n",
      "[Epoch 136/64] [Batch 668/937] [D loss: 0.713728] [G loss: 0.859880]\n",
      "[Epoch 136/64] [Batch 768/937] [D loss: 0.655795] [G loss: 0.872071]\n",
      "[Epoch 136/64] [Batch 868/937] [D loss: 0.638943] [G loss: 0.862741]\n",
      "[Epoch 137/64] [Batch 31/937] [D loss: 0.628556] [G loss: 0.965022]\n",
      "[Epoch 137/64] [Batch 131/937] [D loss: 0.672921] [G loss: 0.977454]\n",
      "[Epoch 137/64] [Batch 231/937] [D loss: 0.637471] [G loss: 0.835205]\n",
      "[Epoch 137/64] [Batch 331/937] [D loss: 0.656337] [G loss: 0.801474]\n",
      "[Epoch 137/64] [Batch 431/937] [D loss: 0.640368] [G loss: 0.951381]\n",
      "[Epoch 137/64] [Batch 531/937] [D loss: 0.606904] [G loss: 0.893599]\n",
      "[Epoch 137/64] [Batch 631/937] [D loss: 0.615578] [G loss: 0.825405]\n",
      "[Epoch 137/64] [Batch 731/937] [D loss: 0.602079] [G loss: 0.878646]\n",
      "[Epoch 137/64] [Batch 831/937] [D loss: 0.640471] [G loss: 0.917587]\n",
      "[Epoch 137/64] [Batch 931/937] [D loss: 0.601264] [G loss: 0.940669]\n",
      "[Epoch 138/64] [Batch 94/937] [D loss: 0.698563] [G loss: 0.938506]\n",
      "[Epoch 138/64] [Batch 194/937] [D loss: 0.675465] [G loss: 0.866328]\n",
      "[Epoch 138/64] [Batch 294/937] [D loss: 0.625430] [G loss: 0.870292]\n",
      "[Epoch 138/64] [Batch 394/937] [D loss: 0.628507] [G loss: 0.852735]\n",
      "[Epoch 138/64] [Batch 494/937] [D loss: 0.652792] [G loss: 0.801939]\n",
      "[Epoch 138/64] [Batch 594/937] [D loss: 0.647552] [G loss: 0.866026]\n",
      "[Epoch 138/64] [Batch 694/937] [D loss: 0.648103] [G loss: 0.863854]\n",
      "[Epoch 138/64] [Batch 794/937] [D loss: 0.655488] [G loss: 0.868940]\n",
      "[Epoch 138/64] [Batch 894/937] [D loss: 0.558167] [G loss: 0.902551]\n",
      "[Epoch 139/64] [Batch 57/937] [D loss: 0.632766] [G loss: 0.913931]\n",
      "[Epoch 139/64] [Batch 157/937] [D loss: 0.626909] [G loss: 0.920642]\n",
      "[Epoch 139/64] [Batch 257/937] [D loss: 0.638296] [G loss: 0.909697]\n",
      "[Epoch 139/64] [Batch 357/937] [D loss: 0.679043] [G loss: 0.934307]\n",
      "[Epoch 139/64] [Batch 457/937] [D loss: 0.629547] [G loss: 0.881269]\n",
      "[Epoch 139/64] [Batch 557/937] [D loss: 0.627070] [G loss: 0.832374]\n",
      "[Epoch 139/64] [Batch 657/937] [D loss: 0.577736] [G loss: 0.877504]\n",
      "[Epoch 139/64] [Batch 757/937] [D loss: 0.636647] [G loss: 0.919852]\n",
      "[Epoch 139/64] [Batch 857/937] [D loss: 0.677637] [G loss: 0.872176]\n",
      "[Epoch 140/64] [Batch 20/937] [D loss: 0.686310] [G loss: 0.902731]\n",
      "[Epoch 140/64] [Batch 120/937] [D loss: 0.689671] [G loss: 0.858182]\n",
      "[Epoch 140/64] [Batch 220/937] [D loss: 0.603955] [G loss: 0.923798]\n",
      "[Epoch 140/64] [Batch 320/937] [D loss: 0.634466] [G loss: 0.895548]\n",
      "[Epoch 140/64] [Batch 420/937] [D loss: 0.655452] [G loss: 0.932209]\n",
      "[Epoch 140/64] [Batch 520/937] [D loss: 0.666277] [G loss: 0.850287]\n",
      "[Epoch 140/64] [Batch 620/937] [D loss: 0.625911] [G loss: 0.916877]\n",
      "[Epoch 140/64] [Batch 720/937] [D loss: 0.594859] [G loss: 1.060291]\n",
      "[Epoch 140/64] [Batch 820/937] [D loss: 0.614273] [G loss: 0.871387]\n",
      "[Epoch 140/64] [Batch 920/937] [D loss: 0.648578] [G loss: 0.883419]\n",
      "[Epoch 141/64] [Batch 83/937] [D loss: 0.648554] [G loss: 0.862510]\n",
      "[Epoch 141/64] [Batch 183/937] [D loss: 0.627348] [G loss: 0.830711]\n",
      "[Epoch 141/64] [Batch 283/937] [D loss: 0.652366] [G loss: 0.858097]\n",
      "[Epoch 141/64] [Batch 383/937] [D loss: 0.646465] [G loss: 0.904806]\n",
      "[Epoch 141/64] [Batch 483/937] [D loss: 0.599266] [G loss: 0.991146]\n",
      "[Epoch 141/64] [Batch 583/937] [D loss: 0.641900] [G loss: 0.914701]\n",
      "[Epoch 141/64] [Batch 683/937] [D loss: 0.627063] [G loss: 0.845700]\n",
      "[Epoch 141/64] [Batch 783/937] [D loss: 0.654610] [G loss: 0.865727]\n",
      "[Epoch 141/64] [Batch 883/937] [D loss: 0.613276] [G loss: 0.834027]\n",
      "[Epoch 142/64] [Batch 46/937] [D loss: 0.627943] [G loss: 0.916857]\n",
      "[Epoch 142/64] [Batch 146/937] [D loss: 0.657692] [G loss: 0.918009]\n",
      "[Epoch 142/64] [Batch 246/937] [D loss: 0.634988] [G loss: 0.812062]\n",
      "[Epoch 142/64] [Batch 346/937] [D loss: 0.630396] [G loss: 0.940679]\n",
      "[Epoch 142/64] [Batch 446/937] [D loss: 0.642677] [G loss: 0.872883]\n",
      "[Epoch 142/64] [Batch 546/937] [D loss: 0.634837] [G loss: 0.936127]\n",
      "[Epoch 142/64] [Batch 646/937] [D loss: 0.629504] [G loss: 0.962836]\n",
      "[Epoch 142/64] [Batch 746/937] [D loss: 0.663528] [G loss: 0.808308]\n",
      "[Epoch 142/64] [Batch 846/937] [D loss: 0.656479] [G loss: 0.840083]\n",
      "[Epoch 143/64] [Batch 9/937] [D loss: 0.651608] [G loss: 0.788719]\n",
      "[Epoch 143/64] [Batch 109/937] [D loss: 0.631870] [G loss: 0.825094]\n",
      "[Epoch 143/64] [Batch 209/937] [D loss: 0.668495] [G loss: 0.919550]\n",
      "[Epoch 143/64] [Batch 309/937] [D loss: 0.667962] [G loss: 0.866913]\n",
      "[Epoch 143/64] [Batch 409/937] [D loss: 0.630093] [G loss: 0.913574]\n",
      "[Epoch 143/64] [Batch 509/937] [D loss: 0.649100] [G loss: 0.871081]\n",
      "[Epoch 143/64] [Batch 609/937] [D loss: 0.618121] [G loss: 0.901274]\n",
      "[Epoch 143/64] [Batch 709/937] [D loss: 0.637086] [G loss: 0.877743]\n",
      "[Epoch 143/64] [Batch 809/937] [D loss: 0.659949] [G loss: 0.867728]\n",
      "[Epoch 143/64] [Batch 909/937] [D loss: 0.606850] [G loss: 0.883586]\n",
      "[Epoch 144/64] [Batch 72/937] [D loss: 0.670050] [G loss: 0.925074]\n",
      "[Epoch 144/64] [Batch 172/937] [D loss: 0.624389] [G loss: 0.840456]\n",
      "[Epoch 144/64] [Batch 272/937] [D loss: 0.599134] [G loss: 0.894464]\n",
      "[Epoch 144/64] [Batch 372/937] [D loss: 0.648790] [G loss: 0.903555]\n",
      "[Epoch 144/64] [Batch 472/937] [D loss: 0.614674] [G loss: 0.875087]\n",
      "[Epoch 144/64] [Batch 572/937] [D loss: 0.627907] [G loss: 0.940500]\n",
      "[Epoch 144/64] [Batch 672/937] [D loss: 0.656869] [G loss: 0.877090]\n",
      "[Epoch 144/64] [Batch 772/937] [D loss: 0.634417] [G loss: 0.827185]\n",
      "[Epoch 144/64] [Batch 872/937] [D loss: 0.640680] [G loss: 0.876669]\n",
      "[Epoch 145/64] [Batch 35/937] [D loss: 0.655832] [G loss: 0.819819]\n",
      "[Epoch 145/64] [Batch 135/937] [D loss: 0.626067] [G loss: 0.995188]\n",
      "[Epoch 145/64] [Batch 235/937] [D loss: 0.604555] [G loss: 0.884122]\n",
      "[Epoch 145/64] [Batch 335/937] [D loss: 0.636473] [G loss: 1.091083]\n",
      "[Epoch 145/64] [Batch 435/937] [D loss: 0.621639] [G loss: 0.802942]\n",
      "[Epoch 145/64] [Batch 535/937] [D loss: 0.607221] [G loss: 0.930185]\n",
      "[Epoch 145/64] [Batch 635/937] [D loss: 0.555854] [G loss: 0.856555]\n",
      "[Epoch 145/64] [Batch 735/937] [D loss: 0.668901] [G loss: 0.987773]\n",
      "[Epoch 145/64] [Batch 835/937] [D loss: 0.593727] [G loss: 0.855947]\n",
      "[Epoch 145/64] [Batch 935/937] [D loss: 0.642137] [G loss: 1.050627]\n",
      "[Epoch 146/64] [Batch 98/937] [D loss: 0.642286] [G loss: 0.943935]\n",
      "[Epoch 146/64] [Batch 198/937] [D loss: 0.636101] [G loss: 0.907805]\n",
      "[Epoch 146/64] [Batch 298/937] [D loss: 0.681955] [G loss: 0.806104]\n",
      "[Epoch 146/64] [Batch 398/937] [D loss: 0.598619] [G loss: 0.819773]\n",
      "[Epoch 146/64] [Batch 498/937] [D loss: 0.703035] [G loss: 0.921293]\n",
      "[Epoch 146/64] [Batch 598/937] [D loss: 0.613839] [G loss: 0.820080]\n",
      "[Epoch 146/64] [Batch 698/937] [D loss: 0.640852] [G loss: 0.825386]\n",
      "[Epoch 146/64] [Batch 798/937] [D loss: 0.639070] [G loss: 0.824152]\n",
      "[Epoch 146/64] [Batch 898/937] [D loss: 0.645444] [G loss: 0.906310]\n",
      "[Epoch 147/64] [Batch 61/937] [D loss: 0.677903] [G loss: 0.934130]\n",
      "[Epoch 147/64] [Batch 161/937] [D loss: 0.648030] [G loss: 0.907593]\n",
      "[Epoch 147/64] [Batch 261/937] [D loss: 0.667978] [G loss: 0.833973]\n",
      "[Epoch 147/64] [Batch 361/937] [D loss: 0.647188] [G loss: 0.885165]\n",
      "[Epoch 147/64] [Batch 461/937] [D loss: 0.604857] [G loss: 0.957610]\n",
      "[Epoch 147/64] [Batch 561/937] [D loss: 0.658659] [G loss: 0.962283]\n",
      "[Epoch 147/64] [Batch 661/937] [D loss: 0.580412] [G loss: 0.991967]\n",
      "[Epoch 147/64] [Batch 761/937] [D loss: 0.643681] [G loss: 0.898122]\n",
      "[Epoch 147/64] [Batch 861/937] [D loss: 0.634268] [G loss: 0.996907]\n",
      "[Epoch 148/64] [Batch 24/937] [D loss: 0.612272] [G loss: 1.007756]\n",
      "[Epoch 148/64] [Batch 124/937] [D loss: 0.644271] [G loss: 0.945028]\n",
      "[Epoch 148/64] [Batch 224/937] [D loss: 0.596819] [G loss: 0.971482]\n",
      "[Epoch 148/64] [Batch 324/937] [D loss: 0.639903] [G loss: 0.853731]\n",
      "[Epoch 148/64] [Batch 424/937] [D loss: 0.658937] [G loss: 0.795811]\n",
      "[Epoch 148/64] [Batch 524/937] [D loss: 0.620121] [G loss: 1.064541]\n",
      "[Epoch 148/64] [Batch 624/937] [D loss: 0.631201] [G loss: 0.915659]\n",
      "[Epoch 148/64] [Batch 724/937] [D loss: 0.599818] [G loss: 0.975733]\n",
      "[Epoch 148/64] [Batch 824/937] [D loss: 0.588701] [G loss: 0.932681]\n",
      "[Epoch 148/64] [Batch 924/937] [D loss: 0.652448] [G loss: 0.869633]\n",
      "[Epoch 149/64] [Batch 87/937] [D loss: 0.657115] [G loss: 0.902633]\n",
      "[Epoch 149/64] [Batch 187/937] [D loss: 0.598007] [G loss: 0.910755]\n",
      "[Epoch 149/64] [Batch 287/937] [D loss: 0.658464] [G loss: 0.824540]\n",
      "[Epoch 149/64] [Batch 387/937] [D loss: 0.627790] [G loss: 0.884338]\n",
      "[Epoch 149/64] [Batch 487/937] [D loss: 0.645748] [G loss: 0.931782]\n",
      "[Epoch 149/64] [Batch 587/937] [D loss: 0.667694] [G loss: 0.985644]\n",
      "[Epoch 149/64] [Batch 687/937] [D loss: 0.631141] [G loss: 0.740298]\n",
      "[Epoch 149/64] [Batch 787/937] [D loss: 0.611306] [G loss: 0.968511]\n",
      "[Epoch 149/64] [Batch 887/937] [D loss: 0.606834] [G loss: 0.876484]\n",
      "[Epoch 150/64] [Batch 50/937] [D loss: 0.671981] [G loss: 0.900898]\n",
      "[Epoch 150/64] [Batch 150/937] [D loss: 0.604356] [G loss: 0.896071]\n",
      "[Epoch 150/64] [Batch 250/937] [D loss: 0.679585] [G loss: 0.783808]\n",
      "[Epoch 150/64] [Batch 350/937] [D loss: 0.699976] [G loss: 0.829263]\n",
      "[Epoch 150/64] [Batch 450/937] [D loss: 0.634716] [G loss: 0.907781]\n",
      "[Epoch 150/64] [Batch 550/937] [D loss: 0.644260] [G loss: 0.813216]\n",
      "[Epoch 150/64] [Batch 650/937] [D loss: 0.686795] [G loss: 0.818588]\n",
      "[Epoch 150/64] [Batch 750/937] [D loss: 0.680159] [G loss: 0.895560]\n",
      "[Epoch 150/64] [Batch 850/937] [D loss: 0.639811] [G loss: 0.972856]\n",
      "[Epoch 151/64] [Batch 13/937] [D loss: 0.643213] [G loss: 0.923782]\n",
      "[Epoch 151/64] [Batch 113/937] [D loss: 0.652340] [G loss: 0.876477]\n",
      "[Epoch 151/64] [Batch 213/937] [D loss: 0.622853] [G loss: 0.963078]\n",
      "[Epoch 151/64] [Batch 313/937] [D loss: 0.678934] [G loss: 0.845885]\n",
      "[Epoch 151/64] [Batch 413/937] [D loss: 0.681789] [G loss: 0.740709]\n",
      "[Epoch 151/64] [Batch 513/937] [D loss: 0.642081] [G loss: 0.842981]\n",
      "[Epoch 151/64] [Batch 613/937] [D loss: 0.626682] [G loss: 0.950033]\n",
      "[Epoch 151/64] [Batch 713/937] [D loss: 0.633475] [G loss: 0.908826]\n",
      "[Epoch 151/64] [Batch 813/937] [D loss: 0.670996] [G loss: 0.872776]\n",
      "[Epoch 151/64] [Batch 913/937] [D loss: 0.614592] [G loss: 0.818108]\n",
      "[Epoch 152/64] [Batch 76/937] [D loss: 0.614562] [G loss: 0.835519]\n",
      "[Epoch 152/64] [Batch 176/937] [D loss: 0.647232] [G loss: 0.902686]\n",
      "[Epoch 152/64] [Batch 276/937] [D loss: 0.697141] [G loss: 0.823246]\n",
      "[Epoch 152/64] [Batch 376/937] [D loss: 0.589794] [G loss: 0.956721]\n",
      "[Epoch 152/64] [Batch 476/937] [D loss: 0.664417] [G loss: 0.846336]\n",
      "[Epoch 152/64] [Batch 576/937] [D loss: 0.614714] [G loss: 0.871376]\n",
      "[Epoch 152/64] [Batch 676/937] [D loss: 0.607008] [G loss: 0.831229]\n",
      "[Epoch 152/64] [Batch 776/937] [D loss: 0.655671] [G loss: 0.809791]\n",
      "[Epoch 152/64] [Batch 876/937] [D loss: 0.653387] [G loss: 0.811697]\n",
      "[Epoch 153/64] [Batch 39/937] [D loss: 0.595482] [G loss: 0.864874]\n",
      "[Epoch 153/64] [Batch 139/937] [D loss: 0.614541] [G loss: 0.877090]\n",
      "[Epoch 153/64] [Batch 239/937] [D loss: 0.644232] [G loss: 0.822373]\n",
      "[Epoch 153/64] [Batch 339/937] [D loss: 0.648254] [G loss: 0.831111]\n",
      "[Epoch 153/64] [Batch 439/937] [D loss: 0.613465] [G loss: 0.923017]\n",
      "[Epoch 153/64] [Batch 539/937] [D loss: 0.656334] [G loss: 0.902225]\n",
      "[Epoch 153/64] [Batch 639/937] [D loss: 0.667773] [G loss: 0.863394]\n",
      "[Epoch 153/64] [Batch 739/937] [D loss: 0.644531] [G loss: 0.800860]\n",
      "[Epoch 153/64] [Batch 839/937] [D loss: 0.655645] [G loss: 0.839483]\n",
      "[Epoch 154/64] [Batch 2/937] [D loss: 0.652805] [G loss: 0.879736]\n",
      "[Epoch 154/64] [Batch 102/937] [D loss: 0.639883] [G loss: 0.835448]\n",
      "[Epoch 154/64] [Batch 202/937] [D loss: 0.626089] [G loss: 0.922908]\n",
      "[Epoch 154/64] [Batch 302/937] [D loss: 0.608581] [G loss: 0.874727]\n",
      "[Epoch 154/64] [Batch 402/937] [D loss: 0.627232] [G loss: 0.845981]\n",
      "[Epoch 154/64] [Batch 502/937] [D loss: 0.681940] [G loss: 0.880671]\n",
      "[Epoch 154/64] [Batch 602/937] [D loss: 0.651663] [G loss: 0.887545]\n",
      "[Epoch 154/64] [Batch 702/937] [D loss: 0.674610] [G loss: 0.823036]\n",
      "[Epoch 154/64] [Batch 802/937] [D loss: 0.615566] [G loss: 0.911172]\n",
      "[Epoch 154/64] [Batch 902/937] [D loss: 0.645767] [G loss: 0.865195]\n",
      "[Epoch 155/64] [Batch 65/937] [D loss: 0.677313] [G loss: 0.836650]\n",
      "[Epoch 155/64] [Batch 165/937] [D loss: 0.570057] [G loss: 0.895854]\n",
      "[Epoch 155/64] [Batch 265/937] [D loss: 0.685731] [G loss: 0.941122]\n",
      "[Epoch 155/64] [Batch 365/937] [D loss: 0.607387] [G loss: 0.967358]\n",
      "[Epoch 155/64] [Batch 465/937] [D loss: 0.657463] [G loss: 0.805767]\n",
      "[Epoch 155/64] [Batch 565/937] [D loss: 0.643598] [G loss: 0.843097]\n",
      "[Epoch 155/64] [Batch 665/937] [D loss: 0.657448] [G loss: 0.829489]\n",
      "[Epoch 155/64] [Batch 765/937] [D loss: 0.633226] [G loss: 0.957448]\n",
      "[Epoch 155/64] [Batch 865/937] [D loss: 0.648173] [G loss: 0.876770]\n",
      "[Epoch 156/64] [Batch 28/937] [D loss: 0.618075] [G loss: 0.925940]\n",
      "[Epoch 156/64] [Batch 128/937] [D loss: 0.639947] [G loss: 0.871794]\n",
      "[Epoch 156/64] [Batch 228/937] [D loss: 0.688203] [G loss: 0.945650]\n",
      "[Epoch 156/64] [Batch 328/937] [D loss: 0.649232] [G loss: 0.918689]\n",
      "[Epoch 156/64] [Batch 428/937] [D loss: 0.642773] [G loss: 0.884317]\n",
      "[Epoch 156/64] [Batch 528/937] [D loss: 0.640219] [G loss: 0.831361]\n",
      "[Epoch 156/64] [Batch 628/937] [D loss: 0.632887] [G loss: 0.850481]\n",
      "[Epoch 156/64] [Batch 728/937] [D loss: 0.620784] [G loss: 0.800730]\n",
      "[Epoch 156/64] [Batch 828/937] [D loss: 0.604248] [G loss: 0.902279]\n",
      "[Epoch 156/64] [Batch 928/937] [D loss: 0.592996] [G loss: 0.873759]\n",
      "[Epoch 157/64] [Batch 91/937] [D loss: 0.607298] [G loss: 0.801116]\n",
      "[Epoch 157/64] [Batch 191/937] [D loss: 0.610834] [G loss: 0.793432]\n",
      "[Epoch 157/64] [Batch 291/937] [D loss: 0.634022] [G loss: 0.914844]\n",
      "[Epoch 157/64] [Batch 391/937] [D loss: 0.619654] [G loss: 0.872436]\n",
      "[Epoch 157/64] [Batch 491/937] [D loss: 0.631158] [G loss: 0.941558]\n",
      "[Epoch 157/64] [Batch 591/937] [D loss: 0.641674] [G loss: 0.877735]\n",
      "[Epoch 157/64] [Batch 691/937] [D loss: 0.729206] [G loss: 1.013196]\n",
      "[Epoch 157/64] [Batch 791/937] [D loss: 0.607786] [G loss: 0.970104]\n",
      "[Epoch 157/64] [Batch 891/937] [D loss: 0.638481] [G loss: 0.848811]\n",
      "[Epoch 158/64] [Batch 54/937] [D loss: 0.640205] [G loss: 0.845117]\n",
      "[Epoch 158/64] [Batch 154/937] [D loss: 0.670960] [G loss: 0.878543]\n",
      "[Epoch 158/64] [Batch 254/937] [D loss: 0.608787] [G loss: 0.839053]\n",
      "[Epoch 158/64] [Batch 354/937] [D loss: 0.587336] [G loss: 0.825163]\n",
      "[Epoch 158/64] [Batch 454/937] [D loss: 0.637977] [G loss: 0.773994]\n",
      "[Epoch 158/64] [Batch 554/937] [D loss: 0.670035] [G loss: 0.871721]\n",
      "[Epoch 158/64] [Batch 654/937] [D loss: 0.651738] [G loss: 0.812582]\n",
      "[Epoch 158/64] [Batch 754/937] [D loss: 0.594100] [G loss: 0.908301]\n",
      "[Epoch 158/64] [Batch 854/937] [D loss: 0.638541] [G loss: 0.864425]\n",
      "[Epoch 159/64] [Batch 17/937] [D loss: 0.599825] [G loss: 0.921349]\n",
      "[Epoch 159/64] [Batch 117/937] [D loss: 0.632970] [G loss: 0.856696]\n",
      "[Epoch 159/64] [Batch 217/937] [D loss: 0.657584] [G loss: 0.867818]\n",
      "[Epoch 159/64] [Batch 317/937] [D loss: 0.662009] [G loss: 0.925215]\n",
      "[Epoch 159/64] [Batch 417/937] [D loss: 0.681102] [G loss: 0.826744]\n",
      "[Epoch 159/64] [Batch 517/937] [D loss: 0.597743] [G loss: 0.824399]\n",
      "[Epoch 159/64] [Batch 617/937] [D loss: 0.599075] [G loss: 0.934314]\n",
      "[Epoch 159/64] [Batch 717/937] [D loss: 0.629335] [G loss: 0.852263]\n",
      "[Epoch 159/64] [Batch 817/937] [D loss: 0.638988] [G loss: 0.895971]\n",
      "[Epoch 159/64] [Batch 917/937] [D loss: 0.557933] [G loss: 0.835433]\n",
      "[Epoch 160/64] [Batch 80/937] [D loss: 0.619192] [G loss: 0.904743]\n",
      "[Epoch 160/64] [Batch 180/937] [D loss: 0.662362] [G loss: 1.022823]\n",
      "[Epoch 160/64] [Batch 280/937] [D loss: 0.676945] [G loss: 0.804437]\n",
      "[Epoch 160/64] [Batch 380/937] [D loss: 0.607645] [G loss: 0.888505]\n",
      "[Epoch 160/64] [Batch 480/937] [D loss: 0.595564] [G loss: 0.983386]\n",
      "[Epoch 160/64] [Batch 580/937] [D loss: 0.687225] [G loss: 1.019108]\n",
      "[Epoch 160/64] [Batch 680/937] [D loss: 0.646552] [G loss: 0.804484]\n",
      "[Epoch 160/64] [Batch 780/937] [D loss: 0.597083] [G loss: 0.910645]\n",
      "[Epoch 160/64] [Batch 880/937] [D loss: 0.654926] [G loss: 0.943264]\n",
      "[Epoch 161/64] [Batch 43/937] [D loss: 0.615079] [G loss: 0.854316]\n",
      "[Epoch 161/64] [Batch 143/937] [D loss: 0.594246] [G loss: 0.923328]\n",
      "[Epoch 161/64] [Batch 243/937] [D loss: 0.615813] [G loss: 0.924712]\n",
      "[Epoch 161/64] [Batch 343/937] [D loss: 0.627071] [G loss: 0.852864]\n",
      "[Epoch 161/64] [Batch 443/937] [D loss: 0.670099] [G loss: 0.842127]\n",
      "[Epoch 161/64] [Batch 543/937] [D loss: 0.610318] [G loss: 0.870701]\n",
      "[Epoch 161/64] [Batch 643/937] [D loss: 0.631836] [G loss: 0.875644]\n",
      "[Epoch 161/64] [Batch 743/937] [D loss: 0.588919] [G loss: 0.966664]\n",
      "[Epoch 161/64] [Batch 843/937] [D loss: 0.664273] [G loss: 0.814386]\n",
      "[Epoch 162/64] [Batch 6/937] [D loss: 0.661720] [G loss: 0.842122]\n",
      "[Epoch 162/64] [Batch 106/937] [D loss: 0.625836] [G loss: 0.898154]\n",
      "[Epoch 162/64] [Batch 206/937] [D loss: 0.638796] [G loss: 0.983615]\n",
      "[Epoch 162/64] [Batch 306/937] [D loss: 0.662551] [G loss: 0.915240]\n",
      "[Epoch 162/64] [Batch 406/937] [D loss: 0.606077] [G loss: 0.844812]\n",
      "[Epoch 162/64] [Batch 506/937] [D loss: 0.639268] [G loss: 0.806098]\n",
      "[Epoch 162/64] [Batch 606/937] [D loss: 0.651324] [G loss: 1.041478]\n",
      "[Epoch 162/64] [Batch 706/937] [D loss: 0.629481] [G loss: 0.787281]\n",
      "[Epoch 162/64] [Batch 806/937] [D loss: 0.614008] [G loss: 0.783976]\n",
      "[Epoch 162/64] [Batch 906/937] [D loss: 0.646597] [G loss: 0.856288]\n",
      "[Epoch 163/64] [Batch 69/937] [D loss: 0.627061] [G loss: 0.864038]\n",
      "[Epoch 163/64] [Batch 169/937] [D loss: 0.655746] [G loss: 0.915294]\n",
      "[Epoch 163/64] [Batch 269/937] [D loss: 0.633841] [G loss: 0.879394]\n",
      "[Epoch 163/64] [Batch 369/937] [D loss: 0.639818] [G loss: 0.785143]\n",
      "[Epoch 163/64] [Batch 469/937] [D loss: 0.575843] [G loss: 0.862394]\n",
      "[Epoch 163/64] [Batch 569/937] [D loss: 0.697041] [G loss: 1.009758]\n",
      "[Epoch 163/64] [Batch 669/937] [D loss: 0.637139] [G loss: 0.861664]\n",
      "[Epoch 163/64] [Batch 769/937] [D loss: 0.646773] [G loss: 0.902287]\n",
      "[Epoch 163/64] [Batch 869/937] [D loss: 0.632704] [G loss: 0.808375]\n",
      "[Epoch 164/64] [Batch 32/937] [D loss: 0.630953] [G loss: 0.882988]\n",
      "[Epoch 164/64] [Batch 132/937] [D loss: 0.594260] [G loss: 0.795976]\n",
      "[Epoch 164/64] [Batch 232/937] [D loss: 0.641030] [G loss: 0.932673]\n",
      "[Epoch 164/64] [Batch 332/937] [D loss: 0.677618] [G loss: 0.920561]\n",
      "[Epoch 164/64] [Batch 432/937] [D loss: 0.639044] [G loss: 0.917798]\n",
      "[Epoch 164/64] [Batch 532/937] [D loss: 0.621972] [G loss: 0.915209]\n",
      "[Epoch 164/64] [Batch 632/937] [D loss: 0.610231] [G loss: 0.996083]\n",
      "[Epoch 164/64] [Batch 732/937] [D loss: 0.644835] [G loss: 0.879744]\n",
      "[Epoch 164/64] [Batch 832/937] [D loss: 0.600296] [G loss: 0.948434]\n",
      "[Epoch 164/64] [Batch 932/937] [D loss: 0.669827] [G loss: 0.928941]\n",
      "[Epoch 165/64] [Batch 95/937] [D loss: 0.630305] [G loss: 0.867792]\n",
      "[Epoch 165/64] [Batch 195/937] [D loss: 0.666967] [G loss: 0.836628]\n",
      "[Epoch 165/64] [Batch 295/937] [D loss: 0.627269] [G loss: 0.754465]\n",
      "[Epoch 165/64] [Batch 395/937] [D loss: 0.596270] [G loss: 0.880836]\n",
      "[Epoch 165/64] [Batch 495/937] [D loss: 0.621807] [G loss: 0.913686]\n",
      "[Epoch 165/64] [Batch 595/937] [D loss: 0.636483] [G loss: 0.905234]\n",
      "[Epoch 165/64] [Batch 695/937] [D loss: 0.626472] [G loss: 0.887235]\n",
      "[Epoch 165/64] [Batch 795/937] [D loss: 0.651627] [G loss: 0.844685]\n",
      "[Epoch 165/64] [Batch 895/937] [D loss: 0.638070] [G loss: 0.767157]\n",
      "[Epoch 166/64] [Batch 58/937] [D loss: 0.672142] [G loss: 0.915278]\n",
      "[Epoch 166/64] [Batch 158/937] [D loss: 0.649691] [G loss: 0.839466]\n",
      "[Epoch 166/64] [Batch 258/937] [D loss: 0.651789] [G loss: 0.883477]\n",
      "[Epoch 166/64] [Batch 358/937] [D loss: 0.710826] [G loss: 0.898356]\n",
      "[Epoch 166/64] [Batch 458/937] [D loss: 0.639713] [G loss: 0.880607]\n",
      "[Epoch 166/64] [Batch 558/937] [D loss: 0.620122] [G loss: 0.981568]\n",
      "[Epoch 166/64] [Batch 658/937] [D loss: 0.619097] [G loss: 0.915238]\n",
      "[Epoch 166/64] [Batch 758/937] [D loss: 0.606149] [G loss: 0.886122]\n",
      "[Epoch 166/64] [Batch 858/937] [D loss: 0.648014] [G loss: 0.970488]\n",
      "[Epoch 167/64] [Batch 21/937] [D loss: 0.657948] [G loss: 0.862317]\n",
      "[Epoch 167/64] [Batch 121/937] [D loss: 0.676574] [G loss: 0.874605]\n",
      "[Epoch 167/64] [Batch 221/937] [D loss: 0.623972] [G loss: 0.834193]\n",
      "[Epoch 167/64] [Batch 321/937] [D loss: 0.624444] [G loss: 0.965808]\n",
      "[Epoch 167/64] [Batch 421/937] [D loss: 0.635550] [G loss: 0.893675]\n",
      "[Epoch 167/64] [Batch 521/937] [D loss: 0.624224] [G loss: 0.817304]\n",
      "[Epoch 167/64] [Batch 621/937] [D loss: 0.628836] [G loss: 0.853885]\n",
      "[Epoch 167/64] [Batch 721/937] [D loss: 0.636932] [G loss: 0.871119]\n",
      "[Epoch 167/64] [Batch 821/937] [D loss: 0.606957] [G loss: 1.005692]\n",
      "[Epoch 167/64] [Batch 921/937] [D loss: 0.604461] [G loss: 0.805511]\n",
      "[Epoch 168/64] [Batch 84/937] [D loss: 0.578882] [G loss: 0.891260]\n",
      "[Epoch 168/64] [Batch 184/937] [D loss: 0.625381] [G loss: 0.897120]\n",
      "[Epoch 168/64] [Batch 284/937] [D loss: 0.604793] [G loss: 1.096320]\n",
      "[Epoch 168/64] [Batch 384/937] [D loss: 0.630687] [G loss: 0.871619]\n",
      "[Epoch 168/64] [Batch 484/937] [D loss: 0.617757] [G loss: 0.955501]\n",
      "[Epoch 168/64] [Batch 584/937] [D loss: 0.664749] [G loss: 0.958064]\n",
      "[Epoch 168/64] [Batch 684/937] [D loss: 0.619293] [G loss: 0.901742]\n",
      "[Epoch 168/64] [Batch 784/937] [D loss: 0.607592] [G loss: 0.900017]\n",
      "[Epoch 168/64] [Batch 884/937] [D loss: 0.656417] [G loss: 0.866080]\n",
      "[Epoch 169/64] [Batch 47/937] [D loss: 0.683460] [G loss: 0.855213]\n",
      "[Epoch 169/64] [Batch 147/937] [D loss: 0.621067] [G loss: 0.856811]\n",
      "[Epoch 169/64] [Batch 247/937] [D loss: 0.665112] [G loss: 0.885854]\n",
      "[Epoch 169/64] [Batch 347/937] [D loss: 0.615131] [G loss: 0.944693]\n",
      "[Epoch 169/64] [Batch 447/937] [D loss: 0.678339] [G loss: 0.808408]\n",
      "[Epoch 169/64] [Batch 547/937] [D loss: 0.610330] [G loss: 0.865268]\n",
      "[Epoch 169/64] [Batch 647/937] [D loss: 0.606279] [G loss: 0.886883]\n",
      "[Epoch 169/64] [Batch 747/937] [D loss: 0.643323] [G loss: 0.959394]\n",
      "[Epoch 169/64] [Batch 847/937] [D loss: 0.654381] [G loss: 0.867790]\n",
      "[Epoch 170/64] [Batch 10/937] [D loss: 0.663673] [G loss: 0.909019]\n",
      "[Epoch 170/64] [Batch 110/937] [D loss: 0.650639] [G loss: 0.916876]\n",
      "[Epoch 170/64] [Batch 210/937] [D loss: 0.601250] [G loss: 0.860105]\n",
      "[Epoch 170/64] [Batch 310/937] [D loss: 0.586658] [G loss: 0.908872]\n",
      "[Epoch 170/64] [Batch 410/937] [D loss: 0.588364] [G loss: 0.948126]\n",
      "[Epoch 170/64] [Batch 510/937] [D loss: 0.676267] [G loss: 0.883175]\n",
      "[Epoch 170/64] [Batch 610/937] [D loss: 0.640346] [G loss: 0.914475]\n",
      "[Epoch 170/64] [Batch 710/937] [D loss: 0.659840] [G loss: 0.828403]\n",
      "[Epoch 170/64] [Batch 810/937] [D loss: 0.605058] [G loss: 0.972346]\n",
      "[Epoch 170/64] [Batch 910/937] [D loss: 0.613393] [G loss: 0.823279]\n",
      "[Epoch 171/64] [Batch 73/937] [D loss: 0.614819] [G loss: 0.914443]\n",
      "[Epoch 171/64] [Batch 173/937] [D loss: 0.611345] [G loss: 0.830315]\n",
      "[Epoch 171/64] [Batch 273/937] [D loss: 0.630246] [G loss: 0.844386]\n",
      "[Epoch 171/64] [Batch 373/937] [D loss: 0.635494] [G loss: 0.855513]\n",
      "[Epoch 171/64] [Batch 473/937] [D loss: 0.637246] [G loss: 0.767102]\n",
      "[Epoch 171/64] [Batch 573/937] [D loss: 0.640655] [G loss: 0.866355]\n",
      "[Epoch 171/64] [Batch 673/937] [D loss: 0.617883] [G loss: 0.841446]\n",
      "[Epoch 171/64] [Batch 773/937] [D loss: 0.609768] [G loss: 0.949016]\n",
      "[Epoch 171/64] [Batch 873/937] [D loss: 0.595142] [G loss: 0.893813]\n",
      "[Epoch 172/64] [Batch 36/937] [D loss: 0.618399] [G loss: 0.934453]\n",
      "[Epoch 172/64] [Batch 136/937] [D loss: 0.627359] [G loss: 0.864960]\n",
      "[Epoch 172/64] [Batch 236/937] [D loss: 0.675668] [G loss: 0.848430]\n",
      "[Epoch 172/64] [Batch 336/937] [D loss: 0.673277] [G loss: 0.751079]\n",
      "[Epoch 172/64] [Batch 436/937] [D loss: 0.647861] [G loss: 0.822294]\n",
      "[Epoch 172/64] [Batch 536/937] [D loss: 0.593746] [G loss: 0.941696]\n",
      "[Epoch 172/64] [Batch 636/937] [D loss: 0.635362] [G loss: 0.843952]\n",
      "[Epoch 172/64] [Batch 736/937] [D loss: 0.622785] [G loss: 0.844733]\n",
      "[Epoch 172/64] [Batch 836/937] [D loss: 0.665644] [G loss: 0.896053]\n",
      "[Epoch 172/64] [Batch 936/937] [D loss: 0.635063] [G loss: 0.971497]\n",
      "[Epoch 173/64] [Batch 99/937] [D loss: 0.666626] [G loss: 0.869186]\n",
      "[Epoch 173/64] [Batch 199/937] [D loss: 0.642795] [G loss: 0.925888]\n",
      "[Epoch 173/64] [Batch 299/937] [D loss: 0.692654] [G loss: 0.839179]\n",
      "[Epoch 173/64] [Batch 399/937] [D loss: 0.594158] [G loss: 0.865801]\n",
      "[Epoch 173/64] [Batch 499/937] [D loss: 0.621136] [G loss: 0.905883]\n",
      "[Epoch 173/64] [Batch 599/937] [D loss: 0.624062] [G loss: 0.928944]\n",
      "[Epoch 173/64] [Batch 699/937] [D loss: 0.646539] [G loss: 0.850906]\n",
      "[Epoch 173/64] [Batch 799/937] [D loss: 0.706887] [G loss: 0.906079]\n",
      "[Epoch 173/64] [Batch 899/937] [D loss: 0.585934] [G loss: 0.856550]\n",
      "[Epoch 174/64] [Batch 62/937] [D loss: 0.655840] [G loss: 0.801852]\n",
      "[Epoch 174/64] [Batch 162/937] [D loss: 0.638512] [G loss: 0.862890]\n",
      "[Epoch 174/64] [Batch 262/937] [D loss: 0.612096] [G loss: 0.953553]\n",
      "[Epoch 174/64] [Batch 362/937] [D loss: 0.606203] [G loss: 0.926710]\n",
      "[Epoch 174/64] [Batch 462/937] [D loss: 0.615443] [G loss: 0.847122]\n",
      "[Epoch 174/64] [Batch 562/937] [D loss: 0.632910] [G loss: 0.886124]\n",
      "[Epoch 174/64] [Batch 662/937] [D loss: 0.596537] [G loss: 0.865197]\n",
      "[Epoch 174/64] [Batch 762/937] [D loss: 0.596796] [G loss: 0.924905]\n",
      "[Epoch 174/64] [Batch 862/937] [D loss: 0.599082] [G loss: 0.890795]\n",
      "[Epoch 175/64] [Batch 25/937] [D loss: 0.671597] [G loss: 0.795983]\n",
      "[Epoch 175/64] [Batch 125/937] [D loss: 0.615144] [G loss: 0.959749]\n",
      "[Epoch 175/64] [Batch 225/937] [D loss: 0.682329] [G loss: 0.876787]\n",
      "[Epoch 175/64] [Batch 325/937] [D loss: 0.616105] [G loss: 0.921597]\n",
      "[Epoch 175/64] [Batch 425/937] [D loss: 0.633653] [G loss: 0.823799]\n",
      "[Epoch 175/64] [Batch 525/937] [D loss: 0.638245] [G loss: 0.911598]\n",
      "[Epoch 175/64] [Batch 625/937] [D loss: 0.647842] [G loss: 0.866879]\n",
      "[Epoch 175/64] [Batch 725/937] [D loss: 0.612970] [G loss: 0.851903]\n",
      "[Epoch 175/64] [Batch 825/937] [D loss: 0.621677] [G loss: 0.858748]\n",
      "[Epoch 175/64] [Batch 925/937] [D loss: 0.636074] [G loss: 0.884574]\n",
      "[Epoch 176/64] [Batch 88/937] [D loss: 0.611034] [G loss: 0.985414]\n",
      "[Epoch 176/64] [Batch 188/937] [D loss: 0.653605] [G loss: 0.921558]\n",
      "[Epoch 176/64] [Batch 288/937] [D loss: 0.618508] [G loss: 0.869191]\n",
      "[Epoch 176/64] [Batch 388/937] [D loss: 0.603554] [G loss: 0.862305]\n",
      "[Epoch 176/64] [Batch 488/937] [D loss: 0.607038] [G loss: 0.959880]\n",
      "[Epoch 176/64] [Batch 588/937] [D loss: 0.732081] [G loss: 0.825862]\n",
      "[Epoch 176/64] [Batch 688/937] [D loss: 0.657557] [G loss: 0.858193]\n",
      "[Epoch 176/64] [Batch 788/937] [D loss: 0.621975] [G loss: 0.889036]\n",
      "[Epoch 176/64] [Batch 888/937] [D loss: 0.680945] [G loss: 0.938049]\n",
      "[Epoch 177/64] [Batch 51/937] [D loss: 0.680143] [G loss: 1.003425]\n",
      "[Epoch 177/64] [Batch 151/937] [D loss: 0.629533] [G loss: 0.871808]\n",
      "[Epoch 177/64] [Batch 251/937] [D loss: 0.651356] [G loss: 0.938271]\n",
      "[Epoch 177/64] [Batch 351/937] [D loss: 0.668464] [G loss: 0.812452]\n",
      "[Epoch 177/64] [Batch 451/937] [D loss: 0.598003] [G loss: 0.892677]\n",
      "[Epoch 177/64] [Batch 551/937] [D loss: 0.656336] [G loss: 0.848285]\n",
      "[Epoch 177/64] [Batch 651/937] [D loss: 0.624531] [G loss: 0.842171]\n",
      "[Epoch 177/64] [Batch 751/937] [D loss: 0.592669] [G loss: 0.919181]\n",
      "[Epoch 177/64] [Batch 851/937] [D loss: 0.651887] [G loss: 0.934556]\n",
      "[Epoch 178/64] [Batch 14/937] [D loss: 0.643997] [G loss: 0.820922]\n",
      "[Epoch 178/64] [Batch 114/937] [D loss: 0.607356] [G loss: 0.851060]\n",
      "[Epoch 178/64] [Batch 214/937] [D loss: 0.655734] [G loss: 0.891175]\n",
      "[Epoch 178/64] [Batch 314/937] [D loss: 0.632592] [G loss: 0.903533]\n",
      "[Epoch 178/64] [Batch 414/937] [D loss: 0.596660] [G loss: 0.896871]\n",
      "[Epoch 178/64] [Batch 514/937] [D loss: 0.626382] [G loss: 0.949026]\n",
      "[Epoch 178/64] [Batch 614/937] [D loss: 0.597062] [G loss: 0.817840]\n",
      "[Epoch 178/64] [Batch 714/937] [D loss: 0.629843] [G loss: 0.858192]\n",
      "[Epoch 178/64] [Batch 814/937] [D loss: 0.684037] [G loss: 0.850664]\n",
      "[Epoch 178/64] [Batch 914/937] [D loss: 0.629300] [G loss: 0.875613]\n",
      "[Epoch 179/64] [Batch 77/937] [D loss: 0.654407] [G loss: 0.765623]\n",
      "[Epoch 179/64] [Batch 177/937] [D loss: 0.635642] [G loss: 0.850754]\n",
      "[Epoch 179/64] [Batch 277/937] [D loss: 0.613939] [G loss: 0.991484]\n",
      "[Epoch 179/64] [Batch 377/937] [D loss: 0.691074] [G loss: 0.851484]\n",
      "[Epoch 179/64] [Batch 477/937] [D loss: 0.690847] [G loss: 0.884627]\n",
      "[Epoch 179/64] [Batch 577/937] [D loss: 0.626789] [G loss: 0.971150]\n",
      "[Epoch 179/64] [Batch 677/937] [D loss: 0.663742] [G loss: 0.926068]\n",
      "[Epoch 179/64] [Batch 777/937] [D loss: 0.630174] [G loss: 0.865077]\n",
      "[Epoch 179/64] [Batch 877/937] [D loss: 0.713140] [G loss: 0.780761]\n",
      "[Epoch 180/64] [Batch 40/937] [D loss: 0.659848] [G loss: 0.800845]\n",
      "[Epoch 180/64] [Batch 140/937] [D loss: 0.614936] [G loss: 0.826900]\n",
      "[Epoch 180/64] [Batch 240/937] [D loss: 0.658608] [G loss: 0.811539]\n",
      "[Epoch 180/64] [Batch 340/937] [D loss: 0.733270] [G loss: 0.757730]\n",
      "[Epoch 180/64] [Batch 440/937] [D loss: 0.603479] [G loss: 0.851716]\n",
      "[Epoch 180/64] [Batch 540/937] [D loss: 0.617192] [G loss: 0.900198]\n",
      "[Epoch 180/64] [Batch 640/937] [D loss: 0.614437] [G loss: 0.937924]\n",
      "[Epoch 180/64] [Batch 740/937] [D loss: 0.637685] [G loss: 0.886078]\n",
      "[Epoch 180/64] [Batch 840/937] [D loss: 0.600958] [G loss: 1.007056]\n",
      "[Epoch 181/64] [Batch 3/937] [D loss: 0.649521] [G loss: 0.920615]\n",
      "[Epoch 181/64] [Batch 103/937] [D loss: 0.648896] [G loss: 0.861118]\n",
      "[Epoch 181/64] [Batch 203/937] [D loss: 0.601861] [G loss: 0.885497]\n",
      "[Epoch 181/64] [Batch 303/937] [D loss: 0.666070] [G loss: 0.861487]\n",
      "[Epoch 181/64] [Batch 403/937] [D loss: 0.631180] [G loss: 0.953094]\n",
      "[Epoch 181/64] [Batch 503/937] [D loss: 0.609091] [G loss: 0.874020]\n",
      "[Epoch 181/64] [Batch 603/937] [D loss: 0.632548] [G loss: 0.947000]\n",
      "[Epoch 181/64] [Batch 703/937] [D loss: 0.590424] [G loss: 0.828711]\n",
      "[Epoch 181/64] [Batch 803/937] [D loss: 0.644323] [G loss: 0.849902]\n",
      "[Epoch 181/64] [Batch 903/937] [D loss: 0.644492] [G loss: 0.895353]\n",
      "[Epoch 182/64] [Batch 66/937] [D loss: 0.640489] [G loss: 0.904536]\n",
      "[Epoch 182/64] [Batch 166/937] [D loss: 0.645311] [G loss: 0.834027]\n",
      "[Epoch 182/64] [Batch 266/937] [D loss: 0.636393] [G loss: 0.827320]\n",
      "[Epoch 182/64] [Batch 366/937] [D loss: 0.653834] [G loss: 0.887426]\n",
      "[Epoch 182/64] [Batch 466/937] [D loss: 0.623263] [G loss: 0.889702]\n",
      "[Epoch 182/64] [Batch 566/937] [D loss: 0.629588] [G loss: 0.876014]\n",
      "[Epoch 182/64] [Batch 666/937] [D loss: 0.636888] [G loss: 0.919115]\n",
      "[Epoch 182/64] [Batch 766/937] [D loss: 0.737477] [G loss: 0.875485]\n",
      "[Epoch 182/64] [Batch 866/937] [D loss: 0.599380] [G loss: 0.858714]\n",
      "[Epoch 183/64] [Batch 29/937] [D loss: 0.661622] [G loss: 0.936192]\n",
      "[Epoch 183/64] [Batch 129/937] [D loss: 0.665521] [G loss: 0.878708]\n",
      "[Epoch 183/64] [Batch 229/937] [D loss: 0.640101] [G loss: 0.816605]\n",
      "[Epoch 183/64] [Batch 329/937] [D loss: 0.619454] [G loss: 0.977227]\n",
      "[Epoch 183/64] [Batch 429/937] [D loss: 0.603898] [G loss: 0.831551]\n",
      "[Epoch 183/64] [Batch 529/937] [D loss: 0.623423] [G loss: 0.820296]\n",
      "[Epoch 183/64] [Batch 629/937] [D loss: 0.622227] [G loss: 0.860247]\n",
      "[Epoch 183/64] [Batch 729/937] [D loss: 0.619205] [G loss: 0.946564]\n",
      "[Epoch 183/64] [Batch 829/937] [D loss: 0.621529] [G loss: 0.823908]\n",
      "[Epoch 183/64] [Batch 929/937] [D loss: 0.678515] [G loss: 0.774858]\n",
      "[Epoch 184/64] [Batch 92/937] [D loss: 0.643967] [G loss: 0.855568]\n",
      "[Epoch 184/64] [Batch 192/937] [D loss: 0.623500] [G loss: 0.839778]\n",
      "[Epoch 184/64] [Batch 292/937] [D loss: 0.656326] [G loss: 0.851851]\n",
      "[Epoch 184/64] [Batch 392/937] [D loss: 0.619534] [G loss: 0.820246]\n",
      "[Epoch 184/64] [Batch 492/937] [D loss: 0.640358] [G loss: 0.876648]\n",
      "[Epoch 184/64] [Batch 592/937] [D loss: 0.644358] [G loss: 0.834511]\n",
      "[Epoch 184/64] [Batch 692/937] [D loss: 0.640367] [G loss: 0.881807]\n",
      "[Epoch 184/64] [Batch 792/937] [D loss: 0.583946] [G loss: 0.944015]\n",
      "[Epoch 184/64] [Batch 892/937] [D loss: 0.604232] [G loss: 0.856991]\n",
      "[Epoch 185/64] [Batch 55/937] [D loss: 0.617668] [G loss: 0.916326]\n",
      "[Epoch 185/64] [Batch 155/937] [D loss: 0.683501] [G loss: 0.921843]\n",
      "[Epoch 185/64] [Batch 255/937] [D loss: 0.649709] [G loss: 0.915310]\n",
      "[Epoch 185/64] [Batch 355/937] [D loss: 0.665598] [G loss: 0.821465]\n",
      "[Epoch 185/64] [Batch 455/937] [D loss: 0.629845] [G loss: 0.920259]\n",
      "[Epoch 185/64] [Batch 555/937] [D loss: 0.668672] [G loss: 0.863903]\n",
      "[Epoch 185/64] [Batch 655/937] [D loss: 0.610464] [G loss: 0.868840]\n",
      "[Epoch 185/64] [Batch 755/937] [D loss: 0.713373] [G loss: 0.830024]\n",
      "[Epoch 185/64] [Batch 855/937] [D loss: 0.611124] [G loss: 0.890521]\n",
      "[Epoch 186/64] [Batch 18/937] [D loss: 0.633676] [G loss: 0.980822]\n",
      "[Epoch 186/64] [Batch 118/937] [D loss: 0.672135] [G loss: 0.875329]\n",
      "[Epoch 186/64] [Batch 218/937] [D loss: 0.618364] [G loss: 0.922572]\n",
      "[Epoch 186/64] [Batch 318/937] [D loss: 0.620844] [G loss: 0.890805]\n",
      "[Epoch 186/64] [Batch 418/937] [D loss: 0.651905] [G loss: 0.886452]\n",
      "[Epoch 186/64] [Batch 518/937] [D loss: 0.677875] [G loss: 0.854957]\n",
      "[Epoch 186/64] [Batch 618/937] [D loss: 0.667441] [G loss: 0.890353]\n",
      "[Epoch 186/64] [Batch 718/937] [D loss: 0.644373] [G loss: 0.872696]\n",
      "[Epoch 186/64] [Batch 818/937] [D loss: 0.681469] [G loss: 0.850934]\n",
      "[Epoch 186/64] [Batch 918/937] [D loss: 0.673750] [G loss: 0.780672]\n",
      "[Epoch 187/64] [Batch 81/937] [D loss: 0.612741] [G loss: 0.839272]\n",
      "[Epoch 187/64] [Batch 181/937] [D loss: 0.642070] [G loss: 0.867189]\n",
      "[Epoch 187/64] [Batch 281/937] [D loss: 0.644561] [G loss: 0.787856]\n",
      "[Epoch 187/64] [Batch 381/937] [D loss: 0.666452] [G loss: 0.848721]\n",
      "[Epoch 187/64] [Batch 481/937] [D loss: 0.677382] [G loss: 0.799878]\n",
      "[Epoch 187/64] [Batch 581/937] [D loss: 0.616863] [G loss: 0.884980]\n",
      "[Epoch 187/64] [Batch 681/937] [D loss: 0.652496] [G loss: 0.927379]\n",
      "[Epoch 187/64] [Batch 781/937] [D loss: 0.675614] [G loss: 0.887724]\n",
      "[Epoch 187/64] [Batch 881/937] [D loss: 0.637289] [G loss: 0.904345]\n",
      "[Epoch 188/64] [Batch 44/937] [D loss: 0.612223] [G loss: 0.900135]\n",
      "[Epoch 188/64] [Batch 144/937] [D loss: 0.652675] [G loss: 0.835145]\n",
      "[Epoch 188/64] [Batch 244/937] [D loss: 0.652612] [G loss: 0.835343]\n",
      "[Epoch 188/64] [Batch 344/937] [D loss: 0.643259] [G loss: 0.874300]\n",
      "[Epoch 188/64] [Batch 444/937] [D loss: 0.644764] [G loss: 0.844233]\n",
      "[Epoch 188/64] [Batch 544/937] [D loss: 0.670051] [G loss: 0.834713]\n",
      "[Epoch 188/64] [Batch 644/937] [D loss: 0.642144] [G loss: 0.832715]\n",
      "[Epoch 188/64] [Batch 744/937] [D loss: 0.593831] [G loss: 0.874692]\n",
      "[Epoch 188/64] [Batch 844/937] [D loss: 0.665701] [G loss: 0.841394]\n",
      "[Epoch 189/64] [Batch 7/937] [D loss: 0.675625] [G loss: 0.910451]\n",
      "[Epoch 189/64] [Batch 107/937] [D loss: 0.615094] [G loss: 0.838111]\n",
      "[Epoch 189/64] [Batch 207/937] [D loss: 0.618479] [G loss: 0.865644]\n",
      "[Epoch 189/64] [Batch 307/937] [D loss: 0.641173] [G loss: 0.830886]\n",
      "[Epoch 189/64] [Batch 407/937] [D loss: 0.631398] [G loss: 0.834487]\n",
      "[Epoch 189/64] [Batch 507/937] [D loss: 0.612338] [G loss: 0.908437]\n",
      "[Epoch 189/64] [Batch 607/937] [D loss: 0.630010] [G loss: 0.864414]\n",
      "[Epoch 189/64] [Batch 707/937] [D loss: 0.626867] [G loss: 0.896724]\n",
      "[Epoch 189/64] [Batch 807/937] [D loss: 0.635005] [G loss: 0.917689]\n",
      "[Epoch 189/64] [Batch 907/937] [D loss: 0.610416] [G loss: 0.873095]\n",
      "[Epoch 190/64] [Batch 70/937] [D loss: 0.602067] [G loss: 0.947497]\n",
      "[Epoch 190/64] [Batch 170/937] [D loss: 0.705562] [G loss: 0.918347]\n",
      "[Epoch 190/64] [Batch 270/937] [D loss: 0.637188] [G loss: 0.831366]\n",
      "[Epoch 190/64] [Batch 370/937] [D loss: 0.635183] [G loss: 0.864407]\n",
      "[Epoch 190/64] [Batch 470/937] [D loss: 0.638858] [G loss: 0.771056]\n",
      "[Epoch 190/64] [Batch 570/937] [D loss: 0.622412] [G loss: 0.884841]\n",
      "[Epoch 190/64] [Batch 670/937] [D loss: 0.630641] [G loss: 0.792616]\n",
      "[Epoch 190/64] [Batch 770/937] [D loss: 0.629160] [G loss: 0.862608]\n",
      "[Epoch 190/64] [Batch 870/937] [D loss: 0.581997] [G loss: 0.895943]\n",
      "[Epoch 191/64] [Batch 33/937] [D loss: 0.622060] [G loss: 0.867467]\n",
      "[Epoch 191/64] [Batch 133/937] [D loss: 0.629497] [G loss: 0.840484]\n",
      "[Epoch 191/64] [Batch 233/937] [D loss: 0.633139] [G loss: 0.847867]\n",
      "[Epoch 191/64] [Batch 333/937] [D loss: 0.654039] [G loss: 0.829728]\n",
      "[Epoch 191/64] [Batch 433/937] [D loss: 0.660532] [G loss: 0.775726]\n",
      "[Epoch 191/64] [Batch 533/937] [D loss: 0.614823] [G loss: 0.899662]\n",
      "[Epoch 191/64] [Batch 633/937] [D loss: 0.655924] [G loss: 0.822628]\n",
      "[Epoch 191/64] [Batch 733/937] [D loss: 0.599528] [G loss: 0.831879]\n",
      "[Epoch 191/64] [Batch 833/937] [D loss: 0.647915] [G loss: 0.881765]\n",
      "[Epoch 191/64] [Batch 933/937] [D loss: 0.648312] [G loss: 0.899678]\n",
      "[Epoch 192/64] [Batch 96/937] [D loss: 0.652458] [G loss: 0.869734]\n",
      "[Epoch 192/64] [Batch 196/937] [D loss: 0.657121] [G loss: 0.927822]\n",
      "[Epoch 192/64] [Batch 296/937] [D loss: 0.608033] [G loss: 0.881643]\n",
      "[Epoch 192/64] [Batch 396/937] [D loss: 0.649109] [G loss: 1.006991]\n",
      "[Epoch 192/64] [Batch 496/937] [D loss: 0.636728] [G loss: 0.877412]\n",
      "[Epoch 192/64] [Batch 596/937] [D loss: 0.695517] [G loss: 0.855422]\n",
      "[Epoch 192/64] [Batch 696/937] [D loss: 0.625984] [G loss: 0.872524]\n",
      "[Epoch 192/64] [Batch 796/937] [D loss: 0.690506] [G loss: 0.824116]\n",
      "[Epoch 192/64] [Batch 896/937] [D loss: 0.669268] [G loss: 0.902552]\n",
      "[Epoch 193/64] [Batch 59/937] [D loss: 0.610837] [G loss: 0.889792]\n",
      "[Epoch 193/64] [Batch 159/937] [D loss: 0.642403] [G loss: 0.789754]\n",
      "[Epoch 193/64] [Batch 259/937] [D loss: 0.678463] [G loss: 0.828406]\n",
      "[Epoch 193/64] [Batch 359/937] [D loss: 0.625808] [G loss: 0.845902]\n",
      "[Epoch 193/64] [Batch 459/937] [D loss: 0.636999] [G loss: 0.761630]\n",
      "[Epoch 193/64] [Batch 559/937] [D loss: 0.629884] [G loss: 0.726394]\n",
      "[Epoch 193/64] [Batch 659/937] [D loss: 0.595742] [G loss: 0.865275]\n",
      "[Epoch 193/64] [Batch 759/937] [D loss: 0.652065] [G loss: 0.942647]\n",
      "[Epoch 193/64] [Batch 859/937] [D loss: 0.644576] [G loss: 0.921720]\n",
      "[Epoch 194/64] [Batch 22/937] [D loss: 0.610461] [G loss: 0.832548]\n",
      "[Epoch 194/64] [Batch 122/937] [D loss: 0.639556] [G loss: 0.816091]\n",
      "[Epoch 194/64] [Batch 222/937] [D loss: 0.605497] [G loss: 0.865516]\n",
      "[Epoch 194/64] [Batch 322/937] [D loss: 0.675506] [G loss: 0.879731]\n",
      "[Epoch 194/64] [Batch 422/937] [D loss: 0.619891] [G loss: 0.898333]\n",
      "[Epoch 194/64] [Batch 522/937] [D loss: 0.620635] [G loss: 0.920618]\n",
      "[Epoch 194/64] [Batch 622/937] [D loss: 0.665710] [G loss: 0.873963]\n",
      "[Epoch 194/64] [Batch 722/937] [D loss: 0.669966] [G loss: 0.819112]\n",
      "[Epoch 194/64] [Batch 822/937] [D loss: 0.639964] [G loss: 0.839930]\n",
      "[Epoch 194/64] [Batch 922/937] [D loss: 0.672211] [G loss: 0.811562]\n",
      "[Epoch 195/64] [Batch 85/937] [D loss: 0.645298] [G loss: 0.797592]\n",
      "[Epoch 195/64] [Batch 185/937] [D loss: 0.715181] [G loss: 0.841102]\n",
      "[Epoch 195/64] [Batch 285/937] [D loss: 0.647087] [G loss: 0.853997]\n",
      "[Epoch 195/64] [Batch 385/937] [D loss: 0.614588] [G loss: 0.875960]\n",
      "[Epoch 195/64] [Batch 485/937] [D loss: 0.663722] [G loss: 0.821391]\n",
      "[Epoch 195/64] [Batch 585/937] [D loss: 0.623398] [G loss: 0.971881]\n",
      "[Epoch 195/64] [Batch 685/937] [D loss: 0.619593] [G loss: 0.923607]\n",
      "[Epoch 195/64] [Batch 785/937] [D loss: 0.602854] [G loss: 1.024518]\n",
      "[Epoch 195/64] [Batch 885/937] [D loss: 0.623348] [G loss: 0.788620]\n",
      "[Epoch 196/64] [Batch 48/937] [D loss: 0.666860] [G loss: 0.838890]\n",
      "[Epoch 196/64] [Batch 148/937] [D loss: 0.652429] [G loss: 0.895091]\n",
      "[Epoch 196/64] [Batch 248/937] [D loss: 0.660724] [G loss: 0.802676]\n",
      "[Epoch 196/64] [Batch 348/937] [D loss: 0.637144] [G loss: 0.731848]\n",
      "[Epoch 196/64] [Batch 448/937] [D loss: 0.591375] [G loss: 0.902988]\n",
      "[Epoch 196/64] [Batch 548/937] [D loss: 0.609131] [G loss: 0.752762]\n",
      "[Epoch 196/64] [Batch 648/937] [D loss: 0.596469] [G loss: 0.886530]\n",
      "[Epoch 196/64] [Batch 748/937] [D loss: 0.630812] [G loss: 0.841888]\n",
      "[Epoch 196/64] [Batch 848/937] [D loss: 0.638874] [G loss: 0.787007]\n",
      "[Epoch 197/64] [Batch 11/937] [D loss: 0.687362] [G loss: 0.864291]\n",
      "[Epoch 197/64] [Batch 111/937] [D loss: 0.636202] [G loss: 0.876776]\n",
      "[Epoch 197/64] [Batch 211/937] [D loss: 0.607238] [G loss: 0.835014]\n",
      "[Epoch 197/64] [Batch 311/937] [D loss: 0.585387] [G loss: 0.800468]\n",
      "[Epoch 197/64] [Batch 411/937] [D loss: 0.628620] [G loss: 0.872126]\n",
      "[Epoch 197/64] [Batch 511/937] [D loss: 0.671370] [G loss: 0.819613]\n",
      "[Epoch 197/64] [Batch 611/937] [D loss: 0.623266] [G loss: 0.840169]\n",
      "[Epoch 197/64] [Batch 711/937] [D loss: 0.603993] [G loss: 0.815516]\n",
      "[Epoch 197/64] [Batch 811/937] [D loss: 0.595666] [G loss: 0.856330]\n",
      "[Epoch 197/64] [Batch 911/937] [D loss: 0.697519] [G loss: 0.891563]\n",
      "[Epoch 198/64] [Batch 74/937] [D loss: 0.628928] [G loss: 0.900235]\n",
      "[Epoch 198/64] [Batch 174/937] [D loss: 0.606470] [G loss: 0.858719]\n",
      "[Epoch 198/64] [Batch 274/937] [D loss: 0.593131] [G loss: 0.798408]\n",
      "[Epoch 198/64] [Batch 374/937] [D loss: 0.661164] [G loss: 0.826479]\n",
      "[Epoch 198/64] [Batch 474/937] [D loss: 0.613694] [G loss: 0.836721]\n",
      "[Epoch 198/64] [Batch 574/937] [D loss: 0.614159] [G loss: 0.963277]\n",
      "[Epoch 198/64] [Batch 674/937] [D loss: 0.650010] [G loss: 0.877648]\n",
      "[Epoch 198/64] [Batch 774/937] [D loss: 0.652446] [G loss: 0.778931]\n",
      "[Epoch 198/64] [Batch 874/937] [D loss: 0.603047] [G loss: 0.814424]\n",
      "[Epoch 199/64] [Batch 37/937] [D loss: 0.601452] [G loss: 0.890141]\n",
      "[Epoch 199/64] [Batch 137/937] [D loss: 0.615642] [G loss: 0.826037]\n",
      "[Epoch 199/64] [Batch 237/937] [D loss: 0.646081] [G loss: 0.914598]\n",
      "[Epoch 199/64] [Batch 337/937] [D loss: 0.599201] [G loss: 0.813383]\n",
      "[Epoch 199/64] [Batch 437/937] [D loss: 0.639444] [G loss: 0.926664]\n",
      "[Epoch 199/64] [Batch 537/937] [D loss: 0.671572] [G loss: 0.842641]\n",
      "[Epoch 199/64] [Batch 637/937] [D loss: 0.618729] [G loss: 0.883241]\n",
      "[Epoch 199/64] [Batch 737/937] [D loss: 0.633460] [G loss: 0.985876]\n",
      "[Epoch 199/64] [Batch 837/937] [D loss: 0.609768] [G loss: 0.887353]\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"./mlpgan\", exist_ok=True)\n",
    "for epoch in range(200):\n",
    "    for i, (real_imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        real_imgs = real_imgs.cuda()\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = torch.Tensor(np.random.normal(0, 1, (real_imgs.shape[0], 100))).cuda()\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "        \n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), torch.ones((gen_imgs.size(0),1)).cuda())\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), torch.ones((gen_imgs.size(0),1)).cuda())\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), torch.zeros((gen_imgs.size(0),1)).cuda())\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        \n",
    "        if batches_done % 100 == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (epoch, 64, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "            )\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % 2000 == 0:\n",
    "            save_image(gen_imgs.data[:25], \"mlpgan/%d.png\" % batches_done, nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d542b-9180-401e-a5f3-57564121b102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e37e4f-2eaa-46ad-9fba-5aa956a3392f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
