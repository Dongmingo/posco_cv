{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ad4877-2ae8-4fb0-8649-824aff1064f7",
   "metadata": {},
   "source": [
    "Referecnce : https://github.com/eriklindernoren/PyTorch-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ede26885-108e-4524-8acf-52b96f04ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae79be69-3c33-481c-955e-1bae591e32e4",
   "metadata": {},
   "source": [
    "### Generator architecture\n",
    "* input random vector: 100 dim, labels\n",
    "* embedding layer: embeding labels to 100 dim\n",
    "* linear layer: out_features 128 * 8 * 8\n",
    "* batchnorm\n",
    "* upsample: factor 2\n",
    "* Conv2d: out_channel: 128, kernel size 3, stride 1, padding 1\n",
    "* batchnorm\n",
    "* leakyrelu: 0.2\n",
    "* upsample: factor 2\n",
    "* conv2d: out_channel: 64, kernel size 3, stride 1, padding 1\n",
    "* batchnorm\n",
    "* leakyrelu: 0.2\n",
    "* conv2d: out_channel: 1, kernel size 3, stride 1, padding 1\n",
    "* tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b2f3ac-9e09-473f-ab69-9d9360dad41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        ## fill here\n",
    "        self.label_emb = nn.Embedding(10, 100)\n",
    "        \n",
    "        self.l1 = nn.Sequential(nn.Linear(100, 128*8*8))\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Conv2d(64, 1, 3, stride=1, padding=1),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        ## fill here\n",
    "        gen_input = torch.mul(self.label_emb(labels), noise)\n",
    "        out = self.l1(gen_input)\n",
    "        out = out.view(out.shape[0], 128, 8, 8)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd819a1-71bf-4a43-adf0-8ff85d9318e7",
   "metadata": {},
   "source": [
    "### Discriminator architecture\n",
    "* input: [1 , 32 , 32] image \n",
    "* conv2d: out_channel: 16, kernel size 3, stride 2, padding 1\n",
    "* leakyrelu: 0.2\n",
    "* dropout: 0.25\n",
    "* Conv2d: out_channel: 32, kernel size 3, stride 2, padding 1\n",
    "* leakyrelu: 0.2\n",
    "* dropout: 0.25\n",
    "* batchnorm\n",
    "* Conv2d: out_channel: 64, kernel size 3, stride 2, padding 1\n",
    "* leakyrelu: 0.2\n",
    "* dropout: 0.25\n",
    "* batchnorm\n",
    "* Conv2d: out_channel: 128, kernel size 3, stride 2, padding 1\n",
    "* leakyrelu: 0.2\n",
    "* dropout: 0.25\n",
    "* batchnorm\n",
    "* two linear layers: one for adversarial loss, one for classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f59bb0e7-928c-42af-81d2-5882061144cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        ## fill here\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2), nn.Dropout2d(0.25)]\n",
    "            \n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters))\n",
    "            return block ## *list\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            *discriminator_block(1, 16, bn=False), ## 16 * 16 * 16\n",
    "            *discriminator_block(16, 32), ## 32 * 8 * 8\n",
    "            *discriminator_block(32, 64), ## 64 * 4 * 4\n",
    "            *discriminator_block(64, 128),## 128 * 2 * 2 = 512\n",
    "        )\n",
    "        \n",
    "        self.adv_layer = nn.Sequential(nn.Linear(512, 1), nn.Sigmoid())\n",
    "        self.aux_layer = nn.Sequential(nn.Linear(512, 10))\n",
    "\n",
    "    def forward(self, img):\n",
    "        ## fill here\n",
    "        out = self.conv_blocks(img) ## 128 by 2 by 2\n",
    "        out = out.view(out.shape[0], -1) ## batch_size * 512\n",
    "        validity = self.adv_layer(out)\n",
    "        label = self.aux_layer(out)\n",
    "        return validity, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7d5e89-c18f-41b8-b958-d86b3dc76bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = Generator()\n",
    "\n",
    "# input_sample = torch.randn(2,100)\n",
    "# labels = torch.Tensor([0, 1]).long()\n",
    "# output = generator(input_sample, labels)\n",
    "# output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8728f4c-c09b-405a-9712-f8549c0626da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "auxiliary_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator().cuda()\n",
    "discriminator = Discriminator().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58be1559-7ce5-4963-bcc9-908f51675242",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(\"../data/mnist\", train=True, download=True, \n",
    "                         transform=transforms.Compose([transforms.Resize(32), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d249fb70-78cf-4191-9d58-afd3d6d4572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## optimizer fill here\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.00002, betas=(0.5, 0.9999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.00002, betas=(0.5, 0.9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbfef8fc-4641-4709-a977-1127c75dc9eb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"./acgan_images\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99cec29e-9455-49e5-9d70-a2775d9a4d34",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_image(n_row, batches_done):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    z = torch.Tensor(np.random.normal(0, 1, (n_row ** 2, 100))).cuda()\n",
    "    # Get labels ranging from 0 to n_classes for n rows\n",
    "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
    "    labels = torch.LongTensor(labels).cuda()\n",
    "    gen_imgs = generator(z, labels)\n",
    "    save_image(gen_imgs, \"acgan_images/%d.png\" % batches_done, nrow=n_row, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82726823-448c-46d1-9c13-dd4decfae34c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/937] [D loss: 1.579751, acc: 6%] [G loss: 1.586793]\n",
      "[Epoch 0/200] [Batch 100/937] [D loss: 1.463645, acc: 12%] [G loss: 1.529694]\n",
      "[Epoch 0/200] [Batch 200/937] [D loss: 1.371188, acc: 28%] [G loss: 1.520335]\n",
      "[Epoch 0/200] [Batch 300/937] [D loss: 1.336450, acc: 26%] [G loss: 1.473397]\n",
      "[Epoch 0/200] [Batch 400/937] [D loss: 1.280214, acc: 36%] [G loss: 1.504840]\n",
      "[Epoch 0/200] [Batch 500/937] [D loss: 1.243498, acc: 34%] [G loss: 1.447753]\n",
      "[Epoch 0/200] [Batch 600/937] [D loss: 1.276594, acc: 29%] [G loss: 1.469209]\n",
      "[Epoch 0/200] [Batch 700/937] [D loss: 1.202138, acc: 39%] [G loss: 1.451305]\n",
      "[Epoch 0/200] [Batch 800/937] [D loss: 1.127721, acc: 39%] [G loss: 1.487319]\n",
      "[Epoch 0/200] [Batch 900/937] [D loss: 1.113358, acc: 45%] [G loss: 1.505359]\n",
      "[Epoch 1/200] [Batch 63/937] [D loss: 1.039862, acc: 50%] [G loss: 1.382103]\n",
      "[Epoch 1/200] [Batch 163/937] [D loss: 0.985844, acc: 60%] [G loss: 1.278590]\n",
      "[Epoch 1/200] [Batch 263/937] [D loss: 0.956709, acc: 54%] [G loss: 1.353388]\n",
      "[Epoch 1/200] [Batch 363/937] [D loss: 0.961532, acc: 58%] [G loss: 1.290268]\n",
      "[Epoch 1/200] [Batch 463/937] [D loss: 0.854682, acc: 67%] [G loss: 1.187613]\n",
      "[Epoch 1/200] [Batch 563/937] [D loss: 0.887199, acc: 60%] [G loss: 1.228010]\n",
      "[Epoch 1/200] [Batch 663/937] [D loss: 0.902717, acc: 60%] [G loss: 1.139923]\n",
      "[Epoch 1/200] [Batch 763/937] [D loss: 0.727332, acc: 76%] [G loss: 1.010283]\n",
      "[Epoch 1/200] [Batch 863/937] [D loss: 0.793445, acc: 73%] [G loss: 1.017078]\n",
      "[Epoch 2/200] [Batch 26/937] [D loss: 0.695158, acc: 78%] [G loss: 0.803335]\n",
      "[Epoch 2/200] [Batch 126/937] [D loss: 0.700409, acc: 81%] [G loss: 0.846457]\n",
      "[Epoch 2/200] [Batch 226/937] [D loss: 0.621411, acc: 83%] [G loss: 0.850396]\n",
      "[Epoch 2/200] [Batch 326/937] [D loss: 0.644819, acc: 82%] [G loss: 0.774080]\n",
      "[Epoch 2/200] [Batch 426/937] [D loss: 0.708841, acc: 81%] [G loss: 0.765860]\n",
      "[Epoch 2/200] [Batch 526/937] [D loss: 0.654544, acc: 83%] [G loss: 0.702206]\n",
      "[Epoch 2/200] [Batch 626/937] [D loss: 0.578725, acc: 87%] [G loss: 0.697677]\n",
      "[Epoch 2/200] [Batch 726/937] [D loss: 0.612973, acc: 83%] [G loss: 0.745460]\n",
      "[Epoch 2/200] [Batch 826/937] [D loss: 0.550775, acc: 88%] [G loss: 0.666189]\n",
      "[Epoch 2/200] [Batch 926/937] [D loss: 0.536840, acc: 91%] [G loss: 0.592485]\n",
      "[Epoch 3/200] [Batch 89/937] [D loss: 0.567400, acc: 86%] [G loss: 0.664387]\n",
      "[Epoch 3/200] [Batch 189/937] [D loss: 0.494109, acc: 89%] [G loss: 0.647504]\n",
      "[Epoch 3/200] [Batch 289/937] [D loss: 0.521931, acc: 91%] [G loss: 0.576462]\n",
      "[Epoch 3/200] [Batch 389/937] [D loss: 0.506884, acc: 88%] [G loss: 0.639045]\n",
      "[Epoch 3/200] [Batch 489/937] [D loss: 0.539177, acc: 86%] [G loss: 0.559898]\n",
      "[Epoch 3/200] [Batch 589/937] [D loss: 0.496526, acc: 88%] [G loss: 0.647729]\n",
      "[Epoch 3/200] [Batch 689/937] [D loss: 0.577327, acc: 85%] [G loss: 0.564604]\n",
      "[Epoch 3/200] [Batch 789/937] [D loss: 0.519369, acc: 89%] [G loss: 0.519112]\n",
      "[Epoch 3/200] [Batch 889/937] [D loss: 0.514320, acc: 85%] [G loss: 0.619145]\n",
      "[Epoch 4/200] [Batch 52/937] [D loss: 0.516486, acc: 89%] [G loss: 0.529058]\n",
      "[Epoch 4/200] [Batch 152/937] [D loss: 0.494734, acc: 84%] [G loss: 0.611803]\n",
      "[Epoch 4/200] [Batch 252/937] [D loss: 0.512273, acc: 87%] [G loss: 0.662383]\n",
      "[Epoch 4/200] [Batch 352/937] [D loss: 0.464034, acc: 91%] [G loss: 0.551525]\n",
      "[Epoch 4/200] [Batch 452/937] [D loss: 0.426354, acc: 93%] [G loss: 0.515319]\n",
      "[Epoch 4/200] [Batch 552/937] [D loss: 0.576768, acc: 83%] [G loss: 0.585103]\n",
      "[Epoch 4/200] [Batch 652/937] [D loss: 0.487184, acc: 93%] [G loss: 0.603379]\n",
      "[Epoch 4/200] [Batch 752/937] [D loss: 0.428119, acc: 90%] [G loss: 0.558362]\n",
      "[Epoch 4/200] [Batch 852/937] [D loss: 0.470991, acc: 88%] [G loss: 0.570931]\n",
      "[Epoch 5/200] [Batch 15/937] [D loss: 0.449981, acc: 91%] [G loss: 0.591296]\n",
      "[Epoch 5/200] [Batch 115/937] [D loss: 0.451537, acc: 92%] [G loss: 0.582814]\n",
      "[Epoch 5/200] [Batch 215/937] [D loss: 0.438946, acc: 96%] [G loss: 0.552206]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-19c89bc60e7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreal_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \"\"\"\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    for i, (real_imgs, labels) in enumerate(dataloader):\n",
    "\n",
    "        batch_size = real_imgs.shape[0]\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = real_imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        z = torch.Tensor(np.random.normal(0,1, (batch_size, 100))).cuda()\n",
    "        gen_labels = torch.LongTensor(np.random.randint(0, 10, batch_size)).cuda()\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        ## fill here\n",
    "        optimizer_G.zero_grad()\n",
    "        gen_imgs = generator(z, gen_labels)\n",
    "        \n",
    "        validity, fake_aux = discriminator(gen_imgs)\n",
    "        g_loss = 0.5*(adversarial_loss(validity, torch.ones((gen_imgs.size(0), 1)).cuda())\n",
    "                     + auxiliary_loss(fake_aux, gen_labels))\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        # Loss for real images\n",
    "        real_pred, real_aux = discriminator(real_imgs)\n",
    "        d_real_loss = (adversarial_loss(real_pred, torch.ones((gen_imgs.size(0),1)).cuda()) + auxiliary_loss(real_aux, labels)) / 2\n",
    "\n",
    "        # Loss for fake images\n",
    "        fake_pred, fake_aux = discriminator(gen_imgs.detach())\n",
    "        d_fake_loss = (adversarial_loss(fake_pred, torch.zeros((gen_imgs.size(0),1)).cuda()) + auxiliary_loss(fake_aux, gen_labels)) / 2\n",
    "\n",
    "        # Total discriminator loss\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "        \n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # Calculate discriminator accuracy\n",
    "        pred = np.concatenate([real_aux.detach().cpu().numpy(), fake_aux.detach().cpu().numpy()], axis=0)\n",
    "        gt = np.concatenate([labels.detach().cpu().numpy(), gen_labels.detach().cpu().numpy()], axis=0)\n",
    "        d_acc = np.mean(np.argmax(pred, axis=1) == gt)\n",
    "        \n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % 100 == 0:     \n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %d%%] [G loss: %f]\"\n",
    "                % (epoch, 200, i, len(dataloader), d_loss.item(), 100 * d_acc, g_loss.item())\n",
    "            )\n",
    "            \n",
    "        if batches_done % 2000 == 0:\n",
    "            sample_image(n_row=10, batches_done=batches_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d542b-9180-401e-a5f3-57564121b102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e37e4f-2eaa-46ad-9fba-5aa956a3392f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
