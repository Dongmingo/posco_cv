{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ad4877-2ae8-4fb0-8649-824aff1064f7",
   "metadata": {},
   "source": [
    "Referecnce : https://github.com/eriklindernoren/PyTorch-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede26885-108e-4524-8acf-52b96f04ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb42372-adb1-4366-b6b1-c6d5cb022789",
   "metadata": {},
   "source": [
    "### Generator architecture\n",
    "* input random vector: 100 dim\n",
    "* linear layer: out_features 128 * 8 * 8\n",
    "* batchnorm\n",
    "* upsample: factor 2\n",
    "* Conv2d: out_channel: 128, kernel size 3, stride 1, padding 1\n",
    "* batchnorm\n",
    "* leakyrelu: 0.2\n",
    "* upsample: factor 2\n",
    "* conv2d: out_channel: 64, kernel size 3, stride 1, padding 1\n",
    "* batchnorm\n",
    "* leakyrelu: 0.2\n",
    "* conv2d: out_channel: 1, kernel size 3, stride 1, padding 1\n",
    "* tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23b2f3ac-9e09-473f-ab69-9d9360dad41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        ##implement\n",
    "        ## input [batch, 100]\n",
    "        self.l1 = nn.Linear(100, 128*8*8)\n",
    "        self.conv_blocks = nn.Sequential( #[batch, 128, 8, 8]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor =2), #[16,16]\n",
    "            nn.Conv2d(128, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Upsample(scale_factor =2), #[32, 32]\n",
    "            nn.Conv2d(128, 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 1, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        ##implement\n",
    "        out = self.l1(z) #[batch,, 128*8*8]\n",
    "        out = out.view(out.shape[0], 128, 8, 8)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dede475-d492-4dc9-a1ca-86f5d4628918",
   "metadata": {},
   "source": [
    "### Discriminator architecture\n",
    "* input: [1 , 32 , 32] image \n",
    "* conv2d: out_channel: 16, kernel size 3, stride 2, padding 1\n",
    "* leakyrelu: 0.2\n",
    "* dropout: 0.25\n",
    "* Conv2d: out_channel: 32, kernel size 3, stride 2, padding 1\n",
    "* leakyrelu: 0.2\n",
    "* dropout: 0.25\n",
    "* batchnorm\n",
    "* Conv2d: out_channel: 64, kernel size 3, stride 2, padding 1\n",
    "* leakyrelu: 0.2\n",
    "* dropout: 0.25\n",
    "* batchnorm\n",
    "* Conv2d: out_channel: 128, kernel size 3, stride 2, padding 1\n",
    "* leakyrelu: 0.2\n",
    "* dropout: 0.25\n",
    "* batchnorm\n",
    "* linear: out_features 1\n",
    "* sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f59bb0e7-928c-42af-81d2-5882061144cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        ##implement\n",
    "        def discriminator_block(in_features, out_features, bn = True):\n",
    "            block = []\n",
    "            block.append(\n",
    "                nn.Conv2d(in_features, out_features, kernel_size = 3, stride = 2, padding = 1)\n",
    "            )\n",
    "            block.append(nn.LeakyReLU(0.2))\n",
    "            block.append(nn.Dropout2d(0.25))\n",
    "            \n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_features))\n",
    "            \n",
    "            return block\n",
    "        \n",
    "        self.model = nn.Sequential( #[batch, 1, 32, 32]\n",
    "            *discriminator_block(1, 16, bn = False), #[16, 16]\n",
    "            *discriminator_block(16, 32),#[8, 8]\n",
    "            *discriminator_block(32, 64),#[4, 4]\n",
    "            *discriminator_block(64, 128)#[batch, 128, 2, 2]\n",
    "        )\n",
    "        self.adv_layer = nn.Sequential(\n",
    "            nn.Linear(128*2*2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, img):# [1, 32, 32]\n",
    "        ##implement\n",
    "        out = self.model(img) # [batch, 128, 2, 2]\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.adv_layer(out) # [batch, 1]\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8728f4c-c09b-405a-9712-f8549c0626da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator().cuda()\n",
    "discriminator = Discriminator().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58be1559-7ce5-4963-bcc9-908f51675242",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"./mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose( \n",
    "            [transforms.Resize(32), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d249fb70-78cf-4191-9d58-afd3d6d4572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.00002, betas=(0.5, 0.9999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.00002, betas=(0.5, 0.9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66ffa729-5cdb-4db5-8e84-570112994da1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"./dcgan_images\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82726823-448c-46d1-9c13-dd4decfae34c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/64] [Batch 0/937] [D loss: 0.735453] [G loss: 0.838843]\n",
      "[Epoch 0/64] [Batch 100/937] [D loss: 0.535716] [G loss: 0.738260]\n",
      "[Epoch 0/64] [Batch 200/937] [D loss: 0.610722] [G loss: 0.651718]\n",
      "[Epoch 0/64] [Batch 300/937] [D loss: 0.632699] [G loss: 0.684595]\n",
      "[Epoch 0/64] [Batch 400/937] [D loss: 0.591639] [G loss: 0.822962]\n",
      "[Epoch 0/64] [Batch 500/937] [D loss: 0.613809] [G loss: 0.772098]\n",
      "[Epoch 0/64] [Batch 600/937] [D loss: 0.615125] [G loss: 0.857345]\n",
      "[Epoch 0/64] [Batch 700/937] [D loss: 0.637299] [G loss: 0.919485]\n",
      "[Epoch 0/64] [Batch 800/937] [D loss: 0.632414] [G loss: 0.928242]\n",
      "[Epoch 0/64] [Batch 900/937] [D loss: 0.649178] [G loss: 0.823745]\n",
      "[Epoch 1/64] [Batch 63/937] [D loss: 0.696662] [G loss: 0.783806]\n",
      "[Epoch 1/64] [Batch 163/937] [D loss: 0.675219] [G loss: 0.808673]\n",
      "[Epoch 1/64] [Batch 263/937] [D loss: 0.686528] [G loss: 0.789750]\n",
      "[Epoch 1/64] [Batch 363/937] [D loss: 0.671619] [G loss: 0.851505]\n",
      "[Epoch 1/64] [Batch 463/937] [D loss: 0.688585] [G loss: 0.802248]\n",
      "[Epoch 1/64] [Batch 563/937] [D loss: 0.665072] [G loss: 0.806508]\n",
      "[Epoch 1/64] [Batch 663/937] [D loss: 0.652934] [G loss: 0.738360]\n",
      "[Epoch 1/64] [Batch 763/937] [D loss: 0.683622] [G loss: 0.781662]\n",
      "[Epoch 1/64] [Batch 863/937] [D loss: 0.714884] [G loss: 0.748734]\n",
      "[Epoch 2/64] [Batch 26/937] [D loss: 0.675808] [G loss: 0.729105]\n",
      "[Epoch 2/64] [Batch 126/937] [D loss: 0.665492] [G loss: 0.767072]\n",
      "[Epoch 2/64] [Batch 226/937] [D loss: 0.680548] [G loss: 0.741911]\n",
      "[Epoch 2/64] [Batch 326/937] [D loss: 0.686567] [G loss: 0.695779]\n",
      "[Epoch 2/64] [Batch 426/937] [D loss: 0.681226] [G loss: 0.733513]\n",
      "[Epoch 2/64] [Batch 526/937] [D loss: 0.675189] [G loss: 0.745188]\n",
      "[Epoch 2/64] [Batch 626/937] [D loss: 0.672113] [G loss: 0.795567]\n",
      "[Epoch 2/64] [Batch 726/937] [D loss: 0.686142] [G loss: 0.739425]\n",
      "[Epoch 2/64] [Batch 826/937] [D loss: 0.645302] [G loss: 0.767757]\n",
      "[Epoch 2/64] [Batch 926/937] [D loss: 0.661581] [G loss: 0.735805]\n",
      "[Epoch 3/64] [Batch 89/937] [D loss: 0.662891] [G loss: 0.720685]\n",
      "[Epoch 3/64] [Batch 189/937] [D loss: 0.707598] [G loss: 0.720568]\n",
      "[Epoch 3/64] [Batch 289/937] [D loss: 0.655355] [G loss: 0.813269]\n",
      "[Epoch 3/64] [Batch 389/937] [D loss: 0.640100] [G loss: 0.768801]\n",
      "[Epoch 3/64] [Batch 489/937] [D loss: 0.648257] [G loss: 0.810814]\n",
      "[Epoch 3/64] [Batch 589/937] [D loss: 0.640433] [G loss: 0.750889]\n",
      "[Epoch 3/64] [Batch 689/937] [D loss: 0.664170] [G loss: 0.820609]\n",
      "[Epoch 3/64] [Batch 789/937] [D loss: 0.705342] [G loss: 0.770444]\n",
      "[Epoch 3/64] [Batch 889/937] [D loss: 0.673774] [G loss: 0.757322]\n",
      "[Epoch 4/64] [Batch 52/937] [D loss: 0.657570] [G loss: 0.757016]\n",
      "[Epoch 4/64] [Batch 152/937] [D loss: 0.692382] [G loss: 0.772405]\n",
      "[Epoch 4/64] [Batch 252/937] [D loss: 0.637874] [G loss: 0.768469]\n",
      "[Epoch 4/64] [Batch 352/937] [D loss: 0.649133] [G loss: 0.853092]\n",
      "[Epoch 4/64] [Batch 452/937] [D loss: 0.662855] [G loss: 0.759063]\n",
      "[Epoch 4/64] [Batch 552/937] [D loss: 0.638948] [G loss: 0.716347]\n",
      "[Epoch 4/64] [Batch 652/937] [D loss: 0.666520] [G loss: 0.765762]\n",
      "[Epoch 4/64] [Batch 752/937] [D loss: 0.675847] [G loss: 0.800542]\n",
      "[Epoch 4/64] [Batch 852/937] [D loss: 0.681302] [G loss: 0.842774]\n",
      "[Epoch 5/64] [Batch 15/937] [D loss: 0.664030] [G loss: 0.804865]\n",
      "[Epoch 5/64] [Batch 115/937] [D loss: 0.649142] [G loss: 0.714572]\n",
      "[Epoch 5/64] [Batch 215/937] [D loss: 0.620238] [G loss: 0.742324]\n",
      "[Epoch 5/64] [Batch 315/937] [D loss: 0.618861] [G loss: 0.795458]\n",
      "[Epoch 5/64] [Batch 415/937] [D loss: 0.634053] [G loss: 0.814529]\n",
      "[Epoch 5/64] [Batch 515/937] [D loss: 0.625339] [G loss: 0.770625]\n",
      "[Epoch 5/64] [Batch 615/937] [D loss: 0.638278] [G loss: 0.840123]\n",
      "[Epoch 5/64] [Batch 715/937] [D loss: 0.610625] [G loss: 0.919684]\n",
      "[Epoch 5/64] [Batch 815/937] [D loss: 0.648281] [G loss: 0.772705]\n",
      "[Epoch 5/64] [Batch 915/937] [D loss: 0.623884] [G loss: 0.799291]\n",
      "[Epoch 6/64] [Batch 78/937] [D loss: 0.621704] [G loss: 0.876847]\n",
      "[Epoch 6/64] [Batch 178/937] [D loss: 0.642762] [G loss: 0.862317]\n",
      "[Epoch 6/64] [Batch 278/937] [D loss: 0.654114] [G loss: 0.882021]\n",
      "[Epoch 6/64] [Batch 378/937] [D loss: 0.626486] [G loss: 0.826663]\n",
      "[Epoch 6/64] [Batch 478/937] [D loss: 0.584453] [G loss: 0.917059]\n",
      "[Epoch 6/64] [Batch 578/937] [D loss: 0.631795] [G loss: 0.877849]\n",
      "[Epoch 6/64] [Batch 678/937] [D loss: 0.613154] [G loss: 0.854801]\n",
      "[Epoch 6/64] [Batch 778/937] [D loss: 0.599860] [G loss: 0.854356]\n",
      "[Epoch 6/64] [Batch 878/937] [D loss: 0.582974] [G loss: 1.032571]\n",
      "[Epoch 7/64] [Batch 41/937] [D loss: 0.527352] [G loss: 0.963115]\n",
      "[Epoch 7/64] [Batch 141/937] [D loss: 0.591302] [G loss: 0.755190]\n",
      "[Epoch 7/64] [Batch 241/937] [D loss: 0.587830] [G loss: 0.878545]\n",
      "[Epoch 7/64] [Batch 341/937] [D loss: 0.598039] [G loss: 0.754932]\n",
      "[Epoch 7/64] [Batch 441/937] [D loss: 0.588112] [G loss: 0.873980]\n",
      "[Epoch 7/64] [Batch 541/937] [D loss: 0.636578] [G loss: 0.788872]\n",
      "[Epoch 7/64] [Batch 641/937] [D loss: 0.624251] [G loss: 0.932948]\n",
      "[Epoch 7/64] [Batch 741/937] [D loss: 0.543869] [G loss: 0.827337]\n",
      "[Epoch 7/64] [Batch 841/937] [D loss: 0.638372] [G loss: 1.008546]\n",
      "[Epoch 8/64] [Batch 4/937] [D loss: 0.625364] [G loss: 0.967618]\n",
      "[Epoch 8/64] [Batch 104/937] [D loss: 0.493557] [G loss: 0.891369]\n",
      "[Epoch 8/64] [Batch 204/937] [D loss: 0.633120] [G loss: 0.919187]\n",
      "[Epoch 8/64] [Batch 304/937] [D loss: 0.647404] [G loss: 0.890032]\n",
      "[Epoch 8/64] [Batch 404/937] [D loss: 0.594836] [G loss: 0.882337]\n",
      "[Epoch 8/64] [Batch 504/937] [D loss: 0.523609] [G loss: 0.908355]\n",
      "[Epoch 8/64] [Batch 604/937] [D loss: 0.581594] [G loss: 0.790677]\n",
      "[Epoch 8/64] [Batch 704/937] [D loss: 0.600013] [G loss: 1.013370]\n",
      "[Epoch 8/64] [Batch 804/937] [D loss: 0.638689] [G loss: 1.152296]\n",
      "[Epoch 8/64] [Batch 904/937] [D loss: 0.528359] [G loss: 0.839171]\n",
      "[Epoch 9/64] [Batch 67/937] [D loss: 0.609467] [G loss: 0.920701]\n",
      "[Epoch 9/64] [Batch 167/937] [D loss: 0.577247] [G loss: 0.908943]\n",
      "[Epoch 9/64] [Batch 267/937] [D loss: 0.665294] [G loss: 0.838831]\n",
      "[Epoch 9/64] [Batch 367/937] [D loss: 0.617319] [G loss: 0.917981]\n",
      "[Epoch 9/64] [Batch 467/937] [D loss: 0.527259] [G loss: 0.925387]\n",
      "[Epoch 9/64] [Batch 567/937] [D loss: 0.544630] [G loss: 0.938963]\n",
      "[Epoch 9/64] [Batch 667/937] [D loss: 0.576143] [G loss: 0.948498]\n",
      "[Epoch 9/64] [Batch 767/937] [D loss: 0.658179] [G loss: 0.928645]\n",
      "[Epoch 9/64] [Batch 867/937] [D loss: 0.599113] [G loss: 1.051657]\n",
      "[Epoch 10/64] [Batch 30/937] [D loss: 0.587708] [G loss: 0.867646]\n",
      "[Epoch 10/64] [Batch 130/937] [D loss: 0.596969] [G loss: 0.909230]\n",
      "[Epoch 10/64] [Batch 230/937] [D loss: 0.607332] [G loss: 0.903577]\n",
      "[Epoch 10/64] [Batch 330/937] [D loss: 0.653977] [G loss: 0.820568]\n",
      "[Epoch 10/64] [Batch 430/937] [D loss: 0.645267] [G loss: 0.894146]\n",
      "[Epoch 10/64] [Batch 530/937] [D loss: 0.606274] [G loss: 0.849611]\n",
      "[Epoch 10/64] [Batch 630/937] [D loss: 0.552244] [G loss: 1.032833]\n",
      "[Epoch 10/64] [Batch 730/937] [D loss: 0.607253] [G loss: 1.039485]\n",
      "[Epoch 10/64] [Batch 830/937] [D loss: 0.581492] [G loss: 0.925386]\n",
      "[Epoch 10/64] [Batch 930/937] [D loss: 0.654218] [G loss: 0.912288]\n",
      "[Epoch 11/64] [Batch 93/937] [D loss: 0.549403] [G loss: 1.055878]\n",
      "[Epoch 11/64] [Batch 193/937] [D loss: 0.539883] [G loss: 0.987009]\n",
      "[Epoch 11/64] [Batch 293/937] [D loss: 0.591002] [G loss: 0.952516]\n",
      "[Epoch 11/64] [Batch 393/937] [D loss: 0.659435] [G loss: 0.882710]\n",
      "[Epoch 11/64] [Batch 493/937] [D loss: 0.527719] [G loss: 1.009331]\n",
      "[Epoch 11/64] [Batch 593/937] [D loss: 0.573940] [G loss: 0.923278]\n",
      "[Epoch 11/64] [Batch 693/937] [D loss: 0.436090] [G loss: 0.967498]\n",
      "[Epoch 11/64] [Batch 793/937] [D loss: 0.619586] [G loss: 0.746526]\n",
      "[Epoch 11/64] [Batch 893/937] [D loss: 0.663152] [G loss: 0.742568]\n",
      "[Epoch 12/64] [Batch 56/937] [D loss: 0.586247] [G loss: 0.987248]\n",
      "[Epoch 12/64] [Batch 156/937] [D loss: 0.602288] [G loss: 0.894205]\n",
      "[Epoch 12/64] [Batch 256/937] [D loss: 0.520955] [G loss: 1.138673]\n",
      "[Epoch 12/64] [Batch 356/937] [D loss: 0.532224] [G loss: 0.934695]\n",
      "[Epoch 12/64] [Batch 456/937] [D loss: 0.566279] [G loss: 0.780179]\n",
      "[Epoch 12/64] [Batch 556/937] [D loss: 0.552699] [G loss: 1.137852]\n",
      "[Epoch 12/64] [Batch 656/937] [D loss: 0.615701] [G loss: 0.940320]\n",
      "[Epoch 12/64] [Batch 756/937] [D loss: 0.488128] [G loss: 1.042043]\n",
      "[Epoch 12/64] [Batch 856/937] [D loss: 0.530180] [G loss: 1.095877]\n",
      "[Epoch 13/64] [Batch 19/937] [D loss: 0.624313] [G loss: 0.795945]\n",
      "[Epoch 13/64] [Batch 119/937] [D loss: 0.585441] [G loss: 1.018022]\n",
      "[Epoch 13/64] [Batch 219/937] [D loss: 0.580126] [G loss: 1.152714]\n",
      "[Epoch 13/64] [Batch 319/937] [D loss: 0.555075] [G loss: 0.946342]\n",
      "[Epoch 13/64] [Batch 419/937] [D loss: 0.539683] [G loss: 1.020315]\n",
      "[Epoch 13/64] [Batch 519/937] [D loss: 0.645004] [G loss: 1.089278]\n",
      "[Epoch 13/64] [Batch 619/937] [D loss: 0.572244] [G loss: 1.130126]\n",
      "[Epoch 13/64] [Batch 719/937] [D loss: 0.470282] [G loss: 1.149148]\n",
      "[Epoch 13/64] [Batch 819/937] [D loss: 0.529077] [G loss: 0.928347]\n",
      "[Epoch 13/64] [Batch 919/937] [D loss: 0.588129] [G loss: 1.259115]\n",
      "[Epoch 14/64] [Batch 82/937] [D loss: 0.610007] [G loss: 1.013921]\n",
      "[Epoch 14/64] [Batch 182/937] [D loss: 0.599027] [G loss: 1.024331]\n",
      "[Epoch 14/64] [Batch 282/937] [D loss: 0.587937] [G loss: 0.983982]\n",
      "[Epoch 14/64] [Batch 382/937] [D loss: 0.470994] [G loss: 1.029869]\n",
      "[Epoch 14/64] [Batch 482/937] [D loss: 0.587763] [G loss: 1.096519]\n",
      "[Epoch 14/64] [Batch 582/937] [D loss: 0.494980] [G loss: 1.344505]\n",
      "[Epoch 14/64] [Batch 682/937] [D loss: 0.520945] [G loss: 1.116570]\n",
      "[Epoch 14/64] [Batch 782/937] [D loss: 0.464348] [G loss: 1.028444]\n",
      "[Epoch 14/64] [Batch 882/937] [D loss: 0.469473] [G loss: 1.336197]\n",
      "[Epoch 15/64] [Batch 45/937] [D loss: 0.493621] [G loss: 1.047973]\n",
      "[Epoch 15/64] [Batch 145/937] [D loss: 0.548873] [G loss: 1.101324]\n",
      "[Epoch 15/64] [Batch 245/937] [D loss: 0.603958] [G loss: 1.190847]\n",
      "[Epoch 15/64] [Batch 345/937] [D loss: 0.567032] [G loss: 1.110409]\n",
      "[Epoch 15/64] [Batch 445/937] [D loss: 0.486573] [G loss: 1.084940]\n",
      "[Epoch 15/64] [Batch 545/937] [D loss: 0.596064] [G loss: 0.977856]\n",
      "[Epoch 15/64] [Batch 645/937] [D loss: 0.460567] [G loss: 1.223183]\n",
      "[Epoch 15/64] [Batch 745/937] [D loss: 0.586154] [G loss: 1.164682]\n",
      "[Epoch 15/64] [Batch 845/937] [D loss: 0.477625] [G loss: 0.897940]\n",
      "[Epoch 16/64] [Batch 8/937] [D loss: 0.567006] [G loss: 1.145720]\n",
      "[Epoch 16/64] [Batch 108/937] [D loss: 0.463821] [G loss: 1.170308]\n",
      "[Epoch 16/64] [Batch 208/937] [D loss: 0.510837] [G loss: 1.001233]\n",
      "[Epoch 16/64] [Batch 308/937] [D loss: 0.547985] [G loss: 1.154243]\n",
      "[Epoch 16/64] [Batch 408/937] [D loss: 0.448059] [G loss: 1.273142]\n",
      "[Epoch 16/64] [Batch 508/937] [D loss: 0.730603] [G loss: 0.945216]\n",
      "[Epoch 16/64] [Batch 608/937] [D loss: 0.473307] [G loss: 1.202064]\n",
      "[Epoch 16/64] [Batch 708/937] [D loss: 0.461019] [G loss: 1.613844]\n",
      "[Epoch 16/64] [Batch 808/937] [D loss: 0.751675] [G loss: 0.961607]\n",
      "[Epoch 16/64] [Batch 908/937] [D loss: 0.424216] [G loss: 1.245914]\n",
      "[Epoch 17/64] [Batch 71/937] [D loss: 0.537445] [G loss: 0.952380]\n",
      "[Epoch 17/64] [Batch 171/937] [D loss: 0.575788] [G loss: 0.547453]\n",
      "[Epoch 17/64] [Batch 271/937] [D loss: 0.542715] [G loss: 1.240584]\n",
      "[Epoch 17/64] [Batch 371/937] [D loss: 0.464463] [G loss: 0.867367]\n",
      "[Epoch 17/64] [Batch 471/937] [D loss: 0.551834] [G loss: 1.146217]\n",
      "[Epoch 17/64] [Batch 571/937] [D loss: 0.518858] [G loss: 1.452304]\n",
      "[Epoch 17/64] [Batch 671/937] [D loss: 0.423500] [G loss: 0.979098]\n",
      "[Epoch 17/64] [Batch 771/937] [D loss: 0.625161] [G loss: 1.049752]\n",
      "[Epoch 17/64] [Batch 871/937] [D loss: 0.381415] [G loss: 1.029619]\n",
      "[Epoch 18/64] [Batch 34/937] [D loss: 0.574045] [G loss: 1.024606]\n",
      "[Epoch 18/64] [Batch 134/937] [D loss: 0.506864] [G loss: 0.968771]\n",
      "[Epoch 18/64] [Batch 234/937] [D loss: 0.446679] [G loss: 1.455392]\n",
      "[Epoch 18/64] [Batch 334/937] [D loss: 0.427615] [G loss: 1.073236]\n",
      "[Epoch 18/64] [Batch 434/937] [D loss: 0.396730] [G loss: 1.217316]\n",
      "[Epoch 18/64] [Batch 534/937] [D loss: 0.484240] [G loss: 0.846994]\n",
      "[Epoch 18/64] [Batch 634/937] [D loss: 0.397599] [G loss: 0.860177]\n",
      "[Epoch 18/64] [Batch 734/937] [D loss: 0.519273] [G loss: 0.862787]\n",
      "[Epoch 18/64] [Batch 834/937] [D loss: 0.596446] [G loss: 1.111666]\n",
      "[Epoch 18/64] [Batch 934/937] [D loss: 0.433910] [G loss: 1.086105]\n",
      "[Epoch 19/64] [Batch 97/937] [D loss: 0.386594] [G loss: 1.264260]\n",
      "[Epoch 19/64] [Batch 197/937] [D loss: 0.729520] [G loss: 1.063374]\n",
      "[Epoch 19/64] [Batch 297/937] [D loss: 0.540625] [G loss: 1.182718]\n",
      "[Epoch 19/64] [Batch 397/937] [D loss: 0.520099] [G loss: 1.446001]\n",
      "[Epoch 19/64] [Batch 497/937] [D loss: 0.512933] [G loss: 1.312306]\n",
      "[Epoch 19/64] [Batch 597/937] [D loss: 0.398626] [G loss: 1.281452]\n",
      "[Epoch 19/64] [Batch 697/937] [D loss: 0.380488] [G loss: 1.081177]\n",
      "[Epoch 19/64] [Batch 797/937] [D loss: 0.401599] [G loss: 1.459293]\n",
      "[Epoch 19/64] [Batch 897/937] [D loss: 0.369867] [G loss: 1.178386]\n",
      "[Epoch 20/64] [Batch 60/937] [D loss: 0.305884] [G loss: 1.266397]\n",
      "[Epoch 20/64] [Batch 160/937] [D loss: 0.478407] [G loss: 1.281778]\n",
      "[Epoch 20/64] [Batch 260/937] [D loss: 0.452564] [G loss: 1.655764]\n",
      "[Epoch 20/64] [Batch 360/937] [D loss: 0.438036] [G loss: 1.838220]\n",
      "[Epoch 20/64] [Batch 460/937] [D loss: 0.442907] [G loss: 1.534410]\n",
      "[Epoch 20/64] [Batch 560/937] [D loss: 0.448808] [G loss: 1.368298]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    for i, (real_imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        real_imgs = real_imgs.cuda()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = torch.Tensor(np.random.normal(0, 1, (real_imgs.shape[0], 100))).cuda()\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(\n",
    "            discriminator(gen_imgs), torch.ones((gen_imgs.size(0),1)).cuda()\n",
    "        )\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = adversarial_loss(\n",
    "            discriminator(real_imgs), torch.ones((gen_imgs.size(0),1)).cuda()\n",
    "        )\n",
    "        fake_loss = adversarial_loss(\n",
    "            discriminator(gen_imgs.detach()), torch.zeros((gen_imgs.size(0),1)).cuda()\n",
    "        )\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "\n",
    "\n",
    "        if batches_done % 100 == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (epoch, 64, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "            )\n",
    "\n",
    "        if batches_done % 2000 == 0:\n",
    "            save_image(gen_imgs.data[:25], \"dcgan_images/%d.png\" % batches_done, nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d542b-9180-401e-a5f3-57564121b102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e37e4f-2eaa-46ad-9fba-5aa956a3392f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
