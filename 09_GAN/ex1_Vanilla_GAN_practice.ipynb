{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7eaeec8-075e-440a-8979-9b4b855db11e",
   "metadata": {},
   "source": [
    "# Vanilla GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c410a3-b828-4bb3-bc73-df20473d9a43",
   "metadata": {},
   "source": [
    "- Referecnce : https://github.com/eriklindernoren/PyTorch-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2afbd92-67d7-4d49-8f9a-3bd71ff89243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf49ff4-e851-4aa5-9cb2-cdc4117b8db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61215b14-cf0e-45db-9315-d2144ab0c9a6",
   "metadata": {},
   "source": [
    "## Define Generator & Discriminator\n",
    "- layers would be mlp\n",
    "- Activations except last one are nn.LeakyReLU(0.2)\n",
    "- BachNorm parameter = 0.8\n",
    "- Dropout p = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43de6bd-868a-45ad-ad39-9bdecd594d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #### Implement Here ####\n",
    "        \n",
    "\n",
    "    def make_block(self, in_feat, out_feat):\n",
    "        #### Implement Here ####\n",
    "        \n",
    "\n",
    "        return \n",
    "\n",
    "    def forward(self, z):\n",
    "        #### Implement Here ####\n",
    "        # Hint : Embedding vector should be resized into image shape after go through network\n",
    "        \n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae907330-564c-4572-96a9-b19e07ce7c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #### Implement Here ####\n",
    "\n",
    "        \n",
    "    def forward(self, img):\n",
    "        #### Implement Here ####\n",
    "        # Hint : Image should be vectorized before go through network\n",
    "        \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68008ffd-f9b4-45b9-8f3c-4add4872b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator and discriminator\n",
    "G = Generator()\n",
    "D = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e3821-3aea-4371-a031-abb8e0f2df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(G, device = 'cpu', batch_size = -1, input_size = (100,))\n",
    "summary(D, device = 'cpu', batch_size = -1, input_size = (1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d69860-5acb-4293-bb6f-39fddf3adccc",
   "metadata": {},
   "source": [
    "## Define loss & Optimizer & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8728f4c-c09b-405a-9712-f8549c0626da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Optimizer for each network\n",
    "optimizer_G = torch.optim.Adam(G.parameters(), lr=0.0001, betas = (0.5, 0.9999))\n",
    "optimizer_D = torch.optim.Adam(D.parameters(), lr=0.0001, betas = (0.5, 0.9999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d76894a-7062-4f68-99b0-0bfe0b55b0aa",
   "metadata": {},
   "source": [
    "## Use MNIST Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b86e60d-6340-45e2-8767-5795a46a080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bs = 64\n",
    "\n",
    "dataset = datasets.MNIST(\"./mnist\", train=True, download=True, \n",
    "                         transform=transforms.Compose([transforms.Resize(28), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=train_bs, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dcb70e-e9e3-4c5e-a1c7-e94aca28aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "len(batch)\n",
    "print(batch[0].shape, batch[1])\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.show()\n",
    "    \n",
    "imshow(torchvision.utils.make_grid(batch[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e05d4a-08bd-44bd-a185-0a2ac63b63f7",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad3c2d0-d72e-40e0-a59e-2745980218a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "G, D = G.to(device), D.to(device)\n",
    "os.makedirs(\"./mlpgan\", exist_ok=True)\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6e2e40-5b60-4ddc-9d55-4a4faf66a756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i, (real_imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        real_imgs = real_imgs.to(device)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = torch.Tensor(np.random.normal(0, 1, (real_imgs.shape[0], 100))).to(device)\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = G(z)\n",
    "        \n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        #### implement Loss ####\n",
    "        \n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        #### implement Loss ####\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        \n",
    "        if batches_done % 100 == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (epoch+1,epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "            )\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % 2000 == 0:\n",
    "            save_image(gen_imgs.data, \"mlpgan/%06d.png\" % batches_done, nrow=8, normalize=True)\n",
    "            imshow(torchvision.utils.make_grid(gen_imgs.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d542b-9180-401e-a5f3-57564121b102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
