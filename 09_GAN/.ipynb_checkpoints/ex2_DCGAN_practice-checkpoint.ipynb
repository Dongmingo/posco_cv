{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b27288-2df0-40ca-8e11-b672c02bcf09",
   "metadata": {},
   "source": [
    "# Deep Convloutional GAN (DCGAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ad4877-2ae8-4fb0-8649-824aff1064f7",
   "metadata": {},
   "source": [
    "- Referecnce : https://github.com/eriklindernoren/PyTorch-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede26885-108e-4524-8acf-52b96f04ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281948d1-f352-4655-8251-e99d0f0d88e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb42372-adb1-4366-b6b1-c6d5cb022789",
   "metadata": {},
   "source": [
    "## Define Generator & Discriminator\n",
    "### Generator architecture\n",
    "input random vector: 100 dim\n",
    "* Linear: out_features 128 * 8 * 8\n",
    "* BatchNorm2d\n",
    "* Upsample: scale_factor 2\n",
    "* Conv2d: out_channel: 128, kernel size 3, stride 1, padding 1\n",
    "* BatchNorm2d\n",
    "* LeakyReLU: 0.2\n",
    "* Upsample: scale_factor 2\n",
    "* Conv2d: out_channel: 64, kernel size 3, stride 1, padding 1\n",
    "* BatchNorm\n",
    "* LeakyReLU: 0.2\n",
    "* Conv2d: out_channel: 1, kernel size 3, stride 1, padding 1\n",
    "* Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b2f3ac-9e09-473f-ab69-9d9360dad41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #### Implement Here ####        \n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        #### Implement Here ####\n",
    "        #### Hint : z should be reshaped into 2d before going into conv layer \n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dede475-d492-4dc9-a1ca-86f5d4628918",
   "metadata": {},
   "source": [
    "### Discriminator architecture\n",
    "input: [1 , 32 , 32] image \n",
    "* Conv2d: out_channel: 16, kernel size 3, stride 1, padding 1\n",
    "* LeakyReLU: 0.2\n",
    "* Dropout: 0.25\n",
    "* Conv2d: out_channel: 32, kernel size 3, stride 1, padding 1\n",
    "* LeakyReLU: 0.2\n",
    "* Dropout: 0.25\n",
    "* BatchNorm2d\n",
    "* Conv2d: out_channel: 64, kernel size 3, stride 1, padding 1\n",
    "* LeakyReLU: 0.2\n",
    "* Dropout: 0.25\n",
    "* BatchNorm2d\n",
    "* Conv2d: out_channel: 128, kernel size 3, stride 1, padding 1\n",
    "* LeakyReLU: 0.2\n",
    "* Dropout: 0.25\n",
    "* BatchNorm2d\n",
    "* Linear: out_features 1\n",
    "* Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59bb0e7-928c-42af-81d2-5882061144cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #### Implement Here ####\n",
    "        \n",
    "        \n",
    "    def make_block(self, in_features, out_features):\n",
    "        #### Implement Here ####\n",
    "        \n",
    "        \n",
    "        return \n",
    "        \n",
    "        \n",
    "    def forward(self, img):# [1, 32, 32]\n",
    "        #### Implement Here ####\n",
    "        \n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e093ae1f-37d9-471a-9017-71e4b88272e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator and discriminator\n",
    "G = Generator()\n",
    "D = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b944c3-5353-4e52-91df-9c07c1d5bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(G, device = 'cpu', batch_size = -1, input_size = (100,))\n",
    "summary(D, device = 'cpu', batch_size = -1, input_size = (1, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86b074a-e5ff-46c3-a9bb-8552045c89cd",
   "metadata": {},
   "source": [
    "## Define loss & Optimizer & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8728f4c-c09b-405a-9712-f8549c0626da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "optimizer_G = torch.optim.Adam(G.parameters(), lr=0.0001, betas=(0.5, 0.9999))\n",
    "optimizer_D = torch.optim.Adam(D.parameters(), lr=0.0001, betas=(0.5, 0.9999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800b8f52-d6dc-4722-8000-49e9d19fcc4d",
   "metadata": {},
   "source": [
    "## Use MNIST Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be1559-7ce5-4963-bcc9-908f51675242",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "\n",
    "dataset = datasets.MNIST(\"./mnist\", train=True, download=True, \n",
    "                         transform=transforms.Compose([transforms.Resize(32), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bc9815-ca29-48de-b181-4b6638b5600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "len(batch)\n",
    "print(batch[0].shape, batch[1])\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.show()\n",
    "    \n",
    "imshow(torchvision.utils.make_grid(batch[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161cf88c-c8ad-40ac-8514-9df555ea22af",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac97890f-b202-4f96-a13a-8f1bf7dc4c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "G, D = G.to(device), D.to(device)\n",
    "os.makedirs(\"./dcgan_images\", exist_ok=True)\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82726823-448c-46d1-9c13-dd4decfae34c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i, (real_imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        real_imgs = real_imgs.to(device)\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = torch.Tensor(np.random.normal(0, 1, (real_imgs.shape[0], 100))).to(device)\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        #### Implement Here ####\n",
    "\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        #### Implement Here ####\n",
    "        \n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "\n",
    "        if batches_done % 100 == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (epoch, epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "            )\n",
    "\n",
    "        if batches_done % 2000 == 0:\n",
    "            save_image(gen_imgs.data, \"dcgan_images/%d.png\" % batches_done, nrow=8, normalize=True)\n",
    "            imshow(torchvision.utils.make_grid(gen_imgs.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d542b-9180-401e-a5f3-57564121b102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
