{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb2994e8-76ce-4a00-bd2d-c83fe597ec65",
   "metadata": {},
   "source": [
    "# Auxilary Classifier GAN (ACGAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ad4877-2ae8-4fb0-8649-824aff1064f7",
   "metadata": {},
   "source": [
    "Referecnce : https://github.com/eriklindernoren/PyTorch-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede26885-108e-4524-8acf-52b96f04ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0564e1bf-8109-4355-a2f7-aced393218de",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7d48d-afdd-4ec9-9e8d-6c184532609f",
   "metadata": {},
   "source": [
    "## Use MNIST Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f32ff-143d-449e-9f64-6d6d1aecb873",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs =128\n",
    "\n",
    "dataset = datasets.MNIST(\"./mnist\", train=True, download=True, \n",
    "                         transform=transforms.Compose([transforms.Resize(32), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8d67fb-31d3-4213-ab3f-674a6515f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))\n",
    "len(batch)\n",
    "print(batch[0].shape, batch[1])\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.show()\n",
    "    \n",
    "imshow(torchvision.utils.make_grid(batch[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae79be69-3c33-481c-955e-1bae591e32e4",
   "metadata": {},
   "source": [
    "## Define Generator & Discriminator\n",
    "### Generator architecture\n",
    "input random vector: 100 dim\n",
    "* Embedding: embeding labels to 100 dim\n",
    "* Linear: out_features 128 * 8 * 8\n",
    "* BatchNorm2d\n",
    "* Upsample: scale_factor 2\n",
    "* Conv2d: out_channel: 128, kernel size 3, stride 1, padding 1\n",
    "* BatchNorm2d\n",
    "* LeakyReLU: 0.2\n",
    "* Upsample: scale_factor 2\n",
    "* Conv2d: out_channel: 64, kernel size 3, stride 1, padding 1\n",
    "* BatchNorm\n",
    "* LeakyReLU: 0.2\n",
    "* Conv2d: out_channel: 1, kernel size 3, stride 1, padding 1\n",
    "* Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b2f3ac-9e09-473f-ab69-9d9360dad41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #### Implement Here ####\n",
    "        \n",
    "        \n",
    "    def forward(self, z, labels):\n",
    "        #### Implement Here ####\n",
    "        ## noise, labels -> noise: 100, label: 1 dim -> 100 dim \n",
    "        ## noise * label\n",
    "\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd819a1-71bf-4a43-adf0-8ff85d9318e7",
   "metadata": {},
   "source": [
    "### Discriminator architecture\n",
    "input: [1 , 32 , 32] image  \n",
    "* Conv2d: out_channel: 16, kernel size 3, stride 2, padding 1\n",
    "* LeakyReLU: 0.2\n",
    "* Dropout: 0.25\n",
    "* Conv2d: out_channel: 32, kernel size 3, stride 2, padding 1\n",
    "* LeakyReLU: 0.2\n",
    "* Dropout: 0.25\n",
    "* BatchNorm2d\n",
    "* Conv2d: out_channel: 64, kernel size 3, stride 2, padding 1\n",
    "* LeakyReLU: 0.2\n",
    "* Dropout: 0.25\n",
    "* BatchNorm2d\n",
    "* Conv2d: out_channel: 128, kernel size 3, stride 2, padding 1\n",
    "* LeakyReLU: 0.2\n",
    "* Dropout: 0.25\n",
    "* BatchNorm2d\n",
    "* two linear layers: one for adversarial loss, one for classification\n",
    "- Linear(Val) : output 1, activation : sigmoid\n",
    "- Linear(classification) : output 10, no activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59bb0e7-928c-42af-81d2-5882061144cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #### Implement Here ####\n",
    "\n",
    "        \n",
    "        \n",
    "    def make_block(self, in_channel, out_channel, bn= True):\n",
    "        #### Implement Here ####\n",
    "        layers = [\n",
    "\n",
    "        ]\n",
    "        if bn:\n",
    "            layers.append()\n",
    "        \n",
    "        return nn.Sequential(*layers) \n",
    "        \n",
    "        \n",
    "    def forward(self, img):\n",
    "        ## fill here\n",
    "\n",
    "        \n",
    "        return validity, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d5e89-c18f-41b8-b958-d86b3dc76bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator()\n",
    "\n",
    "input_sample = torch.randn(10,100)\n",
    "labels = torch.Tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).long()\n",
    "output = G(input_sample, labels)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd32dd8-dfd1-43bc-b875-0ac20d85fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator()\n",
    "validity, pred_label = D(output)\n",
    "print(validity.shape)\n",
    "print(pred_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545ac929-302b-4299-9c62-ecbcdd835799",
   "metadata": {},
   "source": [
    "## Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b91cb6c-2381-42f6-b128-145fa28c688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1: # Conv2d layer weights init\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1: # BatchNorm2d layer weights init\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "# weight initialize\n",
    "G.apply(weights_init_normal)\n",
    "D.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b426b483-0d0d-4587-93e0-145f03b4c912",
   "metadata": {},
   "source": [
    "## Define loss & Optimizer & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d249fb70-78cf-4191-9d58-afd3d6d4572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "auxiliary_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "## optimizer fill here\n",
    "optimizer_G = torch.optim.Adam(G.parameters(), lr=0.00002, betas=(0.5, 0.9999))\n",
    "optimizer_D = torch.optim.Adam(D.parameters(), lr=0.00002, betas=(0.5, 0.9999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4116cfae-39c9-4cd3-8903-100c0d42e461",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfef8fc-4641-4709-a977-1127c75dc9eb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "G, D = G.to(device), D.to(device)\n",
    "os.makedirs(\"./acgan_images\", exist_ok=True)\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cec29e-9455-49e5-9d70-a2775d9a4d34",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_image(n_row, batches_done):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    z = torch.Tensor(np.random.normal(0, 1, (n_row ** 2, 100))).to(device)\n",
    "    # Get labels ranging from 0 to n_classes for n rows\n",
    "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
    "    labels = torch.LongTensor(labels).to(device)\n",
    "    gen_imgs = G(z, labels)\n",
    "    save_image(gen_imgs, \"acgan_images/%06d.png\" % batches_done, nrow=n_row, normalize=True)\n",
    "    imshow(torchvision.utils.make_grid(gen_imgs.cpu(), nrow = n_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82726823-448c-46d1-9c13-dd4decfae34c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i, (real_imgs, labels) in enumerate(dataloader):\n",
    "\n",
    "        batch_size = real_imgs.shape[0]\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = real_imgs.to(device)\n",
    "        real_labels = labels.to(device)\n",
    "        \n",
    "        ones = torch.ones((real_imgs.size(0), 1)).to(device)\n",
    "        zeros = torch.zeros((real_imgs.size(0), 1)).to(device)\n",
    "        \n",
    "        ## z random sample\n",
    "        ## label random sample 0-9 int\n",
    "        z = torch.Tensor(np.random.normal(0, 1, (batch_size, 100))).to(device)\n",
    "        gen_labels = torch.LongTensor(np.random.randint(0, 10, batch_size)).to(device)\n",
    "        \n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        #### Implement Here ####\n",
    "        \n",
    "        ## generator, discriminator output\n",
    "\n",
    "        \n",
    "        ## g_loss = adversarial_loss + classification loss\n",
    "\n",
    "\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        #### Implement Here ####\n",
    "        \n",
    "        # Loss for real images : adversarial_loss + classification loss\n",
    "\n",
    "        \n",
    "        # Loss for fake images : adversarial_loss + classification loss\n",
    "\n",
    "        \n",
    "        # Total discriminator loss\n",
    "\n",
    "        \n",
    "        # Calculate discriminator accuracy\n",
    "        pred = np.concatenate([real_labels_pred.detach().cpu().numpy(), fake_labels_pred.detach().cpu().numpy()], axis=0)\n",
    "        gt = np.concatenate([labels.detach().cpu().numpy(), gen_labels.detach().cpu().numpy()], axis=0)\n",
    "        d_acc = np.mean(np.argmax(pred, axis=1) == gt)\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % 100 == 0:     \n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %d%%] [G loss: %f]\"\n",
    "                % (epoch, 200, i, len(dataloader), d_loss.item(), 100 * d_acc, g_loss.item())\n",
    "            )\n",
    "            \n",
    "        if batches_done % 2000 == 0:\n",
    "            sample_image(n_row=10, batches_done=batches_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d542b-9180-401e-a5f3-57564121b102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
