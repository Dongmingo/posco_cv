{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ad4877-2ae8-4fb0-8649-824aff1064f7",
   "metadata": {},
   "source": [
    "Referecnce : https://github.com/eriklindernoren/PyTorch-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ede26885-108e-4524-8acf-52b96f04ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae79be69-3c33-481c-955e-1bae591e32e4",
   "metadata": {},
   "source": [
    "### Generator architecture\n",
    "* input random vector: 100 dim, labels\n",
    "* embedding layer: embeding labels to 100 dim\n",
    "* linear layer: out_features 128 * 8 * 8\n",
    "* batchnorm\n",
    "* upsample: factor 2\n",
    "* Conv2d: out_channel: 128, kernel size 3, stride 1, padding 1\n",
    "* batchnorm\n",
    "* leakyrelu: 0.2\n",
    "* upsample: factor 2\n",
    "* conv2d: out_channel: 64, kernel size 3, stride 1, padding 1\n",
    "* batchnorm\n",
    "* leakyrelu: 0.2\n",
    "* conv2d: out_channel: 1, kernel size 3, stride 1, padding 1\n",
    "* tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b2f3ac-9e09-473f-ab69-9d9360dad41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        ## fill here\n",
    "        ## noise, labels -> noise: 100, label: 1 dim -> 100 dim \n",
    "        ## noise * label\n",
    "        self.label_emb = nn.Embedding(10, 100) \n",
    "        ## label 1: -> 100, 2: -> 100, 9-> 100\n",
    "        self.l1 = nn.Linear(100, 128*8*8)\n",
    "        self.conv_blocks = nn.Sequential( #[batch, 128, 8, 8]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor =2), #[16,16]\n",
    "            nn.Conv2d(128, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Upsample(scale_factor =2), #[32, 32]\n",
    "            nn.Conv2d(128, 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 1, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, noise, labels):\n",
    "        ## fill here\n",
    "        out = torch.mul(self.label_emb(labels), noise) # 100\n",
    "        out = self.l1(out)\n",
    "        out = out.view(out.shape[0], 128, 8, 8)\n",
    "        img = self.conv_blocks(out)\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd819a1-71bf-4a43-adf0-8ff85d9318e7",
   "metadata": {},
   "source": [
    "### Discriminator architecture\n",
    "* input: [1 , 32 , 32] image \n",
    "* conv2d: out_channel: 16, kernel size 3, stride 2, padding 1\n",
    "* leakyrelu: 0.2\n",
    "* dropout: 0.25\n",
    "* Conv2d: out_channel: 32, kernel size 3, stride 2, padding 1\n",
    "* leakyrelu: 0.2\n",
    "* dropout: 0.25\n",
    "* batchnorm\n",
    "* Conv2d: out_channel: 64, kernel size 3, stride 2, padding 1\n",
    "* leakyrelu: 0.2\n",
    "* dropout: 0.25\n",
    "* batchnorm\n",
    "* Conv2d: out_channel: 128, kernel size 3, stride 2, padding 1\n",
    "* leakyrelu: 0.2\n",
    "* dropout: 0.25\n",
    "* batchnorm\n",
    "* two linear layers: one for adversarial loss, one for classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f59bb0e7-928c-42af-81d2-5882061144cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        ## fill here\n",
    "        ## linear 2 \n",
    "        ## one for real/fake classification\n",
    "        ## one for class classification\n",
    "        def discriminator_block(in_features, out_features, bn = True):\n",
    "            block = []\n",
    "            block.append(\n",
    "                nn.Conv2d(in_features, out_features, kernel_size = 3, stride = 2, padding = 1)\n",
    "            )\n",
    "            block.append(nn.LeakyReLU(0.2))\n",
    "            block.append(nn.Dropout2d(0.25))\n",
    "            \n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_features))\n",
    "            \n",
    "            return block\n",
    "        \n",
    "        self.model = nn.Sequential( #[batch, 1, 32, 32]\n",
    "            *discriminator_block(1, 16, bn = False), #[16, 16]\n",
    "            *discriminator_block(16, 32),#[8, 8]\n",
    "            *discriminator_block(32, 64),#[4, 4]\n",
    "            *discriminator_block(64, 128)#[batch, 128, 2, 2]\n",
    "        )\n",
    "        \n",
    "        self.adv_layer = nn.Sequential(\n",
    "            nn.Linear(128*2*2, 1), nn.Sigmoid()\n",
    "        )\n",
    "        self.aux_layer = nn.Sequential(\n",
    "            nn.Linear(128*2*2, 10) ## skip softmax\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        ## fill here\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1) #flatten\n",
    "        validity = self.adv_layer(out) # 0, 1\n",
    "        label = self.aux_layer(out) # 0 - 9\n",
    "        \n",
    "        return validity, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7d5e89-c18f-41b8-b958-d86b3dc76bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = Generator()\n",
    "\n",
    "# input_sample = torch.randn(2,100)\n",
    "# labels = torch.Tensor([0, 1]).long()\n",
    "# output = generator(input_sample, labels)\n",
    "# output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bd32dd8-dfd1-43bc-b875-0ac20d85fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator = Discriminator()\n",
    "# validity, pred_label = discriminator(output)\n",
    "# print(validity.shape)\n",
    "# print(pred_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8728f4c-c09b-405a-9712-f8549c0626da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "auxiliary_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator().cuda()\n",
    "discriminator = Discriminator().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58be1559-7ce5-4963-bcc9-908f51675242",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(\"./mnist\", train=True, download=True, \n",
    "                         transform=transforms.Compose([transforms.Resize(32), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d249fb70-78cf-4191-9d58-afd3d6d4572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## optimizer fill here\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.00002, betas=(0.5, 0.9999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.00002, betas=(0.5, 0.9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbfef8fc-4641-4709-a977-1127c75dc9eb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"./acgan_images\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99cec29e-9455-49e5-9d70-a2775d9a4d34",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_image(n_row, batches_done):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    z = torch.Tensor(np.random.normal(0, 1, (n_row ** 2, 100))).cuda()\n",
    "    # Get labels ranging from 0 to n_classes for n rows\n",
    "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
    "    labels = torch.LongTensor(labels).cuda()\n",
    "    gen_imgs = generator(z, labels)\n",
    "    save_image(gen_imgs, \"acgan_images/%d.png\" % batches_done, nrow=n_row, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82726823-448c-46d1-9c13-dd4decfae34c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/937] [D loss: 1.574347, acc: 13%] [G loss: 1.676080]\n",
      "[Epoch 0/200] [Batch 100/937] [D loss: 1.527292, acc: 12%] [G loss: 1.530517]\n",
      "[Epoch 0/200] [Batch 200/937] [D loss: 1.416282, acc: 21%] [G loss: 1.476052]\n",
      "[Epoch 0/200] [Batch 300/937] [D loss: 1.414452, acc: 23%] [G loss: 1.502225]\n",
      "[Epoch 0/200] [Batch 400/937] [D loss: 1.397690, acc: 31%] [G loss: 1.458599]\n",
      "[Epoch 0/200] [Batch 500/937] [D loss: 1.309003, acc: 32%] [G loss: 1.510559]\n",
      "[Epoch 0/200] [Batch 600/937] [D loss: 1.279793, acc: 40%] [G loss: 1.436679]\n",
      "[Epoch 0/200] [Batch 700/937] [D loss: 1.207819, acc: 39%] [G loss: 1.366102]\n",
      "[Epoch 0/200] [Batch 800/937] [D loss: 1.166805, acc: 42%] [G loss: 1.362931]\n",
      "[Epoch 0/200] [Batch 900/937] [D loss: 1.097959, acc: 53%] [G loss: 1.310933]\n",
      "[Epoch 1/200] [Batch 63/937] [D loss: 1.034429, acc: 55%] [G loss: 1.235254]\n",
      "[Epoch 1/200] [Batch 163/937] [D loss: 0.991135, acc: 58%] [G loss: 1.168180]\n",
      "[Epoch 1/200] [Batch 263/937] [D loss: 0.903980, acc: 67%] [G loss: 1.094663]\n",
      "[Epoch 1/200] [Batch 363/937] [D loss: 0.817763, acc: 70%] [G loss: 1.007255]\n",
      "[Epoch 1/200] [Batch 463/937] [D loss: 0.787313, acc: 72%] [G loss: 0.972403]\n",
      "[Epoch 1/200] [Batch 563/937] [D loss: 0.723602, acc: 78%] [G loss: 0.858294]\n",
      "[Epoch 1/200] [Batch 663/937] [D loss: 0.747673, acc: 69%] [G loss: 0.894803]\n",
      "[Epoch 1/200] [Batch 763/937] [D loss: 0.725582, acc: 75%] [G loss: 0.944400]\n",
      "[Epoch 1/200] [Batch 863/937] [D loss: 0.669805, acc: 82%] [G loss: 0.768014]\n",
      "[Epoch 2/200] [Batch 26/937] [D loss: 0.617160, acc: 84%] [G loss: 0.722124]\n",
      "[Epoch 2/200] [Batch 126/937] [D loss: 0.647644, acc: 80%] [G loss: 0.787190]\n",
      "[Epoch 2/200] [Batch 226/937] [D loss: 0.620306, acc: 78%] [G loss: 0.705806]\n",
      "[Epoch 2/200] [Batch 326/937] [D loss: 0.584922, acc: 85%] [G loss: 0.702501]\n",
      "[Epoch 2/200] [Batch 426/937] [D loss: 0.555425, acc: 88%] [G loss: 0.702279]\n",
      "[Epoch 2/200] [Batch 526/937] [D loss: 0.605583, acc: 82%] [G loss: 0.608607]\n",
      "[Epoch 2/200] [Batch 626/937] [D loss: 0.451269, acc: 92%] [G loss: 0.581779]\n",
      "[Epoch 2/200] [Batch 726/937] [D loss: 0.535767, acc: 91%] [G loss: 0.565825]\n",
      "[Epoch 2/200] [Batch 826/937] [D loss: 0.535870, acc: 86%] [G loss: 0.552135]\n",
      "[Epoch 2/200] [Batch 926/937] [D loss: 0.514546, acc: 90%] [G loss: 0.566448]\n",
      "[Epoch 3/200] [Batch 89/937] [D loss: 0.598860, acc: 84%] [G loss: 0.663719]\n",
      "[Epoch 3/200] [Batch 189/937] [D loss: 0.596052, acc: 84%] [G loss: 0.515189]\n",
      "[Epoch 3/200] [Batch 289/937] [D loss: 0.492147, acc: 92%] [G loss: 0.529293]\n",
      "[Epoch 3/200] [Batch 389/937] [D loss: 0.477091, acc: 90%] [G loss: 0.525811]\n",
      "[Epoch 3/200] [Batch 489/937] [D loss: 0.568606, acc: 88%] [G loss: 0.591677]\n",
      "[Epoch 3/200] [Batch 589/937] [D loss: 0.524527, acc: 88%] [G loss: 0.527161]\n",
      "[Epoch 3/200] [Batch 689/937] [D loss: 0.499268, acc: 91%] [G loss: 0.516385]\n",
      "[Epoch 3/200] [Batch 789/937] [D loss: 0.483731, acc: 90%] [G loss: 0.515033]\n",
      "[Epoch 3/200] [Batch 889/937] [D loss: 0.536930, acc: 88%] [G loss: 0.523974]\n",
      "[Epoch 4/200] [Batch 52/937] [D loss: 0.567835, acc: 89%] [G loss: 0.477276]\n",
      "[Epoch 4/200] [Batch 152/937] [D loss: 0.482503, acc: 91%] [G loss: 0.564578]\n",
      "[Epoch 4/200] [Batch 252/937] [D loss: 0.501212, acc: 93%] [G loss: 0.547376]\n",
      "[Epoch 4/200] [Batch 352/937] [D loss: 0.526090, acc: 90%] [G loss: 0.519093]\n",
      "[Epoch 4/200] [Batch 452/937] [D loss: 0.409272, acc: 96%] [G loss: 0.491278]\n",
      "[Epoch 4/200] [Batch 552/937] [D loss: 0.530527, acc: 90%] [G loss: 0.447131]\n",
      "[Epoch 4/200] [Batch 652/937] [D loss: 0.452253, acc: 91%] [G loss: 0.524348]\n",
      "[Epoch 4/200] [Batch 752/937] [D loss: 0.465201, acc: 88%] [G loss: 0.533405]\n",
      "[Epoch 4/200] [Batch 852/937] [D loss: 0.495221, acc: 86%] [G loss: 0.540160]\n",
      "[Epoch 5/200] [Batch 15/937] [D loss: 0.436026, acc: 93%] [G loss: 0.616381]\n",
      "[Epoch 5/200] [Batch 115/937] [D loss: 0.489062, acc: 92%] [G loss: 0.527534]\n",
      "[Epoch 5/200] [Batch 215/937] [D loss: 0.430221, acc: 93%] [G loss: 0.527460]\n",
      "[Epoch 5/200] [Batch 315/937] [D loss: 0.430797, acc: 92%] [G loss: 0.485917]\n",
      "[Epoch 5/200] [Batch 415/937] [D loss: 0.576167, acc: 88%] [G loss: 0.548984]\n",
      "[Epoch 5/200] [Batch 515/937] [D loss: 0.461635, acc: 92%] [G loss: 0.546348]\n",
      "[Epoch 5/200] [Batch 615/937] [D loss: 0.464426, acc: 90%] [G loss: 0.496053]\n",
      "[Epoch 5/200] [Batch 715/937] [D loss: 0.464691, acc: 90%] [G loss: 0.525685]\n",
      "[Epoch 5/200] [Batch 815/937] [D loss: 0.463419, acc: 95%] [G loss: 0.554472]\n",
      "[Epoch 5/200] [Batch 915/937] [D loss: 0.458345, acc: 91%] [G loss: 0.485284]\n",
      "[Epoch 6/200] [Batch 78/937] [D loss: 0.543475, acc: 87%] [G loss: 0.528286]\n",
      "[Epoch 6/200] [Batch 178/937] [D loss: 0.422328, acc: 92%] [G loss: 0.522273]\n",
      "[Epoch 6/200] [Batch 278/937] [D loss: 0.442566, acc: 95%] [G loss: 0.511844]\n",
      "[Epoch 6/200] [Batch 378/937] [D loss: 0.488932, acc: 88%] [G loss: 0.575337]\n",
      "[Epoch 6/200] [Batch 478/937] [D loss: 0.497550, acc: 91%] [G loss: 0.439398]\n",
      "[Epoch 6/200] [Batch 578/937] [D loss: 0.447651, acc: 94%] [G loss: 0.511538]\n",
      "[Epoch 6/200] [Batch 678/937] [D loss: 0.496170, acc: 89%] [G loss: 0.477122]\n",
      "[Epoch 6/200] [Batch 778/937] [D loss: 0.450638, acc: 95%] [G loss: 0.498173]\n",
      "[Epoch 6/200] [Batch 878/937] [D loss: 0.468911, acc: 90%] [G loss: 0.554183]\n",
      "[Epoch 7/200] [Batch 41/937] [D loss: 0.406347, acc: 95%] [G loss: 0.470547]\n",
      "[Epoch 7/200] [Batch 141/937] [D loss: 0.461640, acc: 92%] [G loss: 0.519292]\n",
      "[Epoch 7/200] [Batch 241/937] [D loss: 0.431282, acc: 95%] [G loss: 0.523197]\n",
      "[Epoch 7/200] [Batch 341/937] [D loss: 0.450676, acc: 91%] [G loss: 0.471748]\n",
      "[Epoch 7/200] [Batch 441/937] [D loss: 0.488113, acc: 92%] [G loss: 0.592821]\n",
      "[Epoch 7/200] [Batch 541/937] [D loss: 0.416454, acc: 92%] [G loss: 0.512322]\n",
      "[Epoch 7/200] [Batch 641/937] [D loss: 0.436253, acc: 93%] [G loss: 0.506182]\n",
      "[Epoch 7/200] [Batch 741/937] [D loss: 0.414996, acc: 93%] [G loss: 0.488260]\n",
      "[Epoch 7/200] [Batch 841/937] [D loss: 0.416719, acc: 95%] [G loss: 0.497143]\n",
      "[Epoch 8/200] [Batch 4/937] [D loss: 0.376802, acc: 96%] [G loss: 0.522497]\n",
      "[Epoch 8/200] [Batch 104/937] [D loss: 0.434406, acc: 88%] [G loss: 0.480886]\n",
      "[Epoch 8/200] [Batch 204/937] [D loss: 0.400964, acc: 93%] [G loss: 0.495253]\n",
      "[Epoch 8/200] [Batch 304/937] [D loss: 0.360745, acc: 95%] [G loss: 0.516730]\n",
      "[Epoch 8/200] [Batch 404/937] [D loss: 0.401130, acc: 93%] [G loss: 0.567720]\n",
      "[Epoch 8/200] [Batch 504/937] [D loss: 0.430871, acc: 89%] [G loss: 0.504949]\n",
      "[Epoch 8/200] [Batch 604/937] [D loss: 0.372370, acc: 94%] [G loss: 0.472542]\n",
      "[Epoch 8/200] [Batch 704/937] [D loss: 0.447875, acc: 94%] [G loss: 0.485227]\n",
      "[Epoch 8/200] [Batch 804/937] [D loss: 0.565413, acc: 87%] [G loss: 0.466701]\n",
      "[Epoch 8/200] [Batch 904/937] [D loss: 0.458561, acc: 92%] [G loss: 0.502167]\n",
      "[Epoch 9/200] [Batch 67/937] [D loss: 0.427384, acc: 92%] [G loss: 0.507495]\n",
      "[Epoch 9/200] [Batch 167/937] [D loss: 0.406238, acc: 92%] [G loss: 0.512529]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-13d9dcce2aa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreal_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    for i, (real_imgs, labels) in enumerate(dataloader):\n",
    "\n",
    "        batch_size = real_imgs.shape[0]\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = real_imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        ## fill here\n",
    "        ## z sample\n",
    "        ## label sample 0-9 int value sample\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        z = torch.Tensor(np.random.normal(0, 1, (batch_size, 100))).cuda()\n",
    "        gen_labels = torch.LongTensor(np.random.randint(0, 10, batch_size)).cuda()\n",
    "        gen_images = generator(z, gen_labels)\n",
    "        \n",
    "        ## loss\n",
    "        fake_validity, fake_label_pred = discriminator(gen_images)\n",
    "        ## label prediction\n",
    "        ce_loss = auxiliary_loss(fake_label_pred, gen_labels)\n",
    "        adv_loss = adversarial_loss(fake_validity, torch.ones((batch_size, 1)).cuda())\n",
    "        g_loss = (adv_loss + ce_loss)/2\n",
    "        \n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        \n",
    "        ## adv loss + ce loss\n",
    "        optimizer_D.zero_grad()\n",
    "        # Loss for real images\n",
    "        real_validity, real_label_pred = discriminator(real_imgs)\n",
    "        real_loss = (adversarial_loss(real_validity, torch.ones((batch_size, 1)).cuda()) \n",
    "                     + auxiliary_loss(real_label_pred, labels))/2\n",
    "        # Loss for fake images\n",
    "        fake_validity, fake_label_pred = discriminator(gen_images.detach())\n",
    "        fake_loss = (adversarial_loss(fake_validity, torch.zeros((batch_size, 1)).cuda()) \n",
    "                     + auxiliary_loss(fake_label_pred, gen_labels))/2\n",
    "        # Total discriminator loss\n",
    "        d_loss = (real_loss + fake_loss)/2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # Calculate discriminator accuracy\n",
    "        pred = np.concatenate([real_label_pred.detach().cpu().numpy(), fake_label_pred.detach().cpu().numpy()], axis=0)\n",
    "        gt = np.concatenate([labels.detach().cpu().numpy(), gen_labels.detach().cpu().numpy()], axis=0)\n",
    "        d_acc = np.mean(np.argmax(pred, axis=1) == gt)\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % 100 == 0:     \n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %d%%] [G loss: %f]\"\n",
    "                % (epoch, 200, i, len(dataloader), d_loss.item(), 100 * d_acc, g_loss.item())\n",
    "            )\n",
    "            \n",
    "        if batches_done % 2000 == 0:\n",
    "            sample_image(n_row=10, batches_done=batches_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d542b-9180-401e-a5f3-57564121b102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e37e4f-2eaa-46ad-9fba-5aa956a3392f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
